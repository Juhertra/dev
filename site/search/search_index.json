{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"architecture/00-index/","title":"SecFlow \u2014 Architecture &amp; Design Documentation Index","text":"<p>Welcome to the SecFlow technical documentation suite. This collection defines the complete internal architecture of the Security Toolkit platform \u2014 covering everything from orchestration engines to data models, plugin systems, and CVE enrichment.</p> <p>Each document in this <code>/docs/architecture/</code> folder represents a bounded architectural domain, written in deep-technical mode to serve engineers and architects implementing or extending the system.</p>"},{"location":"architecture/00-index/#document-navigation","title":"\ud83d\udcda Document Navigation","text":"# File Description 01 Title &amp; Executive Summary Project mission, audience, and objectives. 02 Architecture Philosophy Core tenets, design rationale, and constraints. 03 Repository Layout Folder hierarchy, import rules, and tooling. 04 Core Packages &amp; Responsibilities Module roles, data contracts, and dependencies. 05 Orchestration &amp; Workflow Engine DAG-based tool chaining and execution logic. 06 Plugin System Plugin registration, lifecycle, and testing. 07 Tools Integration Model Wrappers, manifests, and sandbox execution. 08 Tool Manager &amp; UX Design How users manage tools and workflows. 09 Resource Registry Global wordlists, payloads, templates, and configs. 10 Wordlist &amp; Output Sharing Rules for shared and isolated resources. 11 Project Isolation &amp; Data Sharing Workspace boundaries, access control, linking. 12 Findings Model &amp; Schema Data models, normalization, and persistence. 13 CVE/CWE/POC Enrichment Layer External vulnerability mapping and enrichment. 14 POC Sources &amp; Legal Guidelines Governance and sandbox policies for proof-of-concepts. 15 Garbage Collection &amp; Retention Data lifecycle, cleanup tasks, and recovery. 16 Security Model Auth, RBAC, sandboxing, and auditing. 17 Observability, Logging &amp; Metrics Telemetry, structured logs, and OpenTelemetry. 18 Error Handling &amp; Recovery Centralized error strategies and resilience patterns. 19 Risk Assessment Framework NIST 5\u00d75 Matrix, CVSS, and MITRE mapping. 20 Migration &amp; Implementation Phases Step-by-step rollout plan. 21 CI/CD &amp; Testing Strategy Build matrix, pipelines, and test automation. 22 Developer Experience &amp; Docs Local setup, MkDocs, and contribution workflow. 23 Future Roadmap AI triage, automation, and next-gen features."},{"location":"architecture/00-index/#reading-order","title":"\ud83e\udded Reading Order","text":"<p>While each document is standalone, recommended order for new contributors:</p> <ol> <li>Start with 01\u201304 to grasp architecture and structure.  </li> <li>Proceed to 05\u201307 for orchestration and integration.  </li> <li>Review 09\u201313 for data, findings, and enrichment logic.  </li> <li>Study 16\u201318 for security and observability.  </li> <li>Conclude with 19\u201323 for governance, testing, and roadmap.</li> </ol>"},{"location":"architecture/00-index/#versioning-maintenance","title":"\ud83e\udde9 Versioning &amp; Maintenance","text":"<ul> <li>Documentation version follows codebase major versions (e.g., <code>1.0</code> = <code>v1.x</code> releases).  </li> <li>Each architectural change must update its corresponding file and cross-links.  </li> <li>Use <code>mkdocs serve</code> locally to preview rendered docs.  </li> <li>Changes to interfaces or DTOs require schema diff logs.</li> </ul>"},{"location":"architecture/00-index/#example-structure-diagram","title":"\ud83e\uddf1 Example Structure Diagram","text":"<pre><code>docs/\n\u2514\u2500\u2500 architecture/\n    \u251c\u2500\u2500 00-index.md\n    \u251c\u2500\u2500 01-title-and-executive-summary.md\n    \u251c\u2500\u2500 02-architecture-philosophy.md\n    \u251c\u2500\u2500 03-repository-layout.md\n    \u251c\u2500\u2500 04-core-packages-and-responsibilities.md\n    \u251c\u2500\u2500 05-orchestration-and-workflow-engine.md\n    \u251c\u2500\u2500 06-plugin-system.md\n    \u251c\u2500\u2500 07-tools-integration-model.md\n    \u251c\u2500\u2500 08-tool-manager-and-ux-design.md\n    \u251c\u2500\u2500 09-resource-registry.md\n    \u251c\u2500\u2500 10-wordlist-and-output-sharing.md\n    \u251c\u2500\u2500 11-project-isolation-and-data-sharing.md\n    \u251c\u2500\u2500 12-findings-model-and-schema.md\n    \u251c\u2500\u2500 13-cve-cwe-poc-enrichment-layer.md\n    \u251c\u2500\u2500 14-poc-sources-and-legal-guidelines.md\n    \u251c\u2500\u2500 15-garbage-collection-and-retention.md\n    \u251c\u2500\u2500 16-security-model.md\n    \u251c\u2500\u2500 17-observability-logging-and-metrics.md\n    \u251c\u2500\u2500 18-error-handling-and-recovery.md\n    \u251c\u2500\u2500 19-risk-assessment-framework.md\n    \u251c\u2500\u2500 20-migration-and-implementation-phases.md\n    \u251c\u2500\u2500 21-ci-cd-and-testing-strategy.md\n    \u251c\u2500\u2500 22-developer-experience-and-docs.md\n    \u2514\u2500\u2500 23-future-roadmap.md\n</code></pre> <p>Next: Title &amp; Executive Summary</p>"},{"location":"architecture/01-title-and-executive-summary/","title":"01 \u2014 Title &amp; Executive Summary","text":""},{"location":"architecture/01-title-and-executive-summary/#project-name","title":"\ud83e\udde9 Project Name","text":"<p>SecFlow \u2014 Security Toolkit Orchestration Framework</p>"},{"location":"architecture/01-title-and-executive-summary/#executive-summary","title":"\ud83e\udded Executive Summary","text":"<p>SecFlow is a modular, extensible, and automation-first security orchestration platform designed to unify multiple open-source and proprietary tools for penetration testing, vulnerability management, and risk analytics.</p> <p>It merges dynamic scanning, tool orchestration, data normalization, and risk intelligence into a single cohesive system \u2014 optimized for both solo pentesters and enterprise red-team workflows.</p>"},{"location":"architecture/01-title-and-executive-summary/#core-vision","title":"Core Vision","text":"<p>\"One orchestrator to chain, enrich, and analyze all security tools \u2014 safely, intelligently, and reproducibly.\"</p>"},{"location":"architecture/01-title-and-executive-summary/#core-differentiators","title":"Core Differentiators","text":"<ul> <li>\ud83d\udd04 End-to-end orchestration: Tools (Nuclei, Feroxbuster, Katana, ZAP, Burp, Caido, etc.) communicate via normalized JSON pipelines.</li> <li>\ud83e\uddf1 Hexagonal architecture: Strict separation between core logic, adapters, and interfaces.</li> <li>\ud83e\udde0 Data-driven intelligence: Findings automatically enriched with CVE/CWE/CVSS and MITRE mapping.</li> <li>\u2699\ufe0f Resource registry: Shared wordlists, templates, and payloads under a versioned resource management system.</li> <li>\ud83e\uddf0 AI-ready foundation: All findings and telemetry are machine-readable for later AI triage and summarization.</li> </ul>"},{"location":"architecture/01-title-and-executive-summary/#project-goals","title":"\ud83c\udfaf Project Goals","text":"Category Objective Engineering Create a modular mono-repo structure enabling multiple apps (CLI, API, Worker, UI). Automation Allow users to chain discovery \u2192 scanning \u2192 enrichment workflows via declarative YAML recipes. Data Consistency Standardize tool outputs into common Finding DTOs for unified triage and metrics. Usability Provide a CLI and web UI for project management, orchestration, and analytics. Security Guarantee safe sandboxing, configuration isolation, and audit logging. Scalability Support multi-tenant projects with configurable resource scopes."},{"location":"architecture/01-title-and-executive-summary/#key-capabilities-overview","title":"\ud83e\uddee Key Capabilities Overview","text":"Layer Functionality Description Core-Lib Schema &amp; DTOs Defines data models, ports, and contracts. Findings-Engine Normalization Converts raw tool outputs into structured findings. Wrappers Tool Adapters Execute, monitor, and parse tool output. Worker Orchestration Runs workflows (DAG execution, concurrency, retry policies). Web-API REST + WS Interface Exposes project, scan, and findings endpoints. UI HTMX/React Web dashboard for triage and insights. Plugins Extensibility Detectors, enrichers, or analytics extensions."},{"location":"architecture/01-title-and-executive-summary/#architecture-summary","title":"\ud83e\uddf1 Architecture Summary","text":"<pre><code>        +---------------------------+\n        |         Web-API / UI      |\n        +-------------+-------------+\n                      |\n                 REST / WebSocket\n                      |\n        +-------------v-------------+\n        |         Worker Engine     |\n        |  (Workflows, DAG, Queues) |\n        +-------------+-------------+\n                      |\n               Ports / DTOs\n                      |\n    +-----------------v-----------------+\n    |            Core-Lib              |\n    | (Models, Ports, Repositories)    |\n    +-----------------+----------------+\n                      |\n        +-------------v-------------+\n        |      Wrappers / Plugins   |\n        | (Nuclei, Ferox, Katana\u2026)  |\n        +-------------+-------------+\n                      |\n                  Tool Output\n                      |\n        +-------------v-------------+\n        |        Findings Engine    |\n        |  (Normalization, Metrics) |\n        +---------------------------+\n</code></pre>"},{"location":"architecture/01-title-and-executive-summary/#toolchain-technology-stack","title":"\u2699\ufe0f Toolchain &amp; Technology Stack","text":"Category Tools / Frameworks Language Python 3.11+ Frameworks FastAPI / Flask (API), HTMX / React (UI) ORM / DB SQLModel (SQLite / PostgreSQL) Task Queue Celery / RQ (Redis backend) Caching Redis Testing Pytest + Tox + Coverage CI/CD GitHub Actions + Import-Linter + Ruff + Pyright Packaging Poetry Docs MkDocs + Material theme"},{"location":"architecture/01-title-and-executive-summary/#intended-audience","title":"\ud83e\udde9 Intended Audience","text":"Audience Needs Red-Team / Pentesters Automate repetitive workflows, triage large data, correlate findings. Security Engineers Integrate with CI/CD, enrich findings with vulnerability intelligence. Researchers Extend plugins, add enrichment sources, or create experimental scanners. Developers Contribute to wrappers, tooling, and orchestration improvements."},{"location":"architecture/01-title-and-executive-summary/#guiding-principles","title":"\ud83e\udde0 Guiding Principles","text":"<ol> <li>Automation-First \u2013 Everything that can be automated should be.  </li> <li>Safe by Default \u2013 Every scan runs in isolation, respecting sandbox and audit policies.  </li> <li>Extensible by Design \u2013 Each tool or feature lives as a plugin or wrapper.  </li> <li>Transparent \u2013 Clear data lineage and provenance for every finding.  </li> <li>Declarative Configuration \u2013 Tools and workflows defined in YAML/JSON, not hardcoded logic.  </li> <li>Deterministic Execution \u2013 Same input, same results. All randomness is logged.  </li> </ol>"},{"location":"architecture/01-title-and-executive-summary/#strategic-vision","title":"\ud83d\udd2e Strategic Vision","text":"<p>SecFlow is built not as a single pentest tool, but as a foundation for orchestrated cybersecurity automation. It aims to support: - Scalable enterprise deployments. - Cloud-native workloads (Kubernetes, containerized workers). - AI-driven vulnerability triage. - Integration with bug bounty, CI/CD, and SIEM pipelines.</p> <p>Next: Architecture Philosophy</p>"},{"location":"architecture/02-architecture-philosophy/","title":"02 \u2014 Architecture Philosophy","text":""},{"location":"architecture/02-architecture-philosophy/#overview","title":"\ud83e\udded Overview","text":"<p>SecFlow's architecture follows the Hexagonal Architecture (Ports &amp; Adapters) paradigm, enforcing a clear separation of concerns between business logic, I/O mechanisms, and user interfaces. It is designed for tool orchestration, data normalization, and future AI enrichment \u2014 with extensibility, safety, and testability at its core.</p>"},{"location":"architecture/02-architecture-philosophy/#architectural-tenets","title":"\ud83e\uddf1 Architectural Tenets","text":"Principle Description Hexagonal Isolation All business logic lives in core modules with no framework dependencies. I/O adapters (DB, CLI, API) communicate via interfaces (Ports). Event-Driven Orchestration Workflows operate as Directed Acyclic Graphs (DAGs) executed asynchronously, allowing parallel chaining of tools. Immutable Data Flow Each execution step produces structured, immutable output for auditing and replay. Composable Pipelines Discovery \u2192 Scanning \u2192 Enrichment workflows can be combined declaratively. Strong Typing All data contracts use Pydantic models for type safety and schema validation. Declarative Configuration YAML or JSON defines tools, wordlists, templates, and workflows. Safe Execution Every external tool runs within sandbox boundaries (filesystem + network isolation)."},{"location":"architecture/02-architecture-philosophy/#core-architectural-layers","title":"\u2699\ufe0f Core Architectural Layers","text":"<pre><code>+---------------------------------------------------------------+\n|                    Applications                               |\n|                    Web-API                                   |\n+---------------------------------------------------------------+\n|                    Services Layer                             |\n|                    Workflow Engine                            |\n+---------------------------------------------------------------+\n|                    Core-Lib                                  |\n|                    DTOs                                      |\n+---------------------------------------------------------------+\n|                    Infrastructure                             |\n|                    Database                                   |\n+---------------------------------------------------------------+\n|                    External                                  |\n|                    Tools                                     |\n+---------------------------------------------------------------+\n```python\n\nEach layer exposes **well-defined boundaries**:\n- *Applications* depend only on *Services* through **ports**.\n- *Services* interact with *Core* logic through **domain interfaces**.\n- *Core-Lib* defines **pure domain logic** with zero external imports.\n- *Infrastructure* implements adapters to databases, cache, and external tools.\n\n---\n\n## \ud83e\udde9 Design Goals\n\n| Goal | Implementation Strategy |\n|------|---------------------------|\n| **Maintainability** | Modular mono-repo with strict import boundaries (`import-linter`). |\n| **Scalability** | Async task execution (Celery/RQ) and worker-based orchestration. |\n| **Observability** | Structured logs, Prometheus metrics, and OpenTelemetry tracing. |\n| **Reproducibility** | Deterministic workflows with cached configuration + results. |\n| **Security** | Sandboxed subprocesses, limited file system access, and tokenized configuration. |\n| **Extensibility** | Plugin registry and manifest-based tool definitions. |\n\n---\n\n## \ud83e\udde9 Why Hexagonal Architecture?\n\n| Aspect | Traditional Architecture | SecFlow Approach |\n|--------|--------------------------|------------------|\n| **Dependencies** | Frameworks import core directly | Core is framework-agnostic |\n| **Testing** | Hard to isolate logic | Core modules unit-tested independently |\n| **Tool Integration** | Ad-hoc scripts | Formal wrappers with contracts |\n| **Maintainability** | Spaghetti imports | Controlled boundaries with Import-Linter |\n| **Extensibility** | Static toolset | Plugin &amp; manifest system |\n\n---\n\n## \ud83e\udde9 Component Responsibility Map\n\n| Component | Responsibility |\n|------------|----------------|\n| **Core-Lib** | Defines domain models (`Finding`, `Project`, `Resource`) and interfaces (`ToolPort`, `StoragePort`). |\n| **Findings-Engine** | Normalizes raw scan data into standardized Finding objects. |\n| **Wrappers** | Execute external tools (Nuclei, Ferox, etc.) via manifest-driven configs. |\n| **Worker** | Executes workflows, manages concurrency, caching, and cleanup. |\n| **API** | Exposes endpoints for managing projects, workflows, and triage. |\n| **Triage-UI** | Visual interface for findings review, filtering, and reporting. |\n| **Plugins** | Optional modules extending detection or enrichment logic. |\n| **Resource Registry** | Central management of wordlists, templates, and payloads. |\n\n---\n\n## \ud83e\udde9 Data Flow Model\n\n```text\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u2502  Project   \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Workflow DAG \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 Tool Wrappers    \u2502\u2500\u2500\u2500\u25ba Runs (execution logs)\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 Findings Engine  \u2502\u2500\u2500\u2500\u25ba Findings (normalized)\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 Enrichment Layer \u2502\u2500\u2500\u2500\u25ba CVE/CWE/POC metadata\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 Triage / Metrics \u2502\u2500\u2500\u2500\u25ba Analytics, Dashboards\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/02-architecture-philosophy/#architectural-patterns-used","title":"\ud83e\udde0 Architectural Patterns Used","text":"Pattern Purpose Repository Pattern Abstract data access (DB, file, memory). DTO (Data Transfer Object) Enforce schema boundaries between layers. Command Pattern Workflow node execution commands. Strategy Pattern Dynamic selection of enrichment or parsing strategies. Observer Pattern Metrics and event hooks on scan completion. Decorator Pattern Reusable middleware for retries, timeouts, and auditing."},{"location":"architecture/02-architecture-philosophy/#security-by-design-integration","title":"\ud83d\udd10 Security-by-Design Integration","text":"<p>Every architectural decision includes a security review: - Minimal privilege principle (scoped resource access). - Tokenized secrets (no plaintext credentials). - Environment isolation (Docker/Kubernetes runtime sandboxes). - Mandatory audit trail for findings modification.</p>"},{"location":"architecture/02-architecture-philosophy/#future-proofing-considerations","title":"\ud83e\udde0 Future-Proofing Considerations","text":"<ul> <li>AI Integrations: Workflow outputs use JSON-LD style structures, allowing LLMs to reason over findings safely.  </li> <li>Multi-Tenant Mode: Namespaced projects ensure logical and data isolation.  </li> <li>Plugin Safety: Plugins are signed, versioned, and validated before loading.  </li> <li>Extensible Schema: Findings model allows additional enrichment fields via metadata dicts.</li> </ul> <p>Next: Repository Layout</p>"},{"location":"architecture/03-repository-layout/","title":"03 \u2014 Repository Layout","text":""},{"location":"architecture/03-repository-layout/#overview","title":"\ud83e\udded Overview","text":"<p>The SecFlow repository is structured as a Python mono-repo workspace housing multiple interdependent packages and apps. This allows us to: - Share interfaces and DTOs across services. - Enforce architecture boundaries centrally. - Run unified CI/CD pipelines and dependency resolution through Poetry.</p>"},{"location":"architecture/03-repository-layout/#directory-structure","title":"\ud83e\uddf1 Directory Structure","text":"<pre><code>SecFlow/\n\u251c\u2500\u2500 apps/\n\u2502   \u251c\u2500\u2500 web-api/          # FastAPI service exposing REST &amp; WS endpoints\n\u2502   \u251c\u2500\u2500 worker/           # Background task engine executing workflows\n\u2502   \u251c\u2500\u2500 orchestrator-cli/ # CLI for project operations and tool orchestration\n\u2502   \u251c\u2500\u2500 triage-ui/        # Web dashboard (HTMX/React)\n\u2502   \u2514\u2500\u2500 integrations/     # Optional integrations (CI/CD, Bug bounty, etc.)\n\u2502\n\u251c\u2500\u2500 packages/\n\u2502   \u251c\u2500\u2500 core-lib/         # Domain models, ports, repository contracts\n\u2502   \u251c\u2500\u2500 findings-engine/  # Normalization &amp; enrichment logic\n\u2502   \u251c\u2500\u2500 wrappers/         # Tool wrappers (Nuclei, Ferox, Katana, etc.)\n\u2502   \u251c\u2500\u2500 resources/        # Wordlists, templates, payload registries\n\u2502   \u251c\u2500\u2500 storage/          # Database, cache, and persistence adapters\n\u2502   \u251c\u2500\u2500 plugins/          # Extensible modules for detection/enrichment\n\u2502   \u251c\u2500\u2500 utils/            # Helpers (parsers, validators, caching)\n\u2502   \u2514\u2500\u2500 schemas/          # JSONSchema definitions for validation\n\u2502\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 workflows/\n\u2502   \u2514\u2500\u2500 data/\n\u2502\n\u251c\u2500\u2500 docs/\n\u2502   \u2514\u2500\u2500 architecture/     # This documentation suite\n\u2502\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 bootstrap.sh\n\u2502   \u251c\u2500\u2500 db_migrate.py\n\u2502   \u2514\u2500\u2500 run_tests.sh\n\u2502\n\u251c\u2500\u2500 pyproject.toml        # Poetry configuration\n\u251c\u2500\u2500 tox.ini               # Multi-environment testing\n\u251c\u2500\u2500 importlinter.ini      # Import rules enforcement\n\u251c\u2500\u2500 .github/workflows/ci.yml # CI/CD pipeline\n\u2514\u2500\u2500 README.md\n```yaml\n\n---\n\n## \u2699\ufe0f Python Workspace Configuration\n\n### **`pyproject.toml` Snippet**\n```toml\n[tool.poetry]\nname = \"SecFlow\"\nversion = \"1.0.0\"\ndescription = \"Security Toolkit Orchestration Framework\"\nauthors = [\"Hernan Trajtemberg &lt;hernan.trajtemberg@domain&gt;\"]\n\n[tool.poetry.dependencies]\npython = \"^3.11\"\nfastapi = \"^0.115\"\nsqlmodel = \"^0.0.22\"\ncelery = \"^5.3\"\nredis = \"^5.0\"\npydantic = \"^2.7\"\nimport-linter = \"^1.5\"\nruff = \"^0.7\"\npytest = \"^8.3\"\n\n[tool.poetry.group.dev.dependencies]\npyright = \"*\"\ncoverage = \"*\"\n\n[build-system]\nrequires = [\"poetry-core&gt;=1.6\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```python\n\n## \ud83e\udde9 Application Layering\n\nEach app in `/apps/` uses internal packages exclusively via ports, ensuring loose coupling.\n\n| Layer | Directory | Import Rules |\n|-------|-----------|--------------|\n| **Core** | `packages/core-lib` | No external imports |\n| **Findings Engine** | `packages/findings-engine` | May import core-lib |\n| **Wrappers** | `packages/wrappers` | May import core-lib, utils |\n| **API / Worker** | `apps/web-api`, `apps/worker` | May import via ports only |\n| **Plugins** | `packages/plugins` | Dynamically loaded at runtime |\n\n## \ud83e\udde9 Import-Linter Configuration\n\n`importlinter.ini` enforces import boundaries automatically:\n\n```ini\n[importlinter]\nroot_package = SecFlow\n\n[contract: core-isolation]\nname = Core-Lib Is Independent\ntype = forbidden\nsource_modules = SecFlow.packages.core_lib\nforbidden_modules =\n    SecFlow.apps\n    SecFlow.packages.wrappers\n    SecFlow.packages.findings_engine\n\n[contract: adapters-only]\nname = Adapters Only Depend On Ports\ntype = layers\nlayers =\n    SecFlow.packages.core_lib\n    SecFlow.packages.findings_engine\n    SecFlow.packages.wrappers\n    SecFlow.apps\n```bash\n\nIf violated, the CI pipeline fails the build.\n\n## \ud83e\udde0 Developer Workflow\n\n### Local Development\n```bash\npoetry install\npoetry run pre-commit install\npoetry run pytest\n```yaml\n\n### Run the Worker\n```bash\npoetry run celery -A SecFlow.apps.worker worker --loglevel=info\n```bash\n\n### Run the Web API\n```bash\npoetry run uvicorn SecFlow.apps.web_api.main:app --reload\n```yaml\n\n## \ud83e\udde9 Continuous Integration Pipeline\n\nGitHub Actions (`.github/workflows/ci.yml`):\n\n```yaml\nname: SecFlow CI\non: [push, pull_request]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n      - name: Install dependencies\n        run: |\n          pip install poetry\n          poetry install\n      - name: Lint &amp; Type Check\n        run: |\n          poetry run ruff check .\n          poetry run pyright\n      - name: Run Tests\n        run: poetry run pytest --maxfail=1 --disable-warnings -q\n```yaml\n\n## \ud83e\uddf0 Tooling &amp; Developer Aids\n\n| Tool | Purpose |\n|------|---------|\n| **Ruff** | Linting, formatting enforcement |\n| **Pyright** | Static type checking |\n| **Import-Linter** | Architecture enforcement |\n| **Poetry** | Dependency &amp; build management |\n| **Tox** | Multi-environment testing |\n| **MkDocs** | Documentation site generation |\n| **Coverage.py** | Test coverage reports |\n\n## \ud83e\udde9 ASCII Diagram \u2014 High-Level View\n\n```text\n         +-----------------------------+\n         |          SecFlow/           |\n         +-------------+---------------+\n                       |\n          +------------v-------------+\n          |        packages/         |\n          | core-lib, findings, etc. |\n          +------------+-------------+\n                       |\n          +------------v-------------+\n          |          apps/           |\n          | web-api, worker, cli, ui |\n          +------------+-------------+\n                       |\n          +------------v-------------+\n          |         tests/           |\n          +--------------------------+\n</code></pre>"},{"location":"architecture/03-repository-layout/#future-enhancements","title":"\ud83e\udde0 Future Enhancements","text":"<ul> <li>Monorepo Versioning: Each package versioned via poetry-dynamic-versioning.</li> <li>Documentation Pipeline: Auto-regenerate schema docs (<code>mkdocs build</code>) on merge.</li> <li>Pre-Commit Hooks: Validate imports and enforce ruff formatting pre-push.</li> <li>Code Owners: Assign maintainers per package via <code>.github/CODEOWNERS</code>.</li> </ul> <p>Next: Core Packages &amp; Responsibilities</p>"},{"location":"architecture/04-core-packages-and-responsibilities/","title":"04 \u2014 Core Packages &amp; Responsibilities","text":""},{"location":"architecture/04-core-packages-and-responsibilities/#overview","title":"\ud83e\udded Overview","text":"<p>This document describes the core packages inside the <code>packages/</code> directory and explains the roles, contracts, and relationships that define the heart of SecFlow.</p> <p>The architecture is intentionally hexagonal: - <code>core-lib</code> defines domain models and ports (interfaces). - Other packages such as <code>findings-engine</code>, <code>wrappers</code>, and <code>storage</code> implement those ports. - Application layers (<code>web-api</code>, <code>worker</code>, <code>cli</code>) use the ports but never touch implementations directly.</p>"},{"location":"architecture/04-core-packages-and-responsibilities/#package-overview-table","title":"\ud83e\udde9 Package Overview Table","text":"Package Responsibility Depends On core-lib Domain models, DTOs, Ports, and Service Interfaces. None findings-engine Normalization and enrichment of scan data. <code>core-lib</code> wrappers Executes external tools and parses results. <code>core-lib</code>, <code>utils</code> resources Manages reusable assets (wordlists, payloads, templates). <code>core-lib</code> storage Implements persistence and caching (Postgres, SQLite, Redis). <code>core-lib</code> plugins Houses extension modules (detectors, enrichers, analytics). <code>core-lib</code> utils Generic utilities: logging, validation, subprocess helpers. None"},{"location":"architecture/04-core-packages-and-responsibilities/#core-lib","title":"\u2699\ufe0f Core-Lib","text":""},{"location":"architecture/04-core-packages-and-responsibilities/#purpose","title":"Purpose","text":"<p><code>core-lib</code> is the foundation of SecFlow. It defines all domain entities, type contracts, and abstract interfaces (ports) used throughout the system.</p>"},{"location":"architecture/04-core-packages-and-responsibilities/#structure","title":"Structure","text":"<pre><code>core-lib/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 finding.py\n\u2502   \u251c\u2500\u2500 project.py\n\u2502   \u251c\u2500\u2500 resource.py\n\u2502   \u2514\u2500\u2500 run.py\n\u251c\u2500\u2500 ports/\n\u2502   \u251c\u2500\u2500 storage_port.py\n\u2502   \u251c\u2500\u2500 tool_port.py\n\u2502   \u251c\u2500\u2500 resource_port.py\n\u2502   \u2514\u2500\u2500 findings_port.py\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 workflow_service.py\n\u2502   \u2514\u2500\u2500 triage_service.py\n\u2514\u2500\u2500 exceptions.py\n```python\n\n### Example Model\n```python\n# core-lib/models/finding.py\nfrom pydantic import BaseModel\nfrom datetime import datetime\nfrom typing import List, Optional, Dict\n\nclass Finding(BaseModel):\n    id: str\n    project_id: str\n    detector_id: str\n    title: str\n    severity: str\n    path: str\n    evidence: Dict[str, str]\n    created_at: datetime\n    cwe: Optional[int]\n    owasp: Optional[str]\n    cve_ids: List[str] = []\n    enrichment: Dict[str, any] = {}\n```python\n\n### Example Port\n```python\n# core-lib/ports/tool_port.py\nfrom typing import Protocol, List\nfrom core_lib.models.finding import Finding\n\nclass ToolPort(Protocol):\n    def prepare(self, config: dict) -&gt; None:\n        \"\"\"Prepare the tool with given configuration.\"\"\"\n        pass\n\n    def execute(self) -&gt; List[Finding]:\n        \"\"\"Execute the tool and return findings.\"\"\"\n        pass\n\n    def validate_output(self, raw_output: str) -&gt; bool:\n        \"\"\"Validate tool output format.\"\"\"\n        pass\n```python\n\nThis abstraction allows any external tool to be integrated simply by implementing `ToolPort`.\n\n## \ud83e\udde0 Findings-Engine\n\n### Purpose\nResponsible for normalizing, deduplicating, and enriching findings produced by wrappers.\n\n### Example Normalization Flow\n```python\ndef normalize(raw_data: str, tool: str) -&gt; Finding:\n    if tool == \"nuclei\":\n        return _normalize_nuclei_output(raw_data)\n    elif tool == \"ferox\":\n        return _normalize_ferox_output(raw_data)\n```python\n\n### Capabilities\n- Parse multiple output formats (JSON, XML, plain text).\n- Deduplicate based on fingerprint (host + path + vuln_id).\n- Attach CWE, CVSS, and severity from enrichment sources.\n- Store normalized data through `StoragePort`.\n\n## \u2699\ufe0f Wrappers\n\n### Purpose\nWraps and executes third-party tools through a unified interface defined by `ToolPort`.\n\n### Example Structure\n```text\nwrappers/\n\u251c\u2500\u2500 nuclei_wrapper.py\n\u251c\u2500\u2500 ferox_wrapper.py\n\u251c\u2500\u2500 zap_wrapper.py\n\u2514\u2500\u2500 base_wrapper.py\n```python\n\n### Example Base Class\n```python\n# wrappers/base_wrapper.py\nimport subprocess\nfrom core_lib.models.finding import Finding\n\nclass BaseWrapper:\n    def __init__(self, manifest: dict):\n        self.manifest = manifest\n\n    def run(self, target: str) -&gt; list[Finding]:\n        cmd = [self.manifest[\"binary\"], \"-u\", target]\n        result = subprocess.run(cmd, capture_output=True, text=True)\n        return self.parse_output(result.stdout)\n\n    def parse_output(self, raw: str) -&gt; list[Finding]:\n        raise NotImplementedError\n```python\n\nAll wrappers inherit from `BaseWrapper` and override `parse_output`.\n\n## \ud83d\udce6 Resources\n\n### Purpose\n`resources` manages global and scoped assets:\n- Wordlists (directories, subdomains, parameters)\n- Templates (Nuclei, ZAP)\n- Payload sets\n- Custom configurations\n\n### Example Resource Model\n```python\n# core-lib/models/resource.py\nclass Resource(BaseModel):\n    id: str\n    name: str\n    type: Literal[\"wordlist\", \"template\", \"payload\"]\n    scope: Literal[\"global\", \"group\", \"project\"]\n    hash: str\n    version: str\n    metadata: dict\n```python\n\n## \ud83d\uddc3\ufe0f Storage\n\n### Purpose\nImplements all persistence operations via the `StoragePort` interface.\n\n### Example Interface\n```python\n# core-lib/ports/storage_port.py\nclass StoragePort(Protocol):\n    def save_finding(self, finding: Finding) -&gt; None:\n        \"\"\"Save a finding to storage.\"\"\"\n        pass\n\n    def list_findings(self, project_id: str) -&gt; list[Finding]:\n        \"\"\"List all findings for a project.\"\"\"\n        pass\n\n    def delete_project(self, project_id: str) -&gt; None:\n        \"\"\"Delete a project and all its findings.\"\"\"\n        pass\n```python\n\n### Implementation Examples\n- `SQLiteStorageAdapter`\n- `PostgresStorageAdapter`\n- `RedisCacheAdapter`\n\nAll registered in the `storage.registry`.\n\n## \ud83d\udd0c Plugins\n\n### Purpose\nExtend SecFlow with additional detection or enrichment capabilities.\n\n### Example Plugin Registration\n```python\n# plugins/registry.py\nfrom typing import Dict, Callable\n\nPLUGIN_REGISTRY: Dict[str, Callable] = {}\n\ndef register_plugin(name: str):\n    def decorator(func):\n        PLUGIN_REGISTRY[name] = func\n        return func\n    return decorator\n```yaml\n\nPlugins can dynamically hook into findings processing, orchestration, or resource management.\n\n## \ud83e\uddf0 Utils\n\n`utils` contains helper modules that are shared across packages but contain no business logic.\n\n### Examples:\n- `utils.subprocess_safe` \u2013 wrapper for secure process spawning.\n- `utils.hashing` \u2013 generate resource hashes (SHA256).\n- `utils.validation` \u2013 reusable Pydantic validators.\n- `utils.config` \u2013 environment-aware configuration loader.\n\n## \ud83d\udd17 Cross-Package Interaction Diagram\n\n```text\n+-------------+       +----------------+       +---------------+\n|  Wrappers   | ----&gt; | Findings-Engine| ----&gt; |   Storage     |\n+-------------+       +----------------+       +---------------+\n       |                       ^                       |\n       |                       |                       |\n       v                       |                       v\n   +-----------+        +----------------+        +----------------+\n   | Resources |        |    Core-Lib    |        |    Plugins     |\n   +-----------+        +----------------+        +----------------+\n</code></pre> <p>Arrows represent dependency flow, not import direction (imports always go downward).</p>"},{"location":"architecture/04-core-packages-and-responsibilities/#best-practices","title":"\ud83e\udde0 Best Practices","text":"<ul> <li>Every package must expose a <code>__all__</code> list for stable imports.</li> <li>Each module must define <code>__version__</code> for dependency tracking.</li> <li>No package may import directly from <code>/apps/</code>.</li> <li>Keep adapters stateless; use dependency injection for configuration.</li> <li>Always prefer Pydantic models over raw dictionaries.</li> </ul>"},{"location":"architecture/04-core-packages-and-responsibilities/#testing-guidelines","title":"\ud83e\udde9 Testing Guidelines","text":"Package Test Type Focus core-lib Unit DTO validation and port contracts findings-engine Integration Normalization and enrichment correctness wrappers System Command execution, parsing accuracy storage Integration CRUD consistency across backends plugins Unit Hook execution and registry behavior"},{"location":"architecture/04-core-packages-and-responsibilities/#future-enhancements","title":"\ud83e\udde0 Future Enhancements","text":"<ul> <li>Introduce a service layer in <code>core-lib</code> to coordinate between repositories and orchestrators.</li> <li>Implement schema diffing for <code>findings-engine</code> to detect breaking changes.</li> <li>Add async wrappers for high-performance tools (e.g., Katana via aiohttp).</li> <li>Build auto-generated docs from port signatures (<code>mkdocs-gen-files</code>).</li> </ul> <p>Next: Orchestration &amp; Workflow Engine</p>"},{"location":"architecture/05-orchestration-and-workflow-engine/","title":"05 \u2014 Orchestration &amp; Workflow Engine","text":""},{"location":"architecture/05-orchestration-and-workflow-engine/#overview","title":"\ud83e\udded Overview","text":"<p>The Orchestration Engine is the operational core of SecFlow. It executes multi-tool workflows composed of discovery, scanning, filtering, enrichment, and analysis stages.</p> <p>Workflows are defined declaratively using YAML recipes and executed as Directed Acyclic Graphs (DAGs). Each node represents a tool invocation, and edges define data flow between outputs and inputs.</p>"},{"location":"architecture/05-orchestration-and-workflow-engine/#conceptual-model","title":"\ud83e\uddf1 Conceptual Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Workflow DAG                           \u2502\n\u2502                                                            \u2502\n\u2502  +---------+    +------------+    +-----------+           \u2502\n\u2502  | Node A  |---&gt;|   Node B   |---&gt;|   Node C  |           \u2502\n\u2502  | (Ferox) |    | (Nuclei)   |    | (CVE Enr)|           \u2502\n\u2502  +---------+    +------------+    +-----------+           \u2502\n\u2502      |              |              |                     \u2502\n\u2502      |              |              |                     \u2502\n\u2502  Inputs/Outputs  Config/Env    Artifact Storage          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```yaml\n\nEach node produces one or more datasets that can be consumed by downstream nodes.  \nThe workflow engine guarantees:\n- Topological order of execution  \n- Concurrent execution where possible  \n- Automatic retries, timeouts, and logging per node  \n\n---\n\n## \u2699\ufe0f Workflow Specification Schema\n\n```yaml\nversion: \"1.0\"\nname: \"OWASP Top 10 Scan\"\ndescription: \"End-to-end test: discovery \u2192 scan \u2192 enrichment\"\n\nnodes:\n  - id: \"discovery\"\n    type: \"discovery.ferox\"\n    config:\n      wordlist: \"res://wordlists/dirb:latest\"\n      threads: 50\n    outputs: [\"urls\"]\n\n  - id: \"scan\"\n    type: \"scan.nuclei\"\n    inputs: [\"urls\"]\n    config:\n      templates: \"res://templates/owasp-top10:latest\"\n      rate_limit: 150\n    outputs: [\"findings\"]\n\n  - id: \"enrich\"\n    type: \"enrich.cve\"\n    inputs: [\"findings\"]\n    config:\n      sources: [\"nvd\", \"osv\", \"exploitdb\"]\n    outputs: [\"enriched_findings\"]\n```text\n\n## \ud83e\udde9 Workflow Engine Architecture\n\n```text\n+-------------------------------------------------------------+\n|                         Worker Engine                       |\n|-------------------------------------------------------------|\n| - WorkflowScheduler                                          |\n| - NodeExecutor                                               |\n| - ResultCache                                                |\n| - EventBus                                                   |\n|-------------------------------------------------------------|\n| Uses: Celery (Redis), asyncio, Pydantic validation           |\n+-------------------------------------------------------------+\n```text\n\n### Key Components\n\n| Component | Description |\n|-----------|-------------|\n| **WorkflowScheduler** | Parses YAML recipes, builds DAG, submits jobs to queue. |\n| **NodeExecutor** | Executes nodes, manages subprocess wrappers. |\n| **ResultCache** | Stores intermediate results between nodes. |\n| **EventBus** | Publishes events (node_started, node_completed, workflow_failed). |\n| **WorkflowStore** | Persists workflow metadata in DB. |\n\n## \u2699\ufe0f Python Model \u2014 DAG Representation\n\n```python\n# findings-engine/workflow_dag.py\nfrom typing import List, Dict, Any\nfrom pydantic import BaseModel\n\nclass Node(BaseModel):\n    id: str\n    type: str\n    config: Dict[str, Any] = {}\n    inputs: List[str] = []\n    outputs: List[str] = []\n\nclass Workflow(BaseModel):\n    id: str\n    name: str\n    description: str\n    nodes: List[Node]\n```text\n\n### DAG Validation Example\n```python\ndef validate_dag(workflow: Workflow):\n    ids = [n.id for n in workflow.nodes]\n    for node in workflow.nodes:\n        for inp in node.inputs:\n            if inp not in [out for n in workflow.nodes for out in n.outputs]:\n                raise ValueError(f\"Unresolved input '{inp}' in node {node.id}\")\n```python\n\n## \ud83e\udde0 Execution Flow\n\n1. Parse &amp; Validate YAML workflow using Pydantic schema.\n2. Register DAG in database (`WorkflowStore`).\n3. Submit nodes to Celery/RQ queue respecting topological order.\n4. Execute wrappers through `ToolPort` interface.\n5. Normalize findings via `FindingsEngine`.\n6. Publish events to `EventBus`.\n7. Update metrics and trigger downstream listeners (e.g., triage UI).\n\n## \u2699\ufe0f Node Executor (Simplified)\n\n```python\n# worker/executor.py\nfrom core_lib.ports.tool_port import ToolPort\n\nclass NodeExecutor:\n    def __init__(self, node, context):\n        self.node = node\n        self.context = context\n\n    def run(self):\n        tool: ToolPort = self.context.resolve_tool(self.node.type)\n        tool.prepare(self.node.config)\n        results = tool.execute()\n        self.context.store_results(self.node.outputs, results)\n        return results\n```python\n\n## \ud83d\udd04 Concurrency Model\n\nThe orchestration engine is designed for asynchronous, multi-tool execution.\n\n| Execution Mode | Description |\n|----------------|-------------|\n| **Sequential** | Enforced by DAG dependencies. |\n| **Parallel** | Independent nodes run concurrently (async or Celery workers). |\n| **Chained** | Output from one node auto-feeds into next via `ResultCache`. |\n\n### Example\n```text\n[ferox] \u2500\u2500\u25b6 [katana] \u2500\u2500\u25b6 [nuclei]\n  \u2502                         \u25b2\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 [httpx] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```python\n\n## \ud83e\udde9 Error Handling\n\n| Error Type | Handling Strategy |\n|------------|-------------------|\n| Tool crash / non-zero exit | Retry (max=3) then mark node failed. |\n| Timeout | Kill process, log event, continue DAG. |\n| Missing input dataset | Block downstream nodes, mark dependency unresolved. |\n| Parser error | Log raw output, fallback to generic findings schema. |\n\nEach failure is logged in the `workflow_runs` table and visible in the UI.\n\n## \ud83e\udde0 Event System\n\nThe orchestration layer publishes real-time events to facilitate reactive behavior.\n\n### Example Event Contract\n```json\n{\n  \"event\": \"node_completed\",\n  \"workflow_id\": \"abc123\",\n  \"node_id\": \"scan\",\n  \"duration\": 12.3,\n  \"findings\": 124\n}\n```python\n\nEvents can be consumed by:\n- WebSocket clients in UI (live progress)\n- Audit log processors\n- Metrics collectors\n\n## \ud83e\udde9 Caching &amp; Reuse\n\n- **Intermediate Data:** Stored under `/cache/{workflow_id}/{node_id}.json`\n- **ResultHashing:** SHA256 of config + inputs for cache hits\n- **Warm Runs:** Workflows can resume from cached intermediate outputs\n\n```python\ncache_key = hashlib.sha256(json.dumps(node.config).encode()).hexdigest()\n```text\n\n## \ud83e\uddf1 Example DAG Execution Trace\n\n```text\n[2025-10-06 12:01:02] Workflow \"OWASP Top 10 Scan\" started\n[2025-10-06 12:01:05] Node discovery.ferox completed (urls=356)\n[2025-10-06 12:01:07] Node scan.nuclei completed (findings=112)\n[2025-10-06 12:01:10] Node enrich.cve completed (enriched_findings=112)\n[2025-10-06 12:01:10] Workflow completed successfully\n</code></pre>"},{"location":"architecture/05-orchestration-and-workflow-engine/#integration-with-other-components","title":"\ud83d\udd0c Integration with Other Components","text":"Component Interaction Findings Engine Receives raw output for normalization. Wrappers Execute the underlying binaries/tools. Storage Persists workflow runs, logs, results. Plugins Hooks into <code>on_node_complete</code> and <code>on_workflow_complete</code>. UI / API Subscribes to event bus for progress updates."},{"location":"architecture/05-orchestration-and-workflow-engine/#monitoring-metrics","title":"\ud83e\udde9 Monitoring &amp; Metrics","text":"<p>Every node execution reports: - Duration (seconds) - Findings count - Exit status - CPU/memory usage - Cache hits</p> <p>These metrics feed Prometheus exporters and the analytics dashboards.</p>"},{"location":"architecture/05-orchestration-and-workflow-engine/#future-enhancements","title":"\ud83e\udde0 Future Enhancements","text":"<ul> <li>GraphQL-based workflow builder UI.</li> <li>Dynamic scheduling policies (priority, resource weighting).</li> <li>Conditional branching (if, switch nodes).</li> <li>AI-assisted workflow suggestions based on context and prior runs.</li> <li>Distributed orchestration using Celery groups/chords.</li> </ul> <p>Next: Plugin System</p>"},{"location":"architecture/06-plugin-system/","title":"06 \u2014 Plugin System","text":""},{"location":"architecture/06-plugin-system/#overview","title":"\ud83e\udded Overview","text":"<p>The Plugin System in SecFlow provides an extensible runtime for integrating new detection, enrichment, or analytics capabilities without modifying core code. Plugins operate under a controlled lifecycle and interact through strictly defined contracts (ports).</p> <p>SecFlow supports three primary plugin categories: 1. Detectors \u2014 Introduce new scanning logic or post-processing steps. 2. Enrichers \u2014 Add vulnerability metadata (CVE, CWE, CVSS, etc.). 3. Analytics \u2014 Compute metrics, patterns, or visual insights over findings.</p>"},{"location":"architecture/06-plugin-system/#design-principles","title":"\ud83e\udde9 Design Principles","text":"Principle Description Isolation Each plugin runs in its own context (thread/process sandbox). Declarative Registration Plugins register via manifests or decorators. Contract Enforcement Plugins implement strict base interfaces (<code>PluginBase</code>, <code>DetectorPlugin</code>, etc.). Hot Reloading Plugin discovery occurs dynamically at startup. Safety Each plugin is validated, hashed, and versioned."},{"location":"architecture/06-plugin-system/#plugin-architecture-overview","title":"\ud83e\uddf1 Plugin Architecture Overview","text":"<pre><code>+-------------------------------------------------------------+\n|                    Plugin Manager                           |\n| - Registry                                                  |\n| - Loader                                                    |\n| - Validator                                                 |\n| - Sandbox                                                   |\n+-------------------------------------------------------------+\n     |                |                  |\n     |                |                  |\n     \u25bc                \u25bc                  \u25bc\n+----------+    +-------------+    +-------------+\n|Detector  |    | Enricher    |    | Analytics   |\n|Plugins   |    | Plugins     |    | Plugins     |\n+----------+    +-------------+    +-------------+\n```text\n\n---\n\n## \u2699\ufe0f Base Interfaces\n\n```python\n# core-lib/ports/plugin_port.py\nfrom typing import Protocol, Any, Dict\n\nclass PluginPort(Protocol):\n    name: str\n    version: str\n    category: str  # \"detector\" | \"enricher\" | \"analytics\"\n\n    def initialize(self, context: Dict[str, Any]) -&gt; None:\n        \"\"\"Initialize plugin with execution context.\"\"\"\n        pass\n\n    def execute(self, data: Any) -&gt; Any:\n        \"\"\"Execute plugin logic on input data.\"\"\"\n        pass\n\n    def teardown(self) -&gt; None:\n        \"\"\"Clean up plugin resources.\"\"\"\n        pass\n```python\n\nAll plugins must subclass or conform to `PluginPort`.\n\n## \ud83e\udde9 Example Plugin Registry\n\n```python\n# plugins/registry.py\nfrom typing import Dict, Type\nfrom core_lib.ports.plugin_port import PluginPort\n\nclass PluginRegistry:\n    _registry: Dict[str, Type[PluginPort]] = {}\n\n    @classmethod\n    def register(cls, name: str, plugin: Type[PluginPort]):\n        cls._registry[name] = plugin\n        print(f\"[+] Registered plugin: {name}\")\n\n    @classmethod\n    def get(cls, name: str) -&gt; PluginPort:\n        return cls._registry[name]\n\n    @classmethod\n    def list_plugins(cls):\n        return list(cls._registry.keys())\n```python\n\n### Registration via Decorator\n```python\ndef register_plugin(name: str):\n    def decorator(cls):\n        PluginRegistry.register(name, cls)\n        return cls\n    return decorator\n```python\n\n## \ud83e\udde0 Plugin Lifecycle\n\n1. **Registration:** Discovered from manifests or decorators.\n2. **Validation:** Signature &amp; schema verification.\n3. **Initialization:** Context injected (paths, project ID, config).\n4. **Execution:** Process data via `execute()`.\n5. **Teardown:** Release resources, log metrics.\n\n## \ud83e\udde9 Plugin Manifest Specification\n\n```yaml\nname: nuclei-enricher\nversion: \"1.0.0\"\ncategory: \"enricher\"\nentrypoint: \"plugins.nuclei_enricher:Enricher\"\ndependencies:\n  - requests\n  - cpe\nconfig_schema: \"schemas/nuclei_enricher.json\"\nsandbox: true\n```python\n\nEach manifest is stored under `/plugins/manifests/` and validated on startup.\n\n## \u2699\ufe0f Example \u2014 CVE Enricher Plugin\n\n```python\n# plugins/nuclei_enricher.py\nimport requests\nfrom core_lib.models.finding import Finding\nfrom core_lib.ports.plugin_port import PluginPort\n\n@register_plugin(\"cve_enricher\")\nclass CVEEnricher(PluginPort):\n    name = \"cve_enricher\"\n    version = \"1.0.0\"\n    category = \"enricher\"\n\n    def initialize(self, context):\n        self.sources = context.get(\"sources\", [\"nvd\"])\n\n    def execute(self, finding: Finding) -&gt; Finding:\n        for cve_id in finding.cve_ids:\n            data = self._fetch_cve_data(cve_id)\n            finding.enrichment[\"cve\"][cve_id] = data\n        return finding\n\n    def _fetch_cve_data(self, cve_id):\n        return requests.get(f\"https://services.nvd.nist.gov/rest/json/cve/1.0/{cve_id}\").json()\n\n    def teardown(self):\n        pass\n```yaml\n\n## \ud83d\udd10 Sandbox Model\n\nEach plugin executes inside a restricted environment:\n\n| Control | Enforcement |\n|---------|-------------|\n| **Filesystem** | Read-only mount or temp directory |\n| **Network** | Denied by default, opt-in per manifest |\n| **Memory / CPU** | Controlled via subprocess resource limits |\n| **Timeouts** | Enforced via execution wrapper |\n| **Audit** | Every plugin invocation logged with context |\n\n## \ud83e\udde9 Plugin Discovery\n\n### Directory Layout\n```python\nplugins/\n\u251c\u2500\u2500 registry.py\n\u251c\u2500\u2500 manifests/\n\u2502   \u251c\u2500\u2500 cve_enricher.yaml\n\u2502   \u2514\u2500\u2500 nuclei_detector.yaml\n\u2514\u2500\u2500 detectors/\n    \u251c\u2500\u2500 nuclei_detector.py\n    \u2514\u2500\u2500 zap_detector.py\n```python\n\n### Discovery Algorithm\n```python\ndef discover_plugins():\n    for manifest in Path(\"plugins/manifests\").glob(\"*.yaml\"):\n        data = yaml.safe_load(manifest.read_text())\n        entrypoint = import_string(data[\"entrypoint\"])\n        PluginRegistry.register(data[\"name\"], entrypoint)\n```python\n\n## \ud83e\udde0 Plugin Telemetry\n\nEach plugin emits lifecycle events:\n\n```json\n{\n  \"event\": \"plugin_executed\",\n  \"plugin\": \"cve_enricher\",\n  \"duration_ms\": 342,\n  \"memory_mb\": 42,\n  \"success\": true\n}\n```json\n\nTelemetry is captured by the Observability subsystem (see [Observability, Logging &amp; Metrics](17-observability-logging-and-metrics.md)).\n\n## \ud83e\udde9 Error Handling\n\n| Error | Strategy |\n|-------|----------|\n| Invalid Manifest | Skip plugin, log warning. |\n| Dependency ImportError | Attempt isolated install if allowed. |\n| Execution Timeout | Abort plugin, mark node partial-success. |\n| Sandbox Violation | Terminate process, revoke plugin signature. |\n\n## \ud83e\udde0 Example End-to-End Plugin Flow\n\n```text\n[Plugin Manifest] \u2192 [Registry Register] \u2192 [Initialize] \n      \u2193                       \u2193                   \u2193\n [Execute via Port] \u2192 [Telemetry + Logging] \u2192 [Teardown]\n</code></pre>"},{"location":"architecture/06-plugin-system/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Plugin signing (PGP signatures).</li> <li>Remote plugin repository (index + version resolution).</li> <li>In-UI plugin store with validation and ratings.</li> <li>Plugin telemetry aggregation dashboards.</li> </ul> <p>Next: Tools Integration Model</p>"},{"location":"architecture/07-tools-integration-model/","title":"07 \u2014 Tools Integration Model","text":""},{"location":"architecture/07-tools-integration-model/#overview","title":"\ud83e\udded Overview","text":"<p>The Tools Integration Model defines how external security tools (Nuclei, Feroxbuster, Katana, ZAP, Caido, etc.) are integrated and orchestrated inside SecFlow.</p> <p>The system is manifest-driven, allowing tools to be defined declaratively, executed in isolation, and chained dynamically via the Workflow Engine.</p> <p>Each integrated tool is represented as: - A manifest (describes binary, configuration, security policies, I/O schema) - A wrapper (implements the standardized execution interface) - An optional adapter plugin (translates output to normalized Findings)</p>"},{"location":"architecture/07-tools-integration-model/#architectural-overview","title":"\ud83e\uddf1 Architectural Overview","text":"<pre><code>+--------------------------+\n|     Tool Manager          |\n| - Tool Registry           |\n| - Manifest Validator      |\n| - Sandbox Executor        |\n| - Output Parser           |\n+-----------\u252c---------------+\n            |\n            \u25bc\n+---------------------+\n| Tool Wrapper        |\n| (e.g., Nuclei)      |\n+---------------------+\n            |\n            \u25bc\n+---------------------+\n| Tool Output Parser  |\n+---------------------+\n            |\n            \u25bc\n+---------------------+\n| Findings Engine     |\n+---------------------+\n```python\n\n---\n\n## \u2699\ufe0f Tool Manifest Structure\n\nEvery tool integrated into SecFlow must define a **manifest** under `/wrappers/manifests/&lt;tool&gt;.json`.\n\n### Example: `nuclei.json`\n```json\n{\n  \"name\": \"nuclei\",\n  \"version\": \"3.2.1\",\n  \"binary\": \"nuclei\",\n  \"capabilities\": [\"scan\"],\n  \"outputs\": {\"dataset\": \"findings\"},\n  \"defaults\": {\n    \"threads\": 25,\n    \"rate_limit\": 150,\n    \"templates\": \"res://templates/nuclei:latest\"\n  },\n  \"configSchema\": \"schemas/nuclei-config.json\",\n  \"resource_requirements\": {\n    \"cpu_cores\": 2,\n    \"memory_mb\": 512,\n    \"timeout_seconds\": 300\n  },\n  \"security\": {\n    \"sandbox\": true,\n    \"network_access\": true,\n    \"file_system_access\": \"read_only\"\n  },\n  \"selftest\": {\n    \"args\": [\"-version\"],\n    \"expect\": \"Nuclei\"\n  }\n}\n```python\n\n## \ud83e\udde9 Wrapper Interface\n\nAll tool wrappers implement the same contract to ensure consistent orchestration.\n\n```python\n# core-lib/ports/tool_port.py\nfrom typing import Any, Dict, Protocol, List\nfrom core_lib.models.finding import Finding\n\nclass ToolPort(Protocol):\n    def prepare(self, config: Dict[str, Any]) -&gt; None:\n        \"\"\"Prepare tool with configuration.\"\"\"\n        pass\n\n    def run(self) -&gt; str:\n        \"\"\"Execute tool and return raw output.\"\"\"\n        pass\n\n    def parse_output(self, raw_output: str) -&gt; List[Finding]:\n        \"\"\"Parse raw output into structured findings.\"\"\"\n        pass\n```python\n\n## \ud83e\udde0 Example Implementation: Nuclei Wrapper\n\n```python\n# wrappers/nuclei_wrapper.py\nimport subprocess, json\nfrom core_lib.models.finding import Finding\nfrom core_lib.ports.tool_port import ToolPort\n\nclass NucleiWrapper(ToolPort):\n    def __init__(self, config):\n        self.config = config\n\n    def prepare(self, config):\n        self.args = [\n            \"nuclei\", \"-json\",\n            \"-t\", config.get(\"templates\", \"res://templates/nuclei:latest\"),\n            \"-rl\", str(config.get(\"rate_limit\", 150)),\n            \"-c\", str(config.get(\"threads\", 25))\n        ]\n\n    def run(self):\n        result = subprocess.run(self.args, capture_output=True, text=True, timeout=300)\n        return result.stdout\n\n    def parse_output(self, raw_output):\n        findings = []\n        for line in raw_output.splitlines():\n            try:\n                data = json.loads(line)\n                findings.append(\n                    Finding(\n                        title=data[\"info\"][\"name\"],\n                        severity=data[\"info\"][\"severity\"],\n                        path=data[\"matched-at\"],\n                        detector_id=\"nuclei\",\n                        evidence=data\n                    )\n                )\n            except Exception:\n                continue\n        return findings\n```python\n\n## \ud83d\udd10 Sandbox Execution\n\nTools run through a Sandbox Executor, enforcing CPU, memory, and network constraints.\n\n```python\n# wrappers/executor.py\nimport resource, subprocess, signal\n\nclass SandboxExecutor:\n    def __init__(self, cpu_limit=2, mem_limit_mb=512):\n        self.cpu_limit = cpu_limit\n        self.mem_limit_mb = mem_limit_mb\n\n    def execute(self, args):\n        def set_limits():\n            resource.setrlimit(resource.RLIMIT_CPU, (self.cpu_limit, self.cpu_limit))\n            resource.setrlimit(resource.RLIMIT_AS, (self.mem_limit_mb * 1024**2,) * 2)\n\n        proc = subprocess.Popen(args, preexec_fn=set_limits, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = proc.communicate(timeout=300)\n        return stdout.decode(), stderr.decode(), proc.returncode\n```python\n\n## \ud83e\udde9 Tool Registry\n\n```python\n# wrappers/registry.py\nfrom typing import Dict, Type\nfrom core_lib.ports.tool_port import ToolPort\n\nclass ToolRegistry:\n    _registry: Dict[str, Type[ToolPort]] = {}\n\n    @classmethod\n    def register(cls, name: str, impl: Type[ToolPort]):\n        cls._registry[name] = impl\n        print(f\"[+] Registered tool: {name}\")\n\n    @classmethod\n    def get(cls, name: str) -&gt; ToolPort:\n        return cls._registry[name]\n```python\n\nTools register via decorators or discovery:\n\n```python\nfrom wrappers.registry import ToolRegistry\n\n@ToolRegistry.register(\"feroxbuster\")\nclass FeroxWrapper(ToolPort):\n    def prepare(self, config: Dict[str, Any]) -&gt; None:\n        self.wordlist = config.get(\"wordlist\", \"res://wordlists/dirb:latest\")\n        self.threads = config.get(\"threads\", 50)\n\n    def run(self) -&gt; str:\n        cmd = [\"feroxbuster\", \"-u\", self.target, \"-w\", self.wordlist, \"-t\", str(self.threads)]\n        result = subprocess.run(cmd, capture_output=True, text=True)\n        return result.stdout\n\n    def parse_output(self, raw_output: str) -&gt; List[Finding]:\n        findings = []\n        for line in raw_output.split('\\n'):\n            if line.strip() and not line.startswith('#'):\n                findings.append(Finding(\n                    id=f\"ferox_{hash(line)}\",\n                    url=line.strip(),\n                    tool=\"feroxbuster\",\n                    severity=\"info\"\n                ))\n        return findings\n```python\n\n## \ud83e\udde0 Example Integration \u2014 Feroxbuster\n\n```python\n# wrappers/ferox_wrapper.py\nimport subprocess\nfrom core_lib.models.finding import Finding\n\nclass FeroxWrapper(ToolPort):\n    def prepare(self, config):\n        self.target = config[\"target\"]\n        self.wordlist = config.get(\"wordlist\", \"/usr/share/wordlists/dirb/common.txt\")\n        self.args = [\"feroxbuster\", \"-u\", self.target, \"-w\", self.wordlist, \"-o\", \"-\"]\n\n    def run(self):\n        result = subprocess.run(self.args, capture_output=True, text=True)\n        return result.stdout\n\n    def parse_output(self, raw):\n        findings = []\n        for line in raw.splitlines():\n            if \"200\" in line or \"301\" in line:\n                findings.append(\n                    Finding(\n                        title=\"Discovered Path\",\n                        severity=\"info\",\n                        path=line.split()[0],\n                        detector_id=\"feroxbuster\"\n                    )\n                )\n        return findings\n```text\n\n## \ud83e\udde9 Tool Orchestration\n\nThe Workflow Engine dynamically chains tool executions:\n- Each node defines a tool (by name), configuration, and expected outputs.\n- Outputs become inputs for subsequent nodes.\n\n### Example:\n```yaml\nnodes:\n  - id: discovery\n    type: discovery.ferox\n    config:\n      wordlist: res://wordlists/dirb:latest\n    outputs: [\"urls\"]\n\n  - id: scan\n    type: scan.nuclei\n    inputs: [\"urls\"]\n    outputs: [\"findings\"]\n</code></pre>"},{"location":"architecture/07-tools-integration-model/#tool-output-normalization","title":"\ud83e\udde0 Tool Output Normalization","text":"<p>All tool outputs are normalized into the Finding schema before storage.</p> Field Description detector_id Tool name (e.g., nuclei, zap) title Human-readable description path Target or endpoint severity Normalized (critical/high/medium/low/info) evidence Raw tool output created_at UTC timestamp provenance Manifest + execution context"},{"location":"architecture/07-tools-integration-model/#error-handling","title":"\ud83e\udde9 Error Handling","text":"Condition Behavior Tool binary missing Raise <code>ToolNotFoundError</code> Sandbox violation Terminate subprocess Timeout Abort execution, mark partial-success Parse failure Skip line, log warning Non-zero exit code Log and attach stderr to run context"},{"location":"architecture/07-tools-integration-model/#future-extensions","title":"\ud83d\udd2e Future Extensions","text":"<ul> <li>Interactive tool chaining (UI-based pipeline builder)</li> <li>Tool profiles for project-specific setups</li> <li>Remote execution agents (distributed scanning)</li> <li>Version-aware compatibility checks</li> <li>Auto-updating manifests (self-test validation)</li> </ul> <p>Next: Tool Manager &amp; User Experience Design</p>"},{"location":"architecture/08-tool-manager-and-ux-design/","title":"08 \u2014 Tool Manager &amp; User Experience Design","text":""},{"location":"architecture/08-tool-manager-and-ux-design/#overview","title":"\ud83e\udded Overview","text":"<p>The Tool Manager serves as the central orchestration and configuration interface for all integrated tools (Nuclei, Feroxbuster, Katana, ZAP, Caido, etc.). It acts as the human-facing control plane that bridges declarative configuration, project-level defaults, and the automated orchestration engine.</p> <p>The UX design ensures that both CLI users and UI users can: - Install or enable tools dynamically. - Configure tool parameters or use defaults. - Chain tools together (e.g., Ferox \u2192 Katana \u2192 Nuclei). - Reuse shared wordlists, payloads, and templates. - View and modify execution pipelines visually or textually.</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#architecture-overview","title":"\ud83e\udde9 Architecture Overview","text":"<p><code>text +------------------------------------------------------+ |                    Tool Manager                      | | - Tool Registry (runtime manifest cache)             | | - Config Editor (CLI + UI layer)                    | | - Execution Controller (worker interface)           | | - Output Collector (findings normalization)         | +------------------------\u252c-----------------------------+                          |                          \u25bc            +---------------------+            | Tool Wrappers Layer |            +---------------------+                          |                          \u25bc            +---------------------+            | Findings Engine     |            +---------------------+</code>text</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#tool-manager-responsibilities","title":"\u2699\ufe0f Tool Manager Responsibilities","text":"Subsystem Responsibility Registry Keeps in-memory registry of available tools with metadata. Configurator Provides unified interface for tool configuration &amp; validation. Executor Handles actual subprocess calls via <code>SandboxExecutor</code>. Cache Layer Stores tool state, results, and logs for replay. Renderer Generates UI/CLI views for configuration and results."},{"location":"architecture/08-tool-manager-and-ux-design/#ux-goals","title":"\ud83e\uddf1 UX Goals","text":"Goal Description Low Friction User can run default scans without prior configuration. Transparency Full visibility into command-line arguments, logs, and results. Reusability Configurations and results can be reused across projects. Isolation Each project may have independent or shared tool setups. Extensibility Easy to add new tools through manifests."},{"location":"architecture/08-tool-manager-and-ux-design/#cli-experience","title":"\ud83e\udde0 CLI Experience","text":""},{"location":"architecture/08-tool-manager-and-ux-design/#example-commands","title":"Example Commands","text":"<p>```bash</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#list-available-tools","title":"List available tools","text":"<p>SecFlow tools list</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#enable-feroxbuster-nuclei","title":"Enable Feroxbuster &amp; Nuclei","text":"<p>SecFlow tools enable feroxbuster nuclei</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#configure-a-tool","title":"Configure a tool","text":"<p>SecFlow tools config nuclei --threads 50 --templates owasp-top10</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#run-workflow-interactively","title":"Run workflow interactively","text":"<p>SecFlow run workflow.yaml</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#chain-tools-manually","title":"Chain tools manually","text":"<p>SecFlow run feroxbuster --target https://example.com | SecFlow run nuclei ```text</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#cli-ux-principles","title":"CLI UX Principles","text":"<ul> <li>YAML/JSON inputs mirror internal manifests.</li> <li>All commands are idempotent \u2014 re-runs use cached configurations.</li> <li>CLI supports both single-tool and multi-node workflow modes.</li> </ul>"},{"location":"architecture/08-tool-manager-and-ux-design/#web-ui-experience","title":"\ud83e\udde0 Web UI Experience","text":""},{"location":"architecture/08-tool-manager-and-ux-design/#visual-overview","title":"Visual Overview","text":"<p><code>text +---------------------------------------------------------+ | Project: Acme Web API                                   | |---------------------------------------------------------| | [Tools Panel] [Workflow Builder] [Execution Log] [Results] | +---------------------------------------------------------+</code>text</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#key-panels","title":"Key Panels","text":"Panel Description Tools Panel Shows installed tools, version, manifest, health check. Workflow Builder Drag-and-drop DAG composer (Ferox \u2192 Katana \u2192 Nuclei). Execution Log Real-time stdout/stderr stream with structured logging. Results Viewer Interactive findings dashboard, linked to triage view."},{"location":"architecture/08-tool-manager-and-ux-design/#example-workflow-builder-nodes","title":"Example Workflow Builder Nodes","text":"<p><code>bash \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Feroxbuster  \u2502\u2500\u2500\u2500\u25b6 \u2502 Katana       \u2502\u2500\u2500\u2500\u25b6 \u2502 Nuclei       \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   (Discovery)          (Crawler)            (Scanner)</code>bash</p> <p>Users can: - Configure node properties via sidebar. - Save and export workflows as YAML (<code>workflow-recipe.yaml</code>). - Re-run saved workflows directly or modify them visually.</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#configuration-persistence","title":"\ud83e\udde9 Configuration Persistence","text":"<p>Each tool has a persistent JSON/YAML config stored under:</p> <p><code>text ~/.SecFlow/config/tools/&lt;tool&gt;.yaml</code>text</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#example","title":"Example","text":"<p><code>yaml version: \"1.0\" defaults:   threads: 25   rate_limit: 150   templates: res://templates/nuclei:latest profiles:   aggressive:     rate_limit: 300   safe:     rate_limit: 50     sandbox: true</code>text</p> <p>Profiles allow contextual configurations (e.g., \"aggressive\", \"safe\").</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#tool-chaining-runtime","title":"\ud83d\udd17 Tool Chaining (Runtime)","text":"<p>Tool chaining uses the Workflow Engine, but users can also trigger ad-hoc sequences. Each output dataset is normalized as JSON Lines, allowing flexible piping.</p> <p><code>bash SecFlow run feroxbuster --target https://app.local \\ | SecFlow run katana --stdin \\ | SecFlow run nuclei --stdin</code>text</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#data-interoperability","title":"Data interoperability:","text":"<p>Each tool must produce output in a structured JSON format with required fields:</p> <p><code>json {   \"url\": \"https://example.com/login\",   \"status\": 200,   \"source\": \"feroxbuster\" }</code>python</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#default-configurations-templates","title":"\ud83e\udde9 Default Configurations &amp; Templates","text":"<p>When the user installs SecFlow: - Default manifests are loaded from <code>/resources/defaults/</code> - All core tools (Nuclei, Ferox, Katana) have pre-configured templates. - The user can immediately run scans without extra setup.</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#example-command","title":"Example command:","text":"<p><code>bash SecFlow quickscan https://example.com</code>python</p> <p>Equivalent to: - Workflow: Ferox \u2192 Nuclei (OWASP templates)</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#advanced-features","title":"\ud83e\udde0 Advanced Features","text":"Feature Description Auto-Discovery Detects installed binaries and populates manifest registry automatically. Tool Self-Test Validates binary presence and functionality via manifest-defined tests. Runtime Profiles Switch between safe/aggressive scanning modes. Execution History Stores past runs and parameters for reproducibility."},{"location":"architecture/08-tool-manager-and-ux-design/#user-permissions","title":"\ud83d\udd10 User Permissions","text":"<p>Tool Manager respects project and role isolation:</p> Role Capabilities Admin Install, configure, delete tools. Analyst Execute workflows, view logs, triage findings. Viewer Read-only access to results. <p>All actions are logged to the Audit Log.</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#integration-with-resource-registry","title":"\ud83e\uddf1 Integration with Resource Registry","text":"<p>The Tool Manager automatically pulls shared wordlists, templates, or payloads from the Resource Registry (see 09-resource-registry.md).</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#example_1","title":"Example:","text":"<p><code>yaml wordlist: res://wordlists/dirb:latest templates: res://templates/nuclei:latest</code>ini</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#error-recovery-ux","title":"\ud83e\udde9 Error Recovery UX","text":"<p>If a tool fails: - The UI highlights failed nodes in red. - Logs show stderr output inline. - Users can retry individual nodes. - Failures generate a triage entry (finding type = \"tool error\").</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#example-cli-session","title":"\ud83e\udde0 Example CLI Session","text":"<p>```bash</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#add-ferox-with-a-project-local-override-wordlist","title":"Add Ferox with a project-local override wordlist","text":"<p>secflow tools add ferox \\   --version 2.10.0 \\   --scope project \\   --config '{ \"wordlist\": \"res://wordlists/raft-medium-directories.txt\", \"threads\": 64 }'</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#run-a-two-node-workflow-directly-from-cli-discovery-nuclei","title":"Run a two-node workflow directly from CLI (discovery \u2192 nuclei)","text":"<p>secflow run \\   --project acme-web \\   --recipe workflows/discovery-to-nuclei.yaml \\   --var target=https://app.acme.com ```bash</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#api-response-example","title":"API Response Example","text":"<p><code>json {   \"tool\": \"feroxbuster\",   \"version\": \"2.10.0\",   \"scope\": \"project\",   \"effective_config\": {     \"wordlist\": \"res://wordlists/raft-medium-directories.txt\",     \"threads\": 64,     \"rate_limit\": 0   },   \"status\": \"installed\",   \"selftest\": { \"ok\": true, \"elapsed_ms\": 143 } }</code>json</p>"},{"location":"architecture/08-tool-manager-and-ux-design/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>UI-based \"Workflow Marketplace\" for community templates.</li> <li>AI-assisted tool parameter tuning based on context.</li> <li>Live terminal dashboard with interactive progress visualization.</li> <li>Integration with Burp/OWASP ZAP APIs for direct import.</li> </ul> <p>Next: Resource Registry</p>"},{"location":"architecture/09-resource-registry/","title":"09 \u2014 Resource Registry","text":""},{"location":"architecture/09-resource-registry/#overview","title":"\ud83e\udded Overview","text":"<p>The Resource Registry is SecFlow's shared data layer for managing reusable assets such as:</p> <ul> <li>Wordlists  </li> <li>Templates (Nuclei, ZAP, custom YAML)  </li> <li>Headers and payload sets  </li> <li>Configurations and schema files  </li> <li>CVE/CWE enrichment databases  </li> </ul> <p>This registry provides unified access to all resources, manages versioning and scope isolation, and acts as the single source of truth for both CLI and API workflows.</p>"},{"location":"architecture/09-resource-registry/#design-goals","title":"\ud83e\uddf1 Design Goals","text":"Goal Description Centralized One consistent repository for all reusable data. Scoped Resources may be global, group-specific, or project-specific. Versioned Immutable artifacts with hash-based versioning. Queryable Searchable by tags, type, or metadata. Cacheable Local caching for fast re-use and offline execution. Auditable Every modification is logged in the audit trail."},{"location":"architecture/09-resource-registry/#architecture-overview","title":"\ud83e\udde9 Architecture Overview","text":"<pre><code>+----------------------------------------------------+\n|                Resource API                        |\n| - Resource Manager                                  |\n| - Indexer / Search Engine                          |\n| - Version Resolver                                 |\n| - Storage Adapter (File, DB, Remote)               |\n+---------------------------\u252c------------------------+\n                            |\n                            \u25bc\n                +---------------+\n                | Resource Blob |\n                +---------------+\n                            |\n                            \u25bc\n                +---------------+\n                | Local Cache   |\n                +---------------+\n```python\n\n---\n\n## \u2699\ufe0f Resource Model\n\n```python\n# core-lib/models/resource.py\nfrom typing import Literal, Optional\nfrom datetime import datetime\nfrom pydantic import BaseModel\n\nclass Resource(BaseModel):\n    id: str\n    name: str\n    type: Literal[\"wordlist\", \"templates\", \"headers\", \"payloads\", \"configs\", \"schema\"]\n    version: str\n    hash: str\n    scope: Literal[\"global\", \"group\", \"project\"]\n    owner: Optional[str]\n    blob_uri: str\n    metadata: dict\n    created_at: datetime\n    updated_at: datetime\n    usage_count: int\n    last_used: Optional[datetime]\n```yaml\n\n## \ud83e\udde9 Scope Hierarchy\n\n| Level | Description | Example Path |\n|-------|-------------|--------------|\n| **Global** | Available across all users and projects. | `res://wordlists/common.txt` |\n| **Group** | Shared among specific teams. | `res://group/redteam/headers.json` |\n| **Project** | Private to a specific pentest or client project. | `res://project/acme/templates/custom.yaml` |\n\n### Precedence Rules\n1. Run-level override\n2. Node-level override\n3. Project default\n4. Group default\n5. Global default\n\n### Example:\nIf project-A has a custom wordlist `res://project/acme/dirb.yaml`, it overrides `res://wordlists/dirb:latest`.\n\n## \ud83e\udde9 Example Registry Entry\n\n```yaml\nid: \"res://wordlists/dirb:1.2.0\"\nname: \"Dirbuster Common\"\ntype: \"wordlist\"\nversion: \"1.2.0\"\nhash: \"sha256:ea13f3b4c8d9e2f1a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8\"\nscope: \"global\"\nmetadata:\n  tags: [\"web\", \"discovery\"]\n  size: 24312\n  license: \"GPL-3.0\"\n  source: \"https://github.com/digination/dirbuster\"\ncreated_at: \"2025-08-01T12:32:00Z\"\nupdated_at: \"2025-08-15T09:21:00Z\"\n```python\n\n## \ud83e\uddf1 Storage Backends\n\nThe Resource Registry supports multiple backends:\n\n| Backend | Usage | Notes |\n|---------|-------|-------|\n| **Local Filesystem** | Default for developer use. | Fast, no dependencies. |\n| **SQLite / Postgres** | Production database. | Metadata stored in DB, blob on disk. |\n| **S3 / MinIO** | Remote multi-tenant storage. | Ideal for distributed environments. |\n| **Git-backed Repository** | Version-controlled registry. | Enables audit and rollback. |\n\n## \ud83e\udde9 Resource Manager Interface\n\n```python\n# core-lib/ports/resource_port.py\nfrom typing import List\nfrom .models import Resource\n\nclass ResourcePort(Protocol):\n    def register(self, resource: Resource) -&gt; None:\n        \"\"\"Register a new resource in the registry.\"\"\"\n        pass\n\n    def list(self, scope: str) -&gt; List[Resource]:\n        \"\"\"List resources within a scope.\"\"\"\n        pass\n\n    def get(self, id: str) -&gt; Resource:\n        \"\"\"Get a resource by ID.\"\"\"\n        pass\n\n    def resolve(self, name: str, version: str) -&gt; Resource:\n        \"\"\"Resolve a resource by name and version.\"\"\"\n        pass\n\n    def increment_usage(self, id: str) -&gt; None:\n        \"\"\"Increment usage counter for a resource.\"\"\"\n        pass\n```python\n\n### Example Adapter Implementation\n```python\n# storage/resource_repository.py\nimport json, os\nfrom core_lib.models.resource import Resource\n\nclass FileResourceRepo:\n    def __init__(self, base_path=\"~/.SecFlow/resources\"):\n        self.base = os.path.expanduser(base_path)\n\n    def register(self, res: Resource):\n        path = os.path.join(self.base, f\"{res.id.replace('res://','')}.json\")\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        with open(path, \"w\") as f:\n            f.write(res.model_dump_json())\n\n    def get(self, id):\n        path = os.path.join(self.base, f\"{id.replace('res://','')}.json\")\n        return Resource.parse_file(path)\n```yaml\n\n## \ud83e\udde9 Resource Fetching &amp; Caching\n\nWhen a workflow references `res://wordlists/dirb:latest`:\n\n1. The registry resolves the resource (global/group/project).\n2. The manager checks the local cache.\n3. If missing or outdated, it downloads or loads the file blob.\n4. The reference is then injected into the tool configuration.\n\n```python\nresolved = ResourceManager.resolve(\"res://wordlists/dirb:latest\")\npath = CacheManager.fetch(resolved)\n```yaml\n\n## \ud83e\udde0 Resource Versioning\n\nResources are immutable once published; updates produce new versions.\n\n| Operation | Behavior |\n|-----------|----------|\n| **publish** | Adds new resource version, preserves old one. |\n| **retire** | Marks resource as deprecated (kept for history). |\n| **promote** | Moves a project resource to group/global scope. |\n\n### Version Reference Syntax\n```text\nres://wordlists/dirb:1.2.0\nres://templates/nuclei:latest\n```text\n\n## \ud83e\udde9 Registry CLI Commands\n\n```bash\n# List all resources\nSecFlow resources list\n\n# Show details for a resource\nSecFlow resources show res://wordlists/dirb:latest\n\n# Add new resource\nSecFlow resources add wordlist ./custom.txt --scope project\n\n# Promote resource\nSecFlow resources promote res://project/acme/dirb:latest --to global\n```text\n\n## \ud83e\udde0 Integration with Tool Manager\n\nTools reference resources via symbolic URIs.\nAt runtime, the registry automatically resolves URIs into local paths.\n\n### Example Nuclei config:\n```yaml\ntemplates: res://templates/nuclei:latest\nwordlist: res://wordlists/dirb:latest\n</code></pre>"},{"location":"architecture/09-resource-registry/#security-integrity","title":"\ud83d\udd12 Security &amp; Integrity","text":"Mechanism Description Hash Validation SHA-256 hashes validated before use. Signed Resources Optional GPG signing for remote sources. Access Control Scoped permissions (Admin / Analyst / Viewer). Audit Trail Every fetch and publish event logged."},{"location":"architecture/09-resource-registry/#garbage-collection-policy","title":"\ud83e\udde9 Garbage Collection Policy","text":"<p>When a resource is deleted: - Orphaned blob files are queued for cleanup by the <code>GarbageCollector</code>. - The audit log retains metadata for traceability. - Cached copies remain valid until TTL expiration.</p>"},{"location":"architecture/09-resource-registry/#example-use-case","title":"\ud83e\udde0 Example Use Case","text":""},{"location":"architecture/09-resource-registry/#global-wordlist-shared-by-tools","title":"Global Wordlist Shared by Tools","text":"<p>All tools can reference <code>res://wordlists/dirb:latest</code>: - Feroxbuster uses it for directory brute-force. - Katana can reuse it for crawl hints. - Nuclei leverages it for parameter fuzzing.</p> <p>Each tool can still override with its own wordlist if required.</p>"},{"location":"architecture/09-resource-registry/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Remote Resource Index API (REST/GraphQL).</li> <li>Smart caching with usage-based prefetch.</li> <li>Resource metrics: \"most used\", \"last updated\", etc.</li> <li>Tag-based search and semantic discovery.</li> <li>Signed update feeds from verified community sources.</li> </ul> <p>Next: Wordlist &amp; Output Sharing Rules</p>"},{"location":"architecture/10-wordlist-and-output-sharing/","title":"10 \u2014 Wordlist &amp; Output Sharing Rules","text":""},{"location":"architecture/10-wordlist-and-output-sharing/#overview","title":"\ud83e\udded Overview","text":"<p>One of SecFlow's key strengths is inter-tool resource sharing \u2014 allowing different scanners and discovery tools to reuse wordlists, templates, and output datasets through a unified and versioned Resource Registry.</p> <p>This enables workflows like:</p> <pre><code>Feroxbuster (directory discovery)\n        \u2193\nKatana (crawler + parameter discovery)\n        \u2193\nNuclei (template-driven vulnerability scan)\n```text\n\nEach step consumes outputs and produces standardized findings that can be reused in subsequent stages \u2014 without manual conversions or reconfiguration.\n\n---\n\n## \ud83e\uddf1 Design Objectives\n\n| Objective | Description |\n|------------|-------------|\n| **Shared Wordlists** | All tools can reference the same library of wordlists. |\n| **Isolated Overrides** | Each tool may override global wordlists with project-specific ones. |\n| **Consistent Output Contracts** | Every wrapper emits normalized JSON output. |\n| **Dataset Interoperability** | Discovery results from one tool can feed another automatically. |\n| **Performance Efficiency** | Cached resources and deduplication prevent redundant I/O. |\n\n---\n\n## \u2699\ufe0f Wordlist Management Flow\n\n```text\n[ Resource Registry ]\n        \u2502\n        \u25bc\n[ Wordlist Resolver ]\u2500\u2500\u25ba Global Cache\n        \u2502\n        \u25bc\n[ Tool Wrapper Config ]\n        \u2502\n        \u25bc\n[ Execution Context ]\n```text\n\nEach execution context resolves wordlists from the **Resource Registry**, fetching them locally if needed.\n\n---\n\n## \ud83e\udde9 Shared Wordlist Schema\n\n```yaml\nid: res://wordlists/dirb:1.2.0\ntype: wordlist\nscope: global\nmetadata:\n  description: \"Common web directory wordlist\"\n  format: \"text\"\n  size: 24312\n```yaml\n\n### Usage Example\n```yaml\ntools:\n  feroxbuster:\n    wordlist: res://wordlists/dirb:latest\n  nuclei:\n    templates: res://templates/owasp-top10:latest\n```yaml\n\nAt runtime, SecFlow resolves these resources to absolute paths and injects them into each wrapper.\n\n## \ud83e\udde0 Multi-Scope Selection Logic\n\n### 1. Run-Level Override\nSupplied directly in the workflow recipe or CLI argument.\n\n**Example:**\n```bash\nSecFlow run feroxbuster --wordlist ./private.txt\n```bash\n\n### 2. Node-Level Configuration\nDeclared inside workflow YAML.\n\n**Example:**\n```yaml\nnodes:\n  - id: ferox\n    type: discovery.ferox\n    config:\n      wordlist: res://wordlists/dirb:1.0\n```yaml\n\n### 3. Project Default\nStored under `~/.SecFlow/projects/&lt;id&gt;/config.yaml`.\n\n### 4. Group Default\nShared among organizational units or red-team groups.\n\n### 5. Global Default\nFallback resource available for all users.\n\n## \ud83e\udde0 Tool-Specific Overrides\n\nEach wrapper can define preferred wordlists and formats in its manifest.\n\n### Example (feroxbuster.json):\n```json\n{\n  \"defaults\": {\n    \"wordlist\": \"res://wordlists/dirb:latest\"\n  },\n  \"accepted_formats\": [\"txt\", \"lst\"]\n}\n```json\n\n### Nuclei Example:\n```json\n{\n  \"defaults\": {\n    \"templates\": \"res://templates/nuclei:latest\"\n  },\n  \"accepted_formats\": [\"yaml\"]\n}\n```json\n\nThe Tool Manager dynamically validates that the provided wordlist matches the expected format before execution.\n\n## \ud83e\udde9 Output Standardization\n\nAll tools output to a shared JSON Lines dataset (`.jsonl`).\n\n### Example \u2014 Ferox Output\n```json\n{\"url\": \"https://target.com/login\", \"status\": 200, \"source\": \"feroxbuster\"}\n```json\n\n### Example \u2014 Nuclei Output\n```json\n{\"id\": \"CVE-2024-12345\", \"template\": \"sql-injection\", \"severity\": \"high\", \"matched-at\": \"https://target.com/login\"}\n```json\n\nThese outputs are normalized into the Finding schema by the Findings Engine.\n\n## \ud83e\udde0 Chained Data Exchange\n\n```text\nFeroxbuster \u2500\u2510\n              \u251c\u2500\u2500\u25ba Output (urls.jsonl)\nKatana \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2193\n     Nuclei\n```text\n\nEach wrapper declares output channels (urls, parameters, endpoints, etc.).\n\nThe Workflow Engine automatically maps compatible output types to input fields of the next node.\n\n### Example Workflow Excerpt\n```yaml\nnodes:\n  - id: ferox\n    type: discovery.ferox\n    outputs: [\"urls\"]\n\n  - id: katana\n    type: crawler.katana\n    inputs: [\"urls\"]\n    outputs: [\"urls\", \"params\"]\n\n  - id: nuclei\n    type: scanner.nuclei\n    inputs: [\"urls\", \"params\"]\n    outputs: [\"findings\"]\n```yaml\n\n## \ud83e\udde9 Cross-Tool Resource Sharing Rules\n\n| Rule | Description |\n|------|-------------|\n| **Wordlists** | All tools can access any registered wordlist; wrappers define which formats they accept. |\n| **Templates** | Shared globally between Nuclei, ZAP, or other scanners. |\n| **Headers** | Reusable header sets (e.g., API tokens) can be applied per project. |\n| **Payloads** | Payload libraries are versioned and accessible to all fuzzers. |\n| **Findings Outputs** | Findings may be exported or reused as seed data for enrichment tools. |\n\n## \ud83e\udde0 Example \u2014 Shared Output Dataset\n\n### Scenario:\nA user runs Ferox \u2192 Nuclei chain.\nNuclei reuses the output from Ferox as its input dataset.\n\n```bash\nSecFlow run feroxbuster --target https://api.company.com \\\n| SecFlow run nuclei --stdin\n```bash\n\n### Result:\n1. Ferox writes discovered URLs to `/runs/&lt;uuid&gt;/ferox/urls.jsonl`\n2. The Workflow Engine pipes this dataset to the Nuclei node.\n3. Nuclei scans each URL using selected templates.\n4. Normalized findings are saved under `/runs/&lt;uuid&gt;/nuclei/findings.jsonl`\n\n## \ud83e\udde9 Shared Dataset Metadata\n\n```yaml\ndataset:\n  id: \"runs/2025-10-06T12:31Z-ferox-urls\"\n  type: \"urls\"\n  source: \"feroxbuster\"\n  size: 243\n  created_at: \"2025-10-06T12:31Z\"\n```yaml\n\nThis metadata is referenced by downstream nodes to ensure deterministic workflows.\n\n## \ud83d\udd10 Data Isolation &amp; Sharing Between Projects\n\nSecFlow supports granular sharing control for multi-project setups:\n\n| Mode | Description |\n|------|-------------|\n| **Isolated** | Each project keeps separate resources and findings. |\n| **Shared Group** | Projects under the same group share wordlists and results. |\n| **Selective** | User manually links resources or outputs between projects. |\n\n### Example:\n```yaml\nproject:\n  name: acme-api\n  sharing:\n    with: [\"internal-api\", \"dev-api\"]\n    resources: [\"wordlists\", \"templates\"]\n    outputs: [\"urls\", \"parameters\"]\n```yaml\n\n## \ud83e\udde9 Cache &amp; Deduplication\n\nWordlists and tool outputs are hash-indexed and cached for reuse.\n\n### Cache Key Formula\n```python\ncache_key = sha256(resource_id + version + scope)\n```python\n\nThis guarantees consistent retrieval and avoids redundant downloads.\n\n## \ud83e\udde0 Example End-to-End Flow\n\n```text\nProject: acme-api\n \u251c\u2500\u2500 Shared wordlists (global)\n \u251c\u2500\u2500 Custom payloads (project)\n \u251c\u2500\u2500 Workflow: Ferox \u2192 Katana \u2192 Nuclei\n \u2502     \u251c\u2500\u2500 URLs discovered \u2192 shared dataset\n \u2502     \u251c\u2500\u2500 Parameters extracted \u2192 temp dataset\n \u2502     \u2514\u2500\u2500 Findings enriched \u2192 persisted\n \u2514\u2500\u2500 Cached resources \u2192 reused in next run\n</code></pre>"},{"location":"architecture/10-wordlist-and-output-sharing/#validation-conflict-resolution","title":"\ud83e\udde9 Validation &amp; Conflict Resolution","text":"Conflict Resolution Same resource name, different scope Higher precedence scope wins (project &gt; group &gt; global). Resource deleted mid-run Cached version remains until TTL expires. Output schema mismatch Adapter plugin transforms data. Duplicate URLs or findings De-duplication engine merges entries by hash."},{"location":"architecture/10-wordlist-and-output-sharing/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Distributed cache synchronization (Redis or MinIO).</li> <li>Tag-based linking of related outputs (e.g., same target domain).</li> <li>Automatic scope inference based on project classification.</li> <li>Resource \"diff\" view between runs.</li> <li>AI suggestion for optimal wordlists or template selection.</li> </ul> <p>Next: Project Isolation &amp; Data Sharing Controls</p>"},{"location":"architecture/11-project-isolation-and-data-sharing/","title":"11 \u2014 Project Isolation &amp; Data Sharing Controls","text":""},{"location":"architecture/11-project-isolation-and-data-sharing/#overview","title":"\ud83e\udded Overview","text":"<p>The Project Isolation &amp; Sharing subsystem defines how multiple SecFlow projects coexist securely within the same environment. Each project has its own namespace, storage domain, and execution context, but can optionally share data or resources under controlled policies.</p> <p>SecFlow's isolation model is designed to: - Protect sensitive customer or target data. - Enable reuse of discovery outputs between related engagements. - Support team-based collaboration while maintaining auditability.</p>"},{"location":"architecture/11-project-isolation-and-data-sharing/#design-principles","title":"\ud83e\uddf1 Design Principles","text":"Principle Description Default Isolation Every project operates in its own workspace and database namespace. Explicit Sharing No cross-project access occurs unless explicitly declared. Scoped Resources Shared assets must be tagged and versioned. Least Privilege Access Users only see or manage projects they are assigned to. Full Traceability Every cross-project data access is logged and auditable."},{"location":"architecture/11-project-isolation-and-data-sharing/#architectural-overview","title":"\u2699\ufe0f Architectural Overview","text":"<pre><code>+-----------------------------------------------------------+\n|                Project Manager                            |\n| - Workspace Manager (namespacing, FS isolation)           |\n| - Data Access Layer (scope resolution)                   |\n| - Sharing Policy Engine (group + project-level rules)     |\n| - Audit Log (cross-project actions)                      |\n+------------------------\u252c----------------------------------+\n                         |\n                         \u25bc\n+-----------------------------------------------------------+\n|              Project Storage Structure                    |\n+-----------------------------------------------------------+\n| ~/.SecFlow/projects/&lt;project_id&gt;/                        |\n| \u251c\u2500\u2500 config.yaml                                          |\n| \u251c\u2500\u2500 findings/                                             |\n| \u251c\u2500\u2500 runs/                                                 |\n| \u251c\u2500\u2500 reports/                                              |\n| \u2514\u2500\u2500 cache/                                                |\n+-----------------------------------------------------------+\n```python\n\n---\n\n## \ud83e\udde9 Project Data Model\n\n```python\n# core-lib/models/project.py\nfrom typing import List, Optional\nfrom datetime import datetime\nfrom pydantic import BaseModel\n\nclass Project(BaseModel):\n    id: str\n    name: str\n    owner: str\n    group: Optional[str]\n    description: Optional[str]\n    created_at: datetime\n    updated_at: datetime\n    sharing: Optional[dict] = {\n        \"enabled\": False,\n        \"with\": [],\n        \"resources\": [],\n        \"outputs\": []\n    }\n```text\n\n## \ud83e\udde9 Workspace Isolation\n\nEach project is backed by its own filesystem and database schema.\n\n### Example Directory Layout\n```yaml\n~/.SecFlow/projects/\n\u251c\u2500\u2500 acme-api/\n\u2502   \u251c\u2500\u2500 config.yaml\n\u2502   \u251c\u2500\u2500 runs/\n\u2502   \u251c\u2500\u2500 findings/\n\u2502   \u2514\u2500\u2500 cache/\n\u251c\u2500\u2500 finance-portal/\n\u2502   \u251c\u2500\u2500 config.yaml\n\u2502   \u251c\u2500\u2500 runs/\n\u2502   \u251c\u2500\u2500 findings/\n\u2502   \u2514\u2500\u2500 cache/\n```text\n\n### Database Schema Isolation\n\nEach project gets a dedicated schema:\n\n```yaml\npublic.findings_acme_api\npublic.findings_finance_portal\n```yaml\n\nThis allows multiple concurrent engagements with strict data boundaries.\n\n## \ud83e\udde0 Data Sharing Configuration\n\n### Example: Controlled Cross-Project Sharing\n```yaml\nproject:\n  name: \"acme-api\"\n  sharing:\n    enabled: true\n    with:\n      - \"internal-api\"\n      - \"qa-staging\"\n    resources:\n      - \"wordlists\"\n      - \"templates\"\n    outputs:\n      - \"urls\"\n      - \"parameters\"\n```python\n\nIn this configuration:\n- The `acme-api` project shares wordlists and templates with two sibling projects.\n- The outputs (e.g., discovered URLs) are made available for enrichment or scanning reuse.\n\n## \ud83e\udde9 Sharing Policy Engine\n\n### Logic Flow\n```text\nUser Request\n   \u2193\nPolicy Check (Project A \u2192 Project B)\n   \u2193\nScope Validation\n   \u2193\nAccess Decision (allow | deny)\n```yaml\n\n### Policy Structure\n\n| Field | Description |\n|-------|-------------|\n| **resource_type** | What type of data is being shared (wordlist, output, finding). |\n| **scope** | Allowed scope (project, group, global). |\n| **mode** | Access type (read-only, read-write, clone). |\n| **ttl** | Time-to-live for shared access. |\n\n### Example Policy Definition\n```yaml\npolicies:\n  - resource_type: \"outputs\"\n    scope: \"group\"\n    mode: \"read-only\"\n    ttl: 30d\n```yaml\n\n## \ud83e\udde9 Isolation Enforcement Mechanisms\n\n| Layer | Enforcement |\n|-------|-------------|\n| **Filesystem** | Each project path is sandboxed under `~/.SecFlow/projects/&lt;id&gt;`. |\n| **Database** | Separate schema per project (namespaced tables). |\n| **Cache** | Project-specific cache directories. |\n| **Runtime Context** | Workers run with `PROJECT_ID` environment variable. |\n| **Authorization** | API tokens include `project_id` scope claim. |\n\n## \ud83e\udde0 Access Token Scoping\n\nAPI tokens encode the project scope:\n\n```json\n{\n  \"sub\": \"hernan.trajtemberg\",\n  \"project_id\": \"acme-api\",\n  \"roles\": [\"analyst\"],\n  \"exp\": 1759870400\n}\n```python\n\nTokens can be project-scoped or group-scoped.\nThe access control middleware rejects out-of-scope operations.\n\n## \ud83e\udde9 Resource Linking Between Projects\n\nProjects can import shared assets from another project's registry.\n\n### Example Command\n```bash\nSecFlow projects link internal-api --resources wordlists templates\n```text\n\n### Example Output\n```text\nLinked resources:\n\u2714 wordlists (3)\n\u2714 templates (5)\n```text\n\nLinked resources are marked in metadata:\n\n```yaml\nlinked_from: \"project:internal-api\"\nmode: \"read-only\"\n```python\n\n## \ud83e\uddf1 Output Sharing\n\nOutputs (datasets or findings) can also be shared for cross-project correlation or enrichment.\n\n### Example Workflow:\n```text\nProject A \u2192 Discovery + Scan\n        \u2193\nShared Outputs (URLs, endpoints)\n        \u2193\nProject B \u2192 Enrichment / Retesting\n```text\n\n### Sharing Command\n```bash\nSecFlow share outputs acme-api --with finance-portal --types urls parameters\n```text\n\nThe receiving project's engine imports the shared dataset as a read-only reference.\n\n## \ud83e\udde9 Audit Logging\n\nEvery cross-project access event is logged.\n\n### Example Log Entry\n```json\n{\n  \"event\": \"resource_access\",\n  \"actor\": \"hernan.trajtemberg\",\n  \"source_project\": \"acme-api\",\n  \"target_project\": \"internal-api\",\n  \"resource\": \"wordlists\",\n  \"timestamp\": \"2025-10-06T11:42:21Z\",\n  \"action\": \"read\"\n}\n```python\n\n## \ud83e\udde0 Isolation Example Scenarios\n\n### 1. Strict Isolation (Default)\nEach project operates completely independently.\nUseful for sensitive pentests or regulated environments.\n\n### 2. Group-Level Sharing\nMultiple analysts share discovery data across projects within the same team.\n\n### 3. Selective Sharing\nA red-team lead selectively shares Nuclei findings between \"internal-api\" and \"staging-api\".\n\n## \ud83d\udd10 Security Considerations\n\n| Risk | Mitigation |\n|------|------------|\n| Unauthorized access to shared data | Token-scoped enforcement and audit logging |\n| Resource version drift | Immutable hashes + version pinning |\n| Data leakage across clients | No implicit sharing; explicit only |\n| Lateral movement between project schemas | Database role isolation |\n| Policy misconfiguration | Policy validation + test harness |\n\n## \ud83e\udde9 Example Policy Validation Script\n\n```python\ndef validate_policy(policy):\n    assert policy[\"mode\"] in (\"read-only\", \"read-write\", \"clone\")\n    assert policy[\"scope\"] in (\"project\", \"group\", \"global\")\n    if policy[\"ttl\"]:\n        assert re.match(r\"^\\d+[dh]$\", policy[\"ttl\"])\n</code></pre>"},{"location":"architecture/11-project-isolation-and-data-sharing/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Group-level \"Shared Intelligence Pool\" for recurring findings.</li> <li>Automatic synchronization of enrichment data across related projects.</li> <li>AI-based data deduplication and anomaly detection.</li> <li>Visual dependency graph of shared resources in UI.</li> <li>Temporal sharing policies (\"auto-expire after 30 days\").</li> </ul> <p>Next: Findings Model &amp; Schema Normalization</p>"},{"location":"architecture/12-findings-model-and-schema/","title":"12 \u2014 Findings Model &amp; Schema Normalization","text":""},{"location":"architecture/12-findings-model-and-schema/#overview","title":"\ud83e\udded Overview","text":"<p>The Findings Schema is the canonical data contract for SecFlow \u2014 it defines how vulnerabilities, anomalies, and tool outputs are normalized, enriched, and persisted.</p> <p>Every discovery, scan, or enrichment step in the workflow produces Findings, which are standardized across tools (Nuclei, Ferox, ZAP, Caido, custom detectors).</p> <p>The schema ensures: - Cross-tool consistency - Automated CVE/CWE/OWASP correlation - Risk scoring alignment (CVSS/NIST) - Deterministic enrichment for analytics and triage  </p>"},{"location":"architecture/12-findings-model-and-schema/#data-flow-summary","title":"\ud83e\uddf1 Data Flow Summary","text":"<pre><code>[ Tool Output ]\n        \u2193\n[ Findings Engine ]\n        \u2193\n[ Normalization Layer ]\n        \u2193\n[ Enrichment Layer (CVE/CWE/OWASP) ]\n        \u2193\n[ Persistent Store + Cache + Analytics ]\n```text\n\n---\n\n## \u2699\ufe0f Findings Core Model\n\n```python\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List, Dict\nfrom uuid import UUID\nfrom datetime import datetime\n\nclass Finding(BaseModel):\n    id: UUID\n    project_id: UUID\n    run_id: Optional[UUID]\n    detector_id: str = Field(description=\"canonical tool or plugin id, e.g. scan.nuclei\")\n    title: str\n    severity: str  # enum: info, low, medium, high, critical\n    resource: str  # canonical URL or identifier\n    evidence: Dict[str, object] = {}\n    cwe: Optional[int]\n    owasp: Optional[str]\n    cve_ids: List[str] = []\n    cvss: Optional[float]\n    mitre_attack: List[str] = []\n    poc_links: List[str] = []\n    created_at: datetime\n    provenance: Dict[str, object] = {}\n```python\n\n## \ud83e\udde9 Normalization Process\n\nEach wrapper or plugin output goes through the Findings Normalizer, which performs:\n\n1. Schema validation\n2. Severity normalization\n3. Field mapping\n4. Evidence compression\n5. Deduplication\n\n### Example Normalized Finding\n\n```json\n{\n  \"id\": \"7a3d9f8e-1f83-4a55-9a6c-5ea9e1a3b8d2\",\n  \"project_id\": \"b0b8b6e0-7c6a-43e8-8b2f-8a0d0e8b0f3c\",\n  \"run_id\": \"2a2b3c4d-5e6f-7081-92a3-b4c5d6e7f809\",\n  \"detector_id\": \"scan.nuclei\",\n  \"title\": \"X-Frame-Options header missing\",\n  \"severity\": \"low\",\n  \"resource\": \"https://app.acme.com/\",\n  \"evidence\": { \"request_id\": \"r-01HXXQ5AKP0NWS\", \"template\": \"misconfig/headers/xfo-missing.yaml\" },\n  \"cwe\": 693,\n  \"owasp\": \"A05\",\n  \"cve_ids\": [],\n  \"cvss\": 3.7,\n  \"mitre_attack\": [\"T1190\"],\n  \"poc_links\": [],\n  \"created_at\": \"2025-10-07T08:22:31Z\",\n  \"provenance\": { \"tool_version\": \"nuclei 3.1.0\", \"host\": \"runner-12\" }\n}\n```json\n\n```python\ndef normalize(raw: dict, source: str) -&gt; Finding:\n    severity_map = {\"info\": \"info\", \"low\": \"low\", \"medium\": \"medium\", \"high\": \"high\", \"critical\": \"critical\"}\n    return Finding(\n        id=str(uuid4()),\n        project_id=raw.get(\"project_id\"),\n        detector_id=source,\n        title=raw.get(\"info\", {}).get(\"name\") or raw.get(\"title\", \"Unnamed Finding\"),\n        severity=severity_map.get(raw.get(\"severity\", \"info\")),\n        path=raw.get(\"matched-at\") or raw.get(\"url\"),\n        evidence=raw,\n        created_at=datetime.utcnow(),\n        provenance={\"tool\": source, \"version\": raw.get(\"version\", \"unknown\")}\n    )\n```python\n\n## \ud83e\udde9 Normalization Rules by Source\n\n| Tool | Input Format | Mapping |\n|------|--------------|---------|\n| **Nuclei** | JSON lines | `info.name` \u2192 `title`, `info.severity` \u2192 `severity`, `matched-at` \u2192 `path` |\n| **Feroxbuster** | Text | `URL` \u2192 `path`, `status` \u2192 `evidence.status` |\n| **ZAP/Burp** | XML/JSON | `PluginId` \u2192 `cwe`, `RiskDesc` \u2192 `severity` |\n| **Caido** | SQLite | `Vulnerability.name` \u2192 `title`, `score` \u2192 `cvss_score` |\n| **Custom Detectors** | Python dict | Arbitrary fields normalized via schema mapping |\n\nNormalization is performed by `findings-engine` using source-specific adapters.\n\n## \ud83e\udde0 Severity Mapping\n\n| Raw Severity | Normalized | CVSS Equivalent |\n|--------------|------------|-----------------|\n| informational | info | 0.0\u20133.9 |\n| low | low | 4.0\u20136.9 |\n| medium | medium | 6.0\u20137.4 |\n| high | high | 7.5\u20138.9 |\n| critical | critical | 9.0\u201310.0 |\n\n## \ud83e\udde0 Deduplication Strategy\n\nFindings are hashed on a deterministic fingerprint:\n\n```python\nhash_input = f\"{finding.path}:{finding.title}:{finding.detector_id}\"\nfinding_hash = hashlib.sha256(hash_input.encode()).hexdigest()\n```python\n\nIf the hash already exists in the same project and run scope, the finding is merged rather than duplicated.\n\n## \ud83e\udde9 Enrichment Metadata Structure\n\n```python\nfinding.enrichment = {\n    \"cwe\": {\"id\": 89, \"name\": \"SQL Injection\"},\n    \"owasp\": {\"category\": \"A03\", \"name\": \"Injection\"},\n    \"CVSS\": {\"score\": 9.1, \"vector\": \"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\"},\n    \"mitre\": {\"technique\": \"T1505\", \"tactic\": \"Persistence\"},\n    \"poc\": {\"source\": \"exploitdb\", \"link\": \"https://www.exploit-db.com/exploits/52341\"}\n}\n```python\n\nThis metadata is populated during the Enrichment Phase (CVE/CWE/CVSS sync).\n\n## \ud83e\udde9 CVE / CWE / OWASP Mapping\n\n### CVE \u2192 CWE\n- NVD API provides `cve.affects.vendor.vendor_data` \u2192 `cwe.id`\n- Mapping stored in local SQLite cache.\n\n### CWE \u2192 OWASP\n| CWE | OWASP Category |\n|-----|----------------|\n| CWE-79 | A03: Injection |\n| CWE-89 | A03: Injection |\n| CWE-287 | A07: Identification and Authentication Failures |\n| CWE-601 | A10: Server-Side Request Forgery (SSRF) |\n\n### Example Mapping Resolver\n```python\ndef resolve_owasp(cwe_id):\n    mapping = {\"79\": \"A03\", \"89\": \"A03\", \"287\": \"A07\", \"601\": \"A10\"}\n    return mapping.get(str(cwe_id))\n```python\n\n## \ud83e\udde9 Confidence &amp; Risk Scoring\n\nConfidence combines tool reliability, correlation consistency, and enrichment coverage.\n\n### Formula\n```python\nconfidence = (tool_weight * 0.5) + (enrichment_score * 0.3) + (cross_source_count * 0.2)\n```python\n\n### Risk Score Calculation\n```python\nrisk_score = CVSS * confidence\n```python\n\nThis allows probabilistic triage prioritization.\n\n## \ud83e\udde0 Evidence Normalization\n\nEvidence is stored in compact, structured form for indexing:\n\n```json\n{\n  \"request\": {\n    \"method\": \"POST\",\n    \"url\": \"https://target.com/login\",\n    \"headers\": {\"Content-Type\": \"application/json\"},\n    \"body\": \"{\\\"username\\\":\\\"admin\\\"}\"\n  },\n  \"response\": {\n    \"status\": 500,\n    \"headers\": {\"Server\": \"Apache\"},\n    \"body_snippet\": \"SQL syntax error\"\n  }\n}\n```json\n\nLarge payloads are truncated or compressed to avoid storage overhead.\n\n## \ud83e\udde9 Finding Status Lifecycle\n\n| Status | Meaning | Managed By |\n|--------|---------|------------|\n| open | Newly discovered issue | Scanner |\n| triaged | Analyst reviewed | Analyst |\n| resolved | Fixed or confirmed | Analyst |\n| false_positive | Invalid finding | Analyst |\n| archived | Expired or obsolete | System (GC) |\n\nEach status change triggers an audit log event and optional webhook notification.\n\n## \ud83e\uddf1 Storage Layer Integration\n\nFindings are persisted via the `StoragePort` interface:\n\n```python\nclass FindingsRepository(Protocol):\n    def save(self, finding: Finding) -&gt; None:\n        \"\"\"Save a finding to storage.\"\"\"\n        pass\n\n    def list(self, project_id: str) -&gt; List[Finding]:\n        \"\"\"List findings for a project.\"\"\"\n        pass\n\n    def get(self, id: str) -&gt; Finding:\n        \"\"\"Get a finding by ID.\"\"\"\n        pass\n```python\n\n### Supported backends:\n- SQLite (default local mode)\n- PostgreSQL (production multi-project)\n- JSON (testing or demo mode)\n\n## \ud83e\udde9 Findings Export Schema\n\nSecFlow exports findings in structured formats for interoperability:\n\n| Format | Command |\n|--------|---------|\n| JSON | `SecFlow export findings --format json` |\n| CSV | `SecFlow export findings --format csv` |\n| HTML | `SecFlow report findings --template summary.html` |\n| SARIF | `SecFlow export findings --format sarif` |\n\n### Example JSON export:\n```json\n{\n  \"project\": \"acme-api\",\n  \"findings\": [\n    {\n      \"id\": \"a2b4f3c8-d9e2-4f1a-5b6c-7d8e9f0a1b2c\",\n      \"title\": \"SQL Injection\",\n      \"severity\": \"critical\",\n      \"cwe\": 89,\n      \"cvss_score\": 9.1,\n      \"path\": \"/login\",\n      \"created_at\": \"2025-10-06T10:15:00Z\"\n    }\n  ]\n}\n</code></pre>"},{"location":"architecture/12-findings-model-and-schema/#indexing-analytics","title":"\ud83e\udde0 Indexing &amp; Analytics","text":"<p>Each finding is indexed in the analytics database:</p> <ul> <li>Primary Index: <code>project_id</code> + <code>severity</code> + <code>cwe</code></li> <li>Full-Text Search: <code>title</code>, <code>path</code>, <code>evidence.body_snippet</code></li> <li>Aggregations: count by severity, top affected endpoints, common CWE classes.</li> </ul> <p>The metrics system (see 06-plugin-system.md &amp; 17-observability-logging-and-metrics.md) uses these indexes to generate dashboards.</p>"},{"location":"architecture/12-findings-model-and-schema/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Graph-based finding correlation (attack paths).</li> <li>AI-driven risk clustering (\"find similar vulnerabilities\").</li> <li>Contextual auto-triage (OWASP/NIST mapping feedback loops).</li> <li>Delta reports between runs (<code>run_id</code> diff).</li> <li>Live sync to vulnerability management platforms (DefectDojo, VulnDB).</li> </ul> <p>Next: CVE/CWE/POC Enrichment Layer</p>"},{"location":"architecture/13-cve-cwe-poc-enrichment-layer/","title":"13 \u2014 CVE/CWE/POC Enrichment Layer","text":""},{"location":"architecture/13-cve-cwe-poc-enrichment-layer/#overview","title":"\ud83e\udded Overview","text":"<p>The Enrichment Layer bridges the gap between raw scanner results and full vulnerability intelligence. It performs automated correlation between findings and vulnerability databases such as:</p> <ul> <li>CVE/NVD \u2014 canonical vulnerability records  </li> <li>CWE \u2014 weakness categorization  </li> <li>CVSS \u2014 scoring and severity models  </li> <li>Exploit-DB, Vulners, Metasploit, OSV \u2014 PoC and exploit references  </li> <li>MITRE ATT&amp;CK \u2014 behavioral mapping  </li> </ul> <p>SecFlow treats enrichment as a pluggable knowledge graph layer that can be extended via simple JSON/YAML definitions or API connectors.</p>"},{"location":"architecture/13-cve-cwe-poc-enrichment-layer/#enrichment-pipeline","title":"\u2699\ufe0f Enrichment Pipeline","text":"<pre><code>[Normalized Finding]\n        \u2193\n[CPE Identifier Extraction]\n        \u2193\n[CVE Resolver (NVD, OSV, Vulners)]\n        \u2193\n[CWE / OWASP Mapping]\n        \u2193\n[CVSS Calculation]\n        \u2193\n[POC + Exploit Lookup]\n        \u2193\n[MITRE ATT&amp;CK Correlation]\n        \u2193\n[Final Enriched Finding]\n```text\n\n---\n\n## \ud83e\udde9 CPE &amp; Component Extraction\n\nThe enrichment process begins by fingerprinting software components.\n\n```python\ndef extract_cpe(finding: Finding) -&gt; Optional[str]:\n    headers = finding.evidence.get(\"response\", {}).get(\"headers\", {})\n    banner = headers.get(\"Server\") or headers.get(\"X-Powered-By\")\n    return cpe_guess(banner) if banner else None\n```python\n\n### Example results:\n- `Server: Apache/2.4.54` \u2192 `cpe:/a:apache:http_server:2.4.54`\n- `X-Powered-By: Express` \u2192 `cpe:/a:npmjs:express:4.18.2`\n\n## \ud83e\udde9 CVE Resolution Engine\n\nThe CVE Resolver queries multiple backends in a failover chain:\n\n| Source | Endpoint | Rate Limit | Cache TTL |\n|--------|----------|------------|-----------|\n| **NVD** | `https://services.nvd.nist.gov/rest/json/cves/2.0` | 1000/day | 24h |\n| **OSV.dev** | `https://api.osv.dev/v1/query` | Unlimited | 12h |\n| **Vulners API** | `https://vulners.com/api/v3/search/lucene/` | 2000/day | 24h |\n\n```python\nclass CVEResolver:\n    def resolve(self, cpe: str) -&gt; List[dict]:\n        cached = self.cache.get(cpe)\n        if cached: return cached\n\n        results = []\n        for backend in self.backends:\n            try:\n                results.extend(backend.query(cpe))\n            except Exception:\n                continue\n        self.cache.set(cpe, results)\n        return results\n```python\n\nResults are merged and normalized into a unified CVE format.\n\n## \ud83e\udde0 CVE Normalized Model\n\n```python\nclass CVEEntry(BaseModel):\n    cve_id: str\n    description: str\n    published: datetime\n    cvss_score: float\n    cvss_vector: str\n    cwe_ids: List[int]\n    references: List[str]\n    exploit_refs: List[str]\n    source: str\n```python\n\nEach finding may be associated with multiple CVE entries.\n\n## \ud83e\udde9 CWE / OWASP / MITRE Mapping\n\nOnce CVEs are linked, weaknesses and behavioral context are resolved.\n\n| Source | Purpose | Mapping Strategy |\n|--------|---------|------------------|\n| **CWE** | Weakness classification | CVE \u2192 CWE via NVD JSON |\n| **OWASP** | Application risk class | CWE \u2192 OWASP Top 10 map |\n| **MITRE ATT&amp;CK** | Adversary tactics/techniques | CWE \u2192 ATT&amp;CK TID correlation |\n\n```python\ndef map_cwe_to_owasp(cwe_id: int) -&gt; str:\n    mapping = {\n        79: \"A03: Injection\",\n        89: \"A03: Injection\",\n        787: \"A05: Buffer Overflow\",\n        601: \"A10: SSRF\"\n    }\n    return mapping.get(cwe_id, \"N/A\")\n```python\n\n### MITRE correlation example:\n```python\nmitre_map = {\n    \"CWE-79\": \"T1059.007 (Cross-Site Scripting)\",\n    \"CWE-89\": \"T1505.003 (SQL Injection)\"\n}\n```python\n\n## \ud83e\udde9 CVSS Calculation\n\nIf a finding lacks explicit CVSS scoring, SecFlow derives one via heuristics:\n\n```python\ndef derive_cvss(cwe_id: int, context: dict) -&gt; float:\n    # basic fallback estimation\n    if cwe_id in (79, 89):\n        return 9.0\n    elif cwe_id in (200, 201):\n        return 7.5\n    return 5.0\n```python\n\n### Final score combines:\n```python\nbase = CVSS\ntemporal = exploit_availability * 0.2\nenvironmental = exposure_factor * 0.3\nfinal = (base + temporal + environmental) / 1.5\n```python\n\n## \ud83e\udde0 PoC &amp; Exploit Correlation\n\n### Data Sources\n| Source | Access | Notes |\n|--------|--------|-------|\n| **Exploit-DB** | Public dump | Weekly sync |\n| **Vulners** | API | Indexed by CVE |\n| **Metasploit** | Local metadata | Optional |\n| **GitHub PoC** | OSV + GitHub GraphQL | Filter by repo tags |\n| **SecurityFocus (legacy)** | Offline mirror | Static references |\n\n### Example Resolver\n```python\ndef resolve_poc(cve_id: str) -&gt; list:\n    sources = [exploitdb, vulners, githubpoc]\n    results = []\n    for s in sources:\n        results.extend(s.search(cve_id))\n    return list(set(results))\n```python\n\n## \ud83e\udde9 PoC Safety Governance\n\nBecause PoCs can contain malicious payloads, SecFlow enforces strict isolation.\n\n| Policy | Enforcement |\n|--------|-------------|\n| **Read-only storage** | PoCs stored as text blobs, no exec permission |\n| **Sandbox validation** | Hash-check before use |\n| **Legal disclaimer** | Must be accepted before PoC download |\n| **Runtime restriction** | Execution allowed only in `--sandbox` mode |\n\n### Example governance guard:\n```python\ndef safe_open_poc(poc_path: Path):\n    if not user.accepted_disclaimer:\n        raise PermissionError(\"PoC execution disabled until disclaimer accepted.\")\n    subprocess.run([\"sandbox\", \"python3\", poc_path])\n```python\n\n## \ud83e\udde9 Caching &amp; Synchronization\n\nEach enrichment source maintains a versioned local cache:\n\n| Component | Backend | Format | TTL |\n|-----------|---------|--------|-----|\n| **CVE** | NVD JSON | SQLite | 24h |\n| **CWE** | MITRE XML | JSON | 7d |\n| **PoC** | Exploit-DB | FS/JSON | 14d |\n\n### Example cache adapter:\n```python\nclass LocalCache:\n    def get(self, key: str) -&gt; Optional[Any]:\n        \"\"\"Get value from cache by key.\"\"\"\n        pass\n\n    def set(self, key: str, value: Any, ttl: int) -&gt; None:\n        \"\"\"Set value in cache with TTL.\"\"\"\n        pass\n\n    def purge_expired(self) -&gt; None:\n        \"\"\"Remove expired entries from cache.\"\"\"\n        pass\n```python\n\n## \ud83e\udde9 API Exposure\n\nThe enrichment system provides a unified query interface:\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/api/v1/enrich/cve` | POST | Enrich a finding by CPE/CVE |\n| `/api/v1/enrich/cwe` | POST | Map CWE to OWASP |\n| `/api/v1/enrich/poc` | GET | Retrieve PoC links |\n| `/api/v1/enrich/status` | GET | Show cache health |\n\n### Example response:\n```json\n{\n  \"finding_id\": \"1234\",\n  \"cve\": [\"CVE-2024-12345\"],\n  \"CVSS\": 9.8,\n  \"cwe\": 89,\n  \"owasp\": \"A03: Injection\",\n  \"poc_links\": [\"https://exploit-db.com/exploits/52341\"]\n}\n```json\n\n## \ud83e\udde9 Enrichment Rules &amp; Priority\n\n1. Local cache first\n2. API sources (NVD/OSV) second\n3. Third-party mirrors (Vulners, Exploit-DB) last\n\nEach backend includes retry and circuit-breaker logic via Tenacity.\n\n## \ud83e\udde9 Parallel Enrichment\n\nThe enrichment worker uses async pipelines for batch enrichment:\n\n```python\nasync def enrich_findings_batch(findings: list):\n    async with aiohttp.ClientSession() as session:\n        tasks = [enrich_one(f, session) for f in findings]\n        return await asyncio.gather(*tasks)\n```python\n\nEach finding may take 0.1\u20131.5 seconds depending on CVE count; concurrency keeps throughput high.\n\n## \ud83e\udde0 Example Enrichment Output\n\n```json\n{\n  \"finding_id\": \"abcd-1234\",\n  \"cpe\": \"cpe:/a:apache:http_server:2.4.54\",\n  \"cve_ids\": [\"CVE-2023-25690\"],\n  \"cwe\": 89,\n  \"owasp\": \"A03: Injection\",\n  \"cvss_score\": 9.8,\n  \"poc_links\": [\"https://exploit-db.com/exploits/52341\"],\n  \"mitre_tid\": \"T1505.003\",\n  \"last_enriched\": \"2025-10-06T09:43:00Z\"\n}\n</code></pre>"},{"location":"architecture/13-cve-cwe-poc-enrichment-layer/#security-compliance","title":"\ud83d\udd12 Security &amp; Compliance","text":"<ul> <li>All enrichment data is public-source only.</li> <li>No proprietary or restricted databases.</li> <li>Caching system automatically purges expired CVE entries.</li> <li>Full audit trail for every enrichment event.</li> </ul>"},{"location":"architecture/13-cve-cwe-poc-enrichment-layer/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Integrate VulnCheck, CISA KEV, and EPSS for exploit prediction.</li> <li>Introduce AI-based CVE clustering for semantic matching.</li> <li>Enrichment correlation graph for cross-project analysis.</li> <li>Automated risk re-scoring based on KEV updates.</li> </ul> <p>Next: POC Sources, Safety &amp; Legal Guidelines</p>"},{"location":"architecture/14-poc-sources-and-legal-guidelines/","title":"14 \u2014 PoC Governance, Safety, and Legal Framework","text":""},{"location":"architecture/14-poc-sources-and-legal-guidelines/#overview","title":"\ud83e\udded Overview","text":"<p>Proof-of-Concept (PoC) execution is the most sensitive aspect of the SecFlow platform. While enrichment and discovery involve data collection, PoC modules may trigger actual exploits \u2014 often on controlled test targets or lab environments.</p> <p>This section defines: - The security model for PoC management and execution. - Legal and ethical boundaries for researchers. - Technical enforcement of sandbox isolation. - Policy hierarchy for PoC lifecycle, provenance, and deletion.</p>"},{"location":"architecture/14-poc-sources-and-legal-guidelines/#legal-ethical-framework","title":"\u2696\ufe0f Legal &amp; Ethical Framework","text":""},{"location":"architecture/14-poc-sources-and-legal-guidelines/#1-authorized-testing-only","title":"1. Authorized Testing Only","text":"<p>PoC execution is strictly limited to: - Assets owned or explicitly authorized by the user. - Lab or offline sandbox targets. - Non-production systems unless a signed authorization exists.</p>"},{"location":"architecture/14-poc-sources-and-legal-guidelines/#2-compliance-with-international-norms","title":"2. Compliance with International Norms","text":"<p>SecFlow aligns with: - ISO/IEC 29147 \u2014 Vulnerability Disclosure. - ISO/IEC 30111 \u2014 Vulnerability Handling. - NIST SP 800-115 \u2014 Technical Guide to Information Security Testing. - CISA KEV and CVE\u00ae Program standards.</p>"},{"location":"architecture/14-poc-sources-and-legal-guidelines/#3-researcher-agreement","title":"3. Researcher Agreement","text":"<p>Before using any exploit-related features: - Users must accept the Responsible Use Agreement (RUA). - Every PoC download or execution is logged. - No redistribution of PoC code outside permitted licensing (e.g., GPL, BSD).</p>"},{"location":"architecture/14-poc-sources-and-legal-guidelines/#poc-lifecycle-management","title":"\ud83e\uddf1 PoC Lifecycle Management","text":"Stage Description Acquisition PoC fetched from trusted sources (Exploit-DB, Vulners, GitHub PoC, OSV). Verification Signature/hash validated; metadata normalized. Classification Marked as local, remote, DoS, or privilege escalation. Sandbox Execution Run only in isolated containers or VMs. Audit Logging Execution parameters, user, and timestamp recorded. Retention &amp; Purge Expired PoCs automatically archived or deleted."},{"location":"architecture/14-poc-sources-and-legal-guidelines/#storage-metadata","title":"\ud83e\udde9 Storage &amp; Metadata","text":"<p>PoCs are stored as immutable artifacts under the internal resource store:</p> <pre><code>~/.SecFlow/resources/poc/\n\u251c\u2500\u2500 CVE-2024-12345/\n\u2502   \u251c\u2500\u2500 exploit.py\n\u2502   \u251c\u2500\u2500 metadata.json\n\u2502   \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 CVE-2023-98765/\n```text\n\n### Example `metadata.json`\n```json\n{\n  \"cve\": \"CVE-2024-12345\",\n  \"source\": \"exploit-db\",\n  \"url\": \"https://www.exploit-db.com/exploits/52341\",\n  \"verified\": true,\n  \"language\": \"python\",\n  \"type\": \"rce\",\n  \"hash\": \"b3f9f74e89e2a1b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0\",\n  \"sandbox_only\": true,\n  \"license\": \"GPLv2\",\n  \"date_fetched\": \"2025-10-06T10:20:00Z\"\n}\n```json\n\n## \ud83d\udd12 Sandbox Execution Architecture\n\n### 1. Isolation Model\n\nAll PoC executions occur within the SecFlow Sandbox Runtime, implemented as:\n\n- Docker container with restricted capabilities (`--cap-drop=ALL`).\n- Read-only mount of PoC files.\n- No network egress unless explicitly allowed.\n- Time &amp; memory quotas enforced by cgroups.\n\n### 2. Runtime Diagram\n```yaml\n+-------------------------------------------------------+\n|                SecFlow Sandbox Runtime                |\n|-------------------------------------------------------|\n|  - Namespace Isolation (PID, NET, MNT)                |\n|  - Read-only FS for /poc                              |\n|  - IPC + SYS_ADMIN disabled                           |\n|  - AppArmor / SELinux profiles                        |\n|  - Seccomp filters (deny dangerous syscalls)          |\n+-------------------------------------------------------+\n         \u2191\n         | PoC artifact + parameters\n         |\n[SecFlow Worker] \u2192 [Sandbox Orchestrator] \u2192 [Container Runtime]\n```text\n\n### 3. Sample Sandbox Invocation\n```bash\nSecFlow sandbox run poc CVE-2024-12345 --target https://staging.example.com\n```yaml\n\nUnder the hood:\n```bash\nsubprocess.run([\n  \"docker\", \"run\", \"--rm\", \"--network\", \"none\",\n  \"--memory\", \"512m\", \"--cpus\", \"1\",\n  \"-v\", \"/pocstore/CVE-2024-12345:/poc:ro\",\n  \"SecFlow-sandbox:latest\",\n  \"python3\", \"/poc/exploit.py\", \"--target\", \"https://staging.example.com\"\n])\n```yaml\n\n## \u2699\ufe0f PoC Execution Policy\n\n| Policy | Enforcement |\n|--------|-------------|\n| **Sandbox Only** | No PoC runs on host system. |\n| **Read-only Filesystem** | Prevents code modification or persistence. |\n| **No Network by Default** | All outbound connections blocked. |\n| **User Authorization** | Each run signed with user identity &amp; timestamp. |\n| **Logging &amp; Replay** | Stdout/stderr captured in audit logs. |\n| **Time-Bound Execution** | Hard kill if runtime exceeds `timeout_seconds`. |\n\n## \ud83e\udde0 Policy Configuration Example\n\n```yaml\n# ~/.SecFlow/policies/poc.yaml\nsandbox:\n  image: SecFlow-sandbox:latest\n  max_cpu: 1\n  max_memory_mb: 512\n  timeout_seconds: 300\n  allow_network: false\n  allow_filesystem_write: false\n\ncompliance:\n  require_disclaimer: true\n  require_project_authorization: true\n  auto_verify_hashes: true\n```python\n\n## \ud83e\udde9 Governance Logging\n\nEvery PoC-related event is appended to a tamper-resistant audit log:\n\n| Field | Description |\n|-------|-------------|\n| event_id | UUID of the audit entry |\n| user_id | Executing user |\n| timestamp | UTC ISO-8601 time |\n| action | e.g., \"sandbox_run\", \"download\", \"verify\" |\n| cve_id | Related CVE |\n| tool | Source or wrapper (e.g., \"exploitdb\") |\n| sandbox_id | Container identifier |\n| hash | SHA256 of PoC code |\n\n### Example Log Entry\n```json\n{\n  \"event_id\": \"a1f3b7c2-9f11-45d0-bc97-6c9472cbdcb2\",\n  \"user_id\": \"hernan\",\n  \"action\": \"sandbox_run\",\n  \"cve_id\": \"CVE-2024-12345\",\n  \"timestamp\": \"2025-10-06T10:43:00Z\",\n  \"sandbox_id\": \"sandbox-83214\",\n  \"hash\": \"b3f9f74e89e2a1b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0\",\n  \"tool\": \"exploitdb\"\n}\n```text\n\n## \ud83e\udde0 Legal Notice Enforcement\n\nBefore any PoC interaction, users must sign a legal disclaimer:\n\n```python\nResponsible Use Notice:\nYou acknowledge that PoC exploitation is to be performed exclusively on systems you own or are explicitly authorized to test. SecFlow is not liable for any misuse or damages resulting from unauthorized use.\n```text\n\nThe system stores an acceptance hash:\n```yaml\n~/.SecFlow/.disclaimer_accepted\n```yaml\n\n## \ud83e\udde9 Cross-Project PoC Access\n\nTo prevent accidental disclosure:\n- PoC artifacts are scoped per project by default.\n- Shared PoCs require explicit admin approval.\n- Access controlled via role-based permissions (RBAC).\n\n| Role | Access |\n|------|--------|\n| **Admin** | Global &amp; project PoCs |\n| **Analyst** | Project PoCs only |\n| **Viewer** | Read-only (metadata only) |\n\n## \ud83e\uddf1 PoC Verification Workflow\n\n```mermaid\ngraph TD\nA[Download PoC] --&gt; B[Verify Hash &amp; Signature]\nB --&gt; C{Trusted Source?}\nC --&gt;|Yes| D[Mark Verified]\nC --&gt;|No| E[Quarantine]\nE --&gt; F[Manual Review Required]\nD --&gt; G[Available for Sandbox Run]\n```text\n\n## \ud83d\udd12 Quarantine Mechanism\n\nUnknown or tampered PoCs are moved to:\n```text\n~/.SecFlow/resources/poc/quarantine/\n```python\n\nEach is tagged with a quarantine reason.\nAdmins can review and promote back to verified status.\n\n```python\ndef quarantine_poc(poc_id: str, reason: str):\n    shutil.move(f\"/pocstore/{poc_id}\", \"/pocstore/quarantine/\")\n    write_log(f\"PoC {poc_id} quarantined: {reason}\")\n```text\n\n## \ud83e\udde0 Example Execution Trace\n\n```text\n[PoC: CVE-2024-12345] Verified source: ExploitDB\n[Sandbox] Starting container SecFlow-sandbox:latest\n[Sandbox] CPU quota: 1 core, Memory: 512MB\n[Sandbox] Network: disabled\n[Output]\n    [+] Exploit successful: remote command executed\n[Cleanup]\n    PoC container destroyed after 120s\n</code></pre>"},{"location":"architecture/14-poc-sources-and-legal-guidelines/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>AppArmor enforcement policies with dynamic runtime profiling.</li> <li>PoC provenance blockchain for cryptographic integrity.</li> <li>AI-assisted PoC safety classification (RCE, DoS, PrivEsc).</li> <li>Multi-tenant isolation for collaborative workspaces.</li> <li>Live replay of PoC runs for training and documentation.</li> </ul> <p>Next: Garbage Collection &amp; Data Retention Policy</p>"},{"location":"architecture/15-garbage-collection-and-retention/","title":"15 \u2014 Garbage Collection &amp; Data Retention Policy","text":""},{"location":"architecture/15-garbage-collection-and-retention/#overview","title":"\ud83e\udded Overview","text":"<p>The Garbage Collection (GC) subsystem ensures long-term maintainability and performance of the SecFlow platform. It automates the cleanup of: - Expired runs and temporary results - Deleted project data (findings, resources, logs) - Old cache entries and transient files - Obsolete resources (e.g., old templates or wordlists)  </p> <p>GC operates as an asynchronous background service within the <code>worker</code> app and supports both soft-delete and hard-delete modes.</p>"},{"location":"architecture/15-garbage-collection-and-retention/#core-objectives","title":"\u2699\ufe0f Core Objectives","text":"Objective Description Consistency Prevent orphaned or dangling records (runs, findings). Recoverability Allow temporary undo (via soft delete + TTL). Auditability Maintain logs of every GC event for compliance. Efficiency Keep database and disk footprint minimal. Isolation Per-project retention scopes (independent cleanup)."},{"location":"architecture/15-garbage-collection-and-retention/#architecture-diagram","title":"\ud83e\udde9 Architecture Diagram","text":"<pre><code>+---------------------------------------------+\n|                Worker App                   |\n| - GC Scheduler (Celery Beat)               |\n| - GC Worker (Async Cleanup Tasks)          |\n| - Retention Policy Manager                  |\n| - Audit Trail Logger                        |\n+---------------------------------------------+\n        \u2502\n        \u25bc\n+---------------------------------------------+\n|         Persistent Storage Layer            |\n| - DB Tables: projects, runs, findings, logs |\n| - FS Paths: /resources, /cache, /artifacts  |\n+---------------------------------------------+\n```python\n\n---\n\n## \ud83e\udde9 Retention Model\n\nEach project defines its **retention profile** in `~/.SecFlow/projects/&lt;id&gt;/config.yaml`:\n\n```yaml\nretention:\n  findings_ttl_days: 180\n  runs_ttl_days: 90\n  cache_ttl_days: 30\n  artifacts_ttl_days: 180\n  soft_delete_ttl_days: 14\n  auto_cleanup: true\n```yaml\n\n## \ud83e\uddf1 Data Lifecycle\n\n| Stage | Description |\n|-------|-------------|\n| **Active** | Data used by ongoing projects or workflows. |\n| **Soft Deleted** | Marked for deletion but restorable (`flag: deleted=true`). |\n| **Expired** | TTL exceeded; scheduled for cleanup. |\n| **Hard Deleted** | Permanently removed after grace period. |\n\n## \ud83e\udde0 Database-Level Soft Delete\n\n```python\nclass BaseModel(SQLModel):\n    id: UUID\n    created_at: datetime\n    updated_at: datetime\n    deleted: bool = False\n    deleted_at: Optional[datetime] = None\n```python\n\nWhen a record is soft-deleted:\n\n```python\ndef soft_delete(obj):\n    obj.deleted = True\n    obj.deleted_at = datetime.utcnow()\n    session.add(obj)\n    session.commit()\n```python\n\nRecovery:\n\n```python\ndef restore(obj):\n    obj.deleted = False\n    obj.deleted_at = None\n    session.commit()\n```text\n\n## \ud83e\udde9 File System Garbage Collector\n\n### Directory Structure\n```text\n/data/\n \u251c\u2500\u2500 projects/\n \u2502   \u251c\u2500\u2500 &lt;project_id&gt;/\n \u2502   \u2502   \u251c\u2500\u2500 findings/\n \u2502   \u2502   \u251c\u2500\u2500 runs/\n \u2502   \u2502   \u251c\u2500\u2500 logs/\n \u2502   \u2502   \u2514\u2500\u2500 artifacts/\n \u251c\u2500\u2500 cache/\n \u2514\u2500\u2500 tmp/\n```python\n\nThe GC worker traverses these trees periodically:\n\n```python\ndef sweep_directory(base_path: Path, older_than: timedelta):\n    now = datetime.utcnow()\n    for p in base_path.rglob(\"*\"):\n        if p.is_file() and (now - datetime.fromtimestamp(p.stat().st_mtime)) &gt; older_than:\n            p.unlink()\n```python\n\n## \ud83e\udde0 GC Task Scheduling\n\n### Celery Task Definition\n```python\n@app.task(name=\"gc.cleanup_expired\")\ndef cleanup_expired():\n    sweep_projects()\n    sweep_cache()\n    sweep_artifacts()\n```text\n\n### Scheduler Configuration\n```python\nCELERY_BEAT_SCHEDULE = {\n    \"cleanup-every-6h\": {\n        \"task\": \"gc.cleanup_expired\",\n        \"schedule\": crontab(hour=\"*/6\"),\n    },\n}\n```text\n\nGC tasks can be triggered manually:\n```bash\nSecFlow gc run --project acme-api\n```python\n\n## \ud83e\udde9 Retention Policy Evaluation\n\n### Example Policy Rules\n| Rule | Condition | Action |\n|------|-----------|--------|\n| Inactive Runs | Run ended &gt; 90 days ago | Delete run logs |\n| Soft-Deleted Findings | Deleted &gt; 14 days ago | Purge permanently |\n| Cache Expired | Cache entry older than 30 days | Remove |\n| Unused Artifacts | Artifact not accessed for 180 days | Archive or delete |\n\n### Policy Engine Snippet\n```python\ndef evaluate_retention(entity, policy):\n    if entity.deleted and expired(entity.deleted_at, policy.soft_delete_ttl_days):\n        hard_delete(entity)\n    elif expired(entity.updated_at, policy.findings_ttl_days):\n        soft_delete(entity)\n```text\n\n## \ud83e\udde9 Audit Logging for GC\n\nEach GC operation generates an audit record:\n\n```json\n{\n  \"event\": \"gc_delete\",\n  \"type\": \"finding\",\n  \"target_id\": \"f123-45ac\",\n  \"project_id\": \"p001\",\n  \"timestamp\": \"2025-10-06T09:30:00Z\",\n  \"user\": \"system\",\n  \"ttl_rule\": \"soft_delete_ttl_days=14\"\n}\n```text\n\nStored in:\n```text\n~/.SecFlow/audit/gc.log\n```python\n\n## \ud83e\uddf1 Orphan Detection\n\n### SQL Example\n```sql\nSELECT f.id\nFROM findings f\nLEFT JOIN runs r ON f.run_id = r.id\nWHERE r.id IS NULL;\n```python\n\nAny orphaned findings or artifacts (without associated runs/projects) are purged automatically.\n\n## \ud83e\udde9 Cache Lifecycle\n\nCaches (e.g., CVE data, scan results, tool logs) use a standardized interface:\n\n```python\nclass CacheEntry(BaseModel):\n    key: str\n    value: bytes\n    expires_at: datetime\n\ndef purge_expired():\n    session.query(CacheEntry).filter(CacheEntry.expires_at &lt; datetime.utcnow()).delete()\n```text\n\n## \ud83e\udde0 Manual Cleanup Command\n\nUsers can trigger GC manually via CLI:\n\n```bash\n# Run full cleanup (all projects)\nSecFlow gc run\n\n# Run cleanup for one project\nSecFlow gc run --project acme-api\n\n# Preview what will be deleted\nSecFlow gc dry-run\n```text\n\n### Example output:\n```text\n[GC] Found 12 expired runs, 4 orphaned findings, 6 stale cache entries\n[GC] Total reclaimed: 1.2 GB\n```text\n\n## \ud83d\udd10 Security Considerations\n\n- All deletions (soft or hard) are logged.\n- Data is never removed without audit trace.\n- System prevents GC while a project is locked or running.\n- Manual GC requires Admin role.\n\n## \ud83d\udd04 GC Metrics &amp; Observability\n\n| Metric | Description |\n|--------|-------------|\n| gc_runs_total | Number of GC cycles executed |\n| gc_files_removed_total | Number of files deleted |\n| gc_bytes_reclaimed_total | Storage reclaimed in bytes |\n| gc_duration_seconds | Time per GC cycle |\n| gc_errors_total | Failed cleanup operations |\n\nExposed via Prometheus at `/metrics`.\n\n## \ud83e\udde0 Example GC Cycle Log\n\n```text\n[GC] Cycle started at 2025-10-06T09:00:00Z\n[GC] Processed 3 projects\n[GC] Deleted 15 findings (soft)\n[GC] Purged 10 runs (hard)\n[GC] Reclaimed 1.8GB disk space\n[GC] Cycle completed in 42.3s\n</code></pre>"},{"location":"architecture/15-garbage-collection-and-retention/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Incremental snapshot pruning \u2014 keep only latest versions of runs.</li> <li>Policy-as-Code \u2014 customizable YAML rulesets.</li> <li>AI-based cleanup predictions \u2014 identify stale datasets dynamically.</li> <li>Storage quota enforcement per user/project.</li> <li>UI dashboard for retention and GC insights.</li> </ul> <p>Next: Security Model (RBAC, Authentication, Sandboxing)</p>"},{"location":"architecture/16-security-model/","title":"16 \u2014 Security Model (RBAC, Authentication, and Sandboxing)","text":""},{"location":"architecture/16-security-model/#overview","title":"\ud83e\udded Overview","text":"<p>Security is a first-class design goal in the SecFlow architecture. Every user action, process execution, and data mutation is subject to authentication, authorization, and sandboxing.</p> <p>This model ensures: - Strict access separation between users, projects, and data. - Controlled execution of potentially dangerous tools or PoCs. - Immutable auditability of all operations. - Zero-trust posture inside the orchestration environment.</p>"},{"location":"architecture/16-security-model/#layers-of-the-security-model","title":"\ud83e\udde9 Layers of the Security Model","text":"Layer Scope Mechanism Authentication User identity verification JWT / OAuth2 tokens Authorization (RBAC) Access control Role-based &amp; scope-aware Execution Sandboxing Process isolation Containerized runners Secrets Management API keys, credentials Encrypted vault Audit Logging Accountability Immutable append-only logs"},{"location":"architecture/16-security-model/#authentication-architecture","title":"\ud83e\udde0 Authentication Architecture","text":"<p>SecFlow supports two auth models: 1. Local Auth (default): For standalone or on-premise deployments. 2. Federated Auth (optional): OAuth2/OpenID Connect integration (GitHub, Google, Azure AD).</p>"},{"location":"architecture/16-security-model/#token-model","title":"Token Model","text":"<pre><code>{\n  \"sub\": \"hernan\",\n  \"role\": \"admin\",\n  \"exp\": 1738783200,\n  \"projects\": [\"proj-01\", \"proj-02\"]\n}\n```json\n\n### Token Flow Diagram\n```text\n[User Login] \u2192 [Auth Provider] \u2192 [JWT Issued] \u2192 [API Gateway] \u2192 [SecFlow Web/API]\n```text\n\nEach request to `/api/*` must include:\n```text\nAuthorization: Bearer &lt;token&gt;\n```text\n\nTokens are verified by the API middleware using RS256 signature validation.\n\n## \ud83e\udde9 Role-Based Access Control (RBAC)\n\nRoles define the scope of capabilities across the platform.\n\n| Role | Permissions |\n|------|-------------|\n| **Admin** | Full control \u2014 manage tools, users, projects, retention, policies. |\n| **Analyst** | Execute workflows, triage findings, view reports, limited editing. |\n| **Viewer** | Read-only access to results and dashboards. |\n| **Automation (Service)** | Used by background tasks (limited scoped tokens). |\n\n### Example permission matrix:\n\n| Action | Admin | Analyst | Viewer | Service |\n|--------|-------|---------|--------|---------|\n| Run workflow | \u2705 | \u2705 | \u274c | \u2705 |\n| Modify tool config | \u2705 | \u274c | \u274c | \u274c |\n| View findings | \u2705 | \u2705 | \u2705 | \u2705 |\n| Delete project | \u2705 | \u274c | \u274c | \u274c |\n| Access PoCs | \u2705 | \u2705 | \u274c | \u274c |\n| Run GC tasks | \u2705 | \u274c | \u274c | \u2705 |\n\n## \u2699\ufe0f Policy Enforcement\n\nEvery endpoint and command passes through an Access Policy Filter:\n\n```python\ndef authorize(action: str, user: User, project: Optional[str] = None):\n    if not user.has_permission(action, project):\n        raise HTTPException(403, detail=f\"Forbidden: {action}\")\n```python\n\n### Example route decorator:\n```python\n@app.get(\"/api/v1/findings\")\n@require_role([\"admin\", \"analyst\", \"viewer\"])\ndef list_findings():\n    def authorize(self, action: str, user: User, project: Optional[str] = None) -&gt; bool:\n        \"\"\"Check if user is authorized for action.\"\"\"\n        return user.has_permission(action, project)\n```python\n\n## \ud83e\uddf1 Secrets Management\n\n### Secret Types\n- API tokens for external tools (e.g., Shodan, Vulners)\n- Private SSH keys for remote scans\n- Encrypted credentials for authenticated targets\n\n### Storage Backend\nAll secrets are stored in the SecFlow Vault, an encrypted JSON database backed by Fernet (AES-256).\n\n```python\nclass SecretVault:\n    def __init__(self, keyfile: Path):\n        self.key = load_key(keyfile)\n    def store(self, id: str, data: dict):\n        enc = fernet_encrypt(json.dumps(data), self.key)\n        write_file(f\"/vault/{id}.enc\", enc)\n```python\n\n### Secrets CLI\n```bash\nSecFlow secrets add nuclei_api --value \"TOKEN123\"\nSecFlow secrets list\nSecFlow secrets remove nuclei_api\n```yaml\n\nAll access is scoped by user and project context.\n\n## \ud83d\udd12 Execution Sandboxing\n\nAll scanner and PoC executions run inside restricted containers or subprocess jails.\n\n### Isolation Techniques\n| Mechanism | Purpose |\n|-----------|---------|\n| Namespaces (PID, NET, MNT) | Process isolation |\n| Seccomp Filters | Syscall restriction |\n| cgroups v2 | CPU/memory limits |\n| No-root UID mapping | Drops privileges |\n| AppArmor profiles | File access control |\n| Read-only FS | Prevents persistence |\n\n### Example\n```bash\ndocker run --rm --cap-drop=ALL \\\n  --security-opt=no-new-privileges \\\n  --read-only -m 512m --cpus=1 \\\n  SecFlow-runner:latest nuclei -t /templates\n```python\n\n## \ud83e\udde9 Network &amp; Data Security\n\n| Channel | Encryption | Notes |\n|---------|------------|-------|\n| API &lt;-&gt; UI | HTTPS (TLS 1.3) | Strict transport enforced |\n| Worker &lt;-&gt; API | Mutual TLS | Each worker has its own cert |\n| File Sync | AES-256 encrypted | Optional compression |\n| Database | At-rest encryption | SQLite: SEE, Postgres: TDE |\n| Audit Logs | Signed + timestamped | Prevents tampering |\n\n## \ud83e\udde0 Secure Inter-Process Communication\n\nInternal apps communicate via ZeroMQ or Redis queues over TLS.\n\nEach message includes a signed envelope:\n\n```json\n{\n  \"msg_id\": \"uuid\",\n  \"issuer\": \"worker-1\",\n  \"signature\": \"HMAC-SHA256\",\n  \"payload\": {\"data\": \"encrypted_content\"}\n}\n```json\n\nThis ensures authenticity and non-repudiation.\n\n## \ud83e\udde9 Security Hooks &amp; Middleware\n\nSecFlow injects middleware for:\n- Request validation (pydantic schemas)\n- JWT token expiry verification\n- Role validation (fast-path lookup)\n- Audit log writing after each mutating operation\n\n### Example:\n```python\n@app.middleware(\"http\")\nasync def audit_request(request, call_next):\n    response = await call_next(request)\n    if request.method in (\"POST\", \"DELETE\", \"PATCH\"):\n        log_audit(request, response)\n    return response\n```yaml\n\n## \ud83d\udd10 Audit Trail &amp; Tamper Resistance\n\n### Log Format\n```json\n{\n  \"timestamp\": \"2025-10-06T09:40:00Z\",\n  \"user\": \"hernan\",\n  \"action\": \"workflow_run\",\n  \"project\": \"api-audit\",\n  \"status\": \"success\",\n  \"hash\": \"sha256:0a3b1c2d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2\"\n}\n```json\n\n### Storage &amp; Verification\n- Logs stored as JSON lines under `/audit/`\n- Each file signed with an HMAC chain:\n\n```python\nH_i = HMAC(H_prev + log_i, key)\n```yaml\n\nImmutable and verifiable chain-of-trust.\n\n## \ud83e\udde0 Security Monitoring\n\n| Metric | Description |\n|--------|-------------|\n| auth_failures_total | Failed login attempts |\n| sandbox_executions_total | Containers spawned |\n| policy_violations_total | Unauthorized actions |\n| vault_accesses_total | Secret retrievals |\n| audit_events_total | Log entries recorded |\n\n## \u2699\ufe0f Compliance Framework Alignment\n\nSecFlow's security architecture aligns with:\n\n| Framework | Compliance Area |\n|-----------|-----------------|\n| **NIST SP 800-53** | Access control, auditing, system protection |\n| **ISO/IEC 27001** | Information security management |\n| **OWASP SAMM** | Secure software development lifecycle |\n| **MITRE ATT&amp;CK** | Mapping detection behaviors |\n| **GDPR Art. 32** | Data confidentiality and integrity |\n\n## \ud83d\udd12 Key Rotation &amp; Secrets Expiry\n\n- Secrets have explicit TTLs (default: 180 days).\n- Vault rotation command:\n\n```bash\nSecFlow vault rotate\n```text\n\nRotation regenerates the encryption key and re-encrypts all entries.\n\n## \ud83e\udde9 Example Access Workflow\n\n```text\n[Analyst] \u2192 [Login via OIDC] \u2192 [JWT Issued]\n\u2192 [UI/API Gateway] \u2192 [RBAC Policy Check]\n\u2192 [Worker Executes Workflow in Sandbox]\n\u2192 [Findings Logged + Audit Entry Created]\n</code></pre>"},{"location":"architecture/16-security-model/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Hardware-backed encryption (YubiKey / TPM) for Vault keys.</li> <li>FIPS-compliant container sandbox.</li> <li>Behavior-based anomaly detection on audit logs.</li> <li>Single Sign-On (SSO) with just-in-time role provisioning.</li> <li>Runtime policy engine (OPA / Rego integration).</li> </ul> <p>Next: Observability, Logging &amp; Metrics</p>"},{"location":"architecture/17-observability-logging-and-metrics/","title":"17 \u2014 Observability, Logging, Metrics &amp; Tracing","text":""},{"location":"architecture/17-observability-logging-and-metrics/#overview","title":"\ud83e\udded Overview","text":"<p>The Observability Layer provides full transparency into the runtime behavior of SecFlow. It enables developers, analysts, and operators to: - Track system health and performance metrics. - Trace workflow execution across tools and workers. - Monitor logs and alerts from all layers (API, Worker, Sandbox). - Correlate findings, runs, and audit trails with unique identifiers.</p> <p>The observability system is standards-based, built upon: - OpenTelemetry (OTel) for tracing and context propagation. - Prometheus for metrics export. - JSON structured logging for event correlation. - Grafana dashboards for visualization.</p>"},{"location":"architecture/17-observability-logging-and-metrics/#observability-architecture-overview","title":"\ud83e\uddf1 Observability Architecture Overview","text":"<pre><code>+--------------------------------------------------------------+\n|                    SecFlow Stack                             |\n| API Layer \u2192 Structured Logging, Metrics, Tracing            |\n| Worker \u2192 Task Metrics, Workflow Spans, Sandbox Logs         |\n| Sandbox \u2192 Runtime Metrics, Security Telemetry                |\n| Database \u2192 Query Timing, Connection Pool Stats              |\n--------------------------------------------------------------\n| Exporters \u2192 Prometheus (Metrics), OTLP (Traces), Loki (Logs)|\n+--------------------------------------------------------------+\n```yaml\n\n---\n\n## \ud83e\udde9 Logging Subsystem\n\n### Logging Design Goals\n| Goal | Implementation |\n|-------|----------------|\n| **Machine-readable** | JSON structured format with standard fields |\n| **Correlated across systems** | `trace_id` and `span_id` included |\n| **Context-aware** | User, project, workflow metadata embedded |\n| **Immutable** | Append-only, timestamped, HMAC-signed if required |\n\n### Log Record Example\n\n```json\n{\n  \"timestamp\": \"2025-10-06T09:45:32Z\",\n  \"level\": \"INFO\",\n  \"service\": \"worker\",\n  \"trace_id\": \"cbd82b67-4a2b-4db6-9a90-1c3ed1b7e203\",\n  \"span_id\": \"4f7c2b91\",\n  \"project\": \"acme-api\",\n  \"workflow_id\": \"wf-abc123\",\n  \"message\": \"Nuclei scan completed successfully\",\n  \"duration_ms\": 34215\n}\n```text\n\n### Logging Stack\n- **Python Logging + Structlog** \u2014 base structured logs.\n- **OpenTelemetry LoggingHandler** \u2014 trace context propagation.\n- **Loki Exporter** \u2014 for central log aggregation (optional).\n\n### Configuration snippet:\n```json\nLOGGING = {\n  \"version\": 1,\n  \"formatters\": {\"json\": {\"()\": \"pythonjsonlogger.jsonlogger.JsonFormatter\"}},\n  \"handlers\": {\n    \"console\": {\"class\": \"logging.StreamHandler\", \"formatter\": \"json\"},\n  },\n  \"root\": {\"level\": \"INFO\", \"handlers\": [\"console\"]},\n}\n```json\n\n## \u2699\ufe0f Log Levels &amp; Policies\n\n| Level | Description |\n|-------|-------------|\n| **DEBUG** | Developer-only context, disabled by default in production. |\n| **INFO** | System lifecycle and status messages. |\n| **WARNING** | Recoverable issues, retryable errors. |\n| **ERROR** | Failures in user-triggered operations. |\n| **CRITICAL** | Irrecoverable errors (sandbox isolation breach, DB corruption). |\n\nRetention policy for logs follows the GC subsystem (see [15-garbage-collection-and-retention.md](15-garbage-collection-and-retention.md)).\n\n## \ud83e\udde0 Trace Propagation &amp; Distributed Context\n\nSecFlow uses OpenTelemetry (OTel) for distributed tracing.\nEvery API request, task dispatch, and plugin call generates spans linked under one root trace.\n\n### Example Trace Structure\n```text\nTraceID: 5b2e4f21c9a344f9\n\u2514\u2500\u2500 api.request (GET /api/v1/workflows)\n    \u251c\u2500\u2500 worker.dispatch\n    \u2502   \u251c\u2500\u2500 tool.nuclei.run\n    \u2502   \u2502   \u251c\u2500\u2500 sandbox.spawn\n    \u2502   \u2502   \u2514\u2500\u2500 sandbox.cleanup\n    \u2502   \u251c\u2500\u2500 tool.ferox.run\n    \u2502   \u2514\u2500\u2500 findings.persist\n    \u2514\u2500\u2500 api.response\n```text\n\n### Code Example\n```python\nfrom opentelemetry import trace\n\ntracer = trace.get_tracer(\"SecFlow.worker\")\n\nwith tracer.start_as_current_span(\"workflow.execute\") as span:\n    span.set_attribute(\"workflow.id\", workflow.id)\n    run_workflow(workflow)\n```text\n\nAll traces are exported through OTLP gRPC to the observability backend (e.g., Tempo, Jaeger).\n\n## \ud83d\udcca Metrics System\n\nSecFlow exposes runtime metrics through Prometheus-compatible endpoints.\n\n### Default Endpoint\n```text\n/metrics\n```text\n\n### Example Metrics\n| Metric | Type | Description |\n|--------|------|-------------|\n| secflow_requests_total | Counter | Total API requests handled |\n| secflow_active_workflows | Gauge | Currently running workflows |\n| secflow_findings_generated_total | Counter | Findings created |\n| secflow_task_duration_seconds | Histogram | Time taken by async tasks |\n| secflow_gc_bytes_reclaimed_total | Counter | GC reclaimed bytes |\n| secflow_sandbox_executions_total | Counter | Number of sandbox runs |\n| secflow_tool_failures_total | Counter | Failed tool executions |\n| secflow_worker_queue_depth | Gauge | Pending Celery tasks |\n| secflow_cve_enrichment_latency_seconds | Histogram | Time per CVE query |\n\n### Prometheus Export Example\n```python\nfrom prometheus_client import Counter, Gauge\n\nfindings_total = Counter(\"secflow_findings_generated_total\", \"Number of findings created\")\nactive_workflows = Gauge(\"secflow_active_workflows\", \"Currently running workflows\")\n```yaml\n\n## \ud83d\udd0d Example Grafana Dashboard Panels\n\n| Panel | Visualization | Query |\n|-------|---------------|-------|\n| Workflow Throughput | Time series | `rate(secflow_requests_total[5m])` |\n| Average Scan Duration | Histogram | `histogram_quantile(0.9, rate(secflow_task_duration_seconds_bucket[5m]))` |\n| Findings per Project | Bar chart | `sum by (project)(secflow_findings_generated_total)` |\n| GC Efficiency | SingleStat | `rate(secflow_gc_bytes_reclaimed_total[1h])` |\n| Sandbox Failures | Table | `secflow_tool_failures_total` |\n\n## \ud83e\udde9 Error Correlation &amp; Incident Debugging\n\nEvery finding, workflow, and audit entry includes a trace ID.\nErrors can be traced back to exact processes and spans.\n\n### Example correlation:\n```text\nFinding \u2192 Workflow ID: wf-abc123 \u2192 Trace ID: cbd82b67a1e4f9d2c8b5e6f7a3d4c9e2b1f8a5c6d7e9f2a3b4c5d6e7f8a9b2c3d4e5f6\n\u2192 Logs: worker.log\n\u2192 Span: tool.nuclei.run\n```python\n\nThis guarantees reproducibility and fast RCA (root cause analysis).\n\n## \ud83e\udde0 Alerting &amp; Health Checks\n\n### Health Endpoints\n| Endpoint | Description |\n|----------|-------------|\n| `/healthz` | Liveness probe (basic app status) |\n| `/readyz` | Readiness probe (DB + cache + queue connectivity) |\n\n### Example Output\n```json\n{\n  \"status\": \"ok\",\n  \"services\": {\n    \"database\": \"up\",\n    \"cache\": \"up\",\n    \"worker\": \"idle\"\n  }\n}\n```yaml\n\n### Alerts (Prometheus Rules)\n```yaml\ngroups:\n  - name: secflow_alerts\n    rules:\n      - alert: HighErrorRate\n        expr: rate(secflow_tool_failures_total[5m]) &gt; 5\n        for: 10m\n        labels: { severity: warning }\n        annotations:\n          summary: \"Tool failure rate too high\"\n```python\n\n## \ud83d\udd12 Security of Observability Data\n\n| Concern | Mitigation |\n|---------|------------|\n| Sensitive logs | Field redaction (password, token, secret) |\n| Trace integrity | HMAC signing of exported spans |\n| Log tampering | Append-only JSONL + rotation |\n| Metrics abuse | Authenticated `/metrics` endpoint (basic token or mutual TLS) |\n\n### Example redaction middleware:\n```python\ndef sanitize(data: dict) -&gt; dict:\n    for key in data.keys():\n        if \"token\" in key.lower() or \"password\" in key.lower():\n            data[key] = \"[REDACTED]\"\n    return data\n```text\n\n## \ud83e\uddf1 Correlation Example: End-to-End Trace\n\n```bash\n[TRACE 5b2e4f21c9a344f9]\n\u2514\u2500\u2500 /api/v1/workflows/start\n    \u251c\u2500\u2500 worker.queue.dispatch (duration=12ms)\n    \u251c\u2500\u2500 tool.ferox.run (duration=4.1s)\n    \u251c\u2500\u2500 tool.nuclei.run (duration=9.3s)\n    \u251c\u2500\u2500 enrich.cve (duration=1.4s)\n    \u251c\u2500\u2500 findings.persist (duration=320ms)\n    \u2514\u2500\u2500 audit.log (duration=7ms)\n```bash\n\n## \ud83e\udde9 Integration with CI/CD and Testing\n\nDuring CI runs:\n- Unit and integration tests export OTel traces for regression analysis.\n- Performance tests measure task durations and error rates.\n\n### Example CI configuration:\n```yaml\nenv:\n  OTEL_EXPORTER_OTLP_ENDPOINT: \"http://otel-collector:4317\"\n  PROMETHEUS_MULTIPROC_DIR: \"/tmp/metrics\"\n</code></pre>"},{"location":"architecture/17-observability-logging-and-metrics/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Distributed tracing for multi-cluster deployments.</li> <li>Real-time log streaming to the web UI.</li> <li>AI-assisted anomaly detection for workflow performance.</li> <li>Adaptive sampling for trace volume reduction.</li> <li>On-demand debug mode via CLI flag (<code>--trace verbose</code>).</li> </ul> <p>Next: Error Handling &amp; Recovery</p>"},{"location":"architecture/18-error-handling-and-recovery/","title":"18 \u2014 Error Handling, Fault Tolerance &amp; Recovery Architecture","text":""},{"location":"architecture/18-error-handling-and-recovery/#overview","title":"\ud83e\udded Overview","text":"<p>SecFlow is designed to operate in unpredictable environments \u2014 remote APIs, external security tools, local sandboxes, and asynchronous task queues. This chapter defines the resilience layer of the platform, ensuring that the system can detect, contain, recover, and self-heal from errors without compromising data integrity or user experience.</p>"},{"location":"architecture/18-error-handling-and-recovery/#core-resilience-principles","title":"\ud83e\uddf1 Core Resilience Principles","text":"Principle Description Isolation Failures in one tool or workflow should not cascade. Retryability Transient failures should automatically reattempt. Idempotency Repeated executions must produce consistent outcomes. Observability Every error must be traceable with full context. Graceful Degradation System continues partially even under partial failure."},{"location":"architecture/18-error-handling-and-recovery/#error-taxonomy","title":"\u2699\ufe0f Error Taxonomy","text":"<p>Errors are classified to determine handling strategy:</p> Type Example Recovery Strategy Transient Network timeout, rate-limit, temporary unavailability Retry with exponential backoff Permanent Invalid config, missing file, malformed schema Fail fast, log, require user fix External Tool Nuclei crash, Feroxbuster exit code \u2260 0 Capture stdout/stderr, mark node failed Internal Logic Python exception, schema mismatch Rollback transaction, log critical Security Violation Sandbox breakout, unauthorized access Immediate isolation + alert User Abort Manual workflow stop Graceful cancellation, cleanup resources"},{"location":"architecture/18-error-handling-and-recovery/#error-handling-architecture","title":"\ud83e\udde9 Error Handling Architecture","text":"<pre><code>+------------------------------------------+\n|              Workflow Engine             |\n| - Retry Controller                       |\n| - Error Propagation Manager              |\n| - Compensation Handlers                  |\n| - Dead Letter Queue                      |\n+------------------------------------------+\n      \u2502\n      \u25bc\n+------------------------------------------+\n|     Observability &amp; Audit Log            |\n+------------------------------------------+\n```python\n\n---\n\n## \ud83e\udde0 Exception Handling Model\n\nAll SecFlow components use a unified exception hierarchy:\n\n```python\nclass SecFlowError(Exception):\n    \"\"\"Base class for all SecFlow exceptions.\"\"\"\n\nclass TransientError(SecFlowError):\n    \"\"\"Recoverable error, eligible for retry.\"\"\"\n\nclass PermanentError(SecFlowError):\n    \"\"\"Non-recoverable error, must be logged and halted.\"\"\"\n\nclass SecurityError(SecFlowError):\n    \"\"\"Unauthorized or unsafe action detected.\"\"\"\n```python\n\nEvery operation that might fail is wrapped in a retry-safe decorator.\n\n## \ud83d\udd01 Retry Logic &amp; Tenacity Integration\n\nSecFlow uses the Tenacity library for intelligent retries.\n\n```python\nfrom tenacity import retry, wait_exponential, stop_after_attempt\n\n@retry(\n    wait=wait_exponential(multiplier=1, min=2, max=30),\n    stop=stop_after_attempt(5),\n    retry_error_callback=lambda r: log_error(r)\n)\ndef run_tool(tool_name, args):\n    return subprocess.run(args, check=True)\n```python\n\n### Retry Rules\n| Context | Max Retries | Delay Type |\n|---------|-------------|------------|\n| API HTTP Requests | 5 | Exponential |\n| CVE Enrichment Queries | 3 | Linear |\n| Worker Tasks | 3 | Exponential |\n| File System Operations | 2 | Immediate |\n| PoC Sandbox Launch | 1 | No retry (for safety) |\n\n## \ud83e\uddf1 Circuit Breaker Pattern\n\nSecFlow prevents repeated failures from overloading systems via circuit breakers.\n\n### Implementation Example\n```python\nclass CircuitBreaker:\n    def __init__(self, threshold=5, timeout=60):\n        self.failures = 0\n        self.opened_at = None\n        self.threshold = threshold\n        self.timeout = timeout\n\n    def record_failure(self):\n        self.failures += 1\n        if self.failures &gt;= self.threshold:\n            self.opened_at = datetime.utcnow()\n\n    def can_execute(self):\n        if not self.opened_at:\n            return True\n        return (datetime.utcnow() - self.opened_at).seconds &gt; self.timeout\n```python\n\nUsed for:\n- Remote API (NVD, OSV, Exploit-DB)\n- File I/O saturation\n- Tool wrappers under repeated crashes\n\n## \ud83e\udde9 Dead Letter Queue (DLQ)\n\nFailed tasks that exceed retry limits are pushed into the DLQ for manual review.\n\n```python\n@app.task(bind=True, max_retries=3)\ndef run_scan(self, task_id):\n    try:\n        run_workflow(task_id)\n    except Exception as e:\n        if self.request.retries == self.max_retries:\n            enqueue_dlq(task_id, str(e))\n        raise self.retry(exc=e)\n```text\n\n### DLQ entries include:\n- Task ID\n- Workflow ID\n- Exception message\n- Retry count\n- Timestamp\n\n### Example DLQ record:\n```json\n{\n  \"task\": \"wf-1234-node-nuclei\",\n  \"error\": \"Connection timeout to target\",\n  \"retries\": 3,\n  \"timestamp\": \"2025-10-06T10:22:00Z\"\n}\n```text\n\n## \ud83e\udde0 Self-Healing Workflows\n\nSecFlow supports automatic node rehydration \u2014 failed steps in a workflow can be restarted independently without restarting the entire pipeline.\n\n### Rehydration Process\n1. Detect failed node.\n2. Mark upstream outputs as valid.\n3. Restart failed node only.\n4. Merge results into workflow graph.\n\n### CLI example:\n```bash\nSecFlow workflow resume --node nuclei --project acme-api\n```python\n\n## \ud83e\udde9 Transactional Integrity\n\nDatabase operations are wrapped in ACID transactions using SQLModel context managers:\n\n```python\nfrom sqlmodel import Session\n\ndef save_finding(finding):\n    with Session(engine) as session:\n        try:\n            session.add(finding)\n            session.commit()\n        except Exception:\n            session.rollback()\n            raise\n```text\n\nAll cross-project mutations (findings, triage, cache) are transactional.\n\n## \ud83e\udde0 Error Event Logging &amp; Correlation\n\nEach exception generates an audit entry:\n\n```json\n{\n  \"event\": \"error\",\n  \"component\": \"worker\",\n  \"type\": \"TransientError\",\n  \"workflow_id\": \"wf-abc123\",\n  \"trace_id\": \"b73f0b7c-47f9-4bb3-9b9c-ffacbd1d6a67\",\n  \"message\": \"Feroxbuster timeout\",\n  \"retries\": 3\n}\n```yaml\n\nErrors are correlated with:\n- Workflow Trace ID\n- Finding UUID (if relevant)\n- User and project context\n\nThis allows full replay and debugging via observability dashboards.\n\n## \u2699\ufe0f Graceful Degradation\n\nIf a subsystem fails (e.g., enrichment API offline):\n- Workflows continue with reduced functionality.\n- Missing data marked as `\"partial\": true`.\n- Users notified in the triage panel:\n\n```text\n\u26a0 CVE enrichment service temporarily unavailable \u2014 retry later.\n```python\n\n## \ud83e\udde9 Alerting &amp; Notification Hooks\n\n- Integration with Prometheus Alertmanager for system errors.\n- Optional Slack / Email webhook for high-severity failures.\n- Rate-limited notifications to avoid alert fatigue.\n\n### Example alert webhook payload:\n```json\n{\n  \"severity\": \"critical\",\n  \"component\": \"sandbox\",\n  \"message\": \"PoC execution timeout\",\n  \"project\": \"api-audit\",\n  \"trace_id\": \"a2c134b5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8\"\n}\n```python\n\n## \ud83e\uddf1 Recovery Strategies\n\n| Context | Recovery Action |\n|---------|-----------------|\n| Sandbox crash | Auto-restart with clean container |\n| API outage | Retry with backoff + circuit breaker |\n| Tool misconfiguration | Disable tool temporarily, notify user |\n| Cache corruption | Rebuild from source |\n| Disk full | Trigger GC and alert |\n| Worker crash | Celery task re-queued |\n| DB lock contention | Exponential backoff retry |\n\n## \ud83e\udde0 Example Error Lifecycle\n\n```text\n[Error Detected] \u2192 [Retry 1/3] \u2192 [Retry 2/3] \u2192 [DLQ]\n\u2192 [Alert sent to Slack] \u2192 [Analyst re-runs workflow node] \u2192 [Recovered]\n```text\n\n## \ud83d\udd12 Security Implications\n\n- Sensitive stack traces are redacted before exposure.\n- Error details logged internally only.\n- External responses use generic safe messages:\n\n```json\n{\"error\": \"Internal processing issue, please retry later.\"}\n</code></pre>"},{"location":"architecture/18-error-handling-and-recovery/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Adaptive retry policies based on machine learning.</li> <li>AI-powered incident summarization for triage.</li> <li>Transactional outbox pattern for guaranteed task delivery.</li> <li>Fine-grained chaos testing integrated in CI/CD.</li> </ul> <p>Next: Risk Assessment &amp; Scoring Framework</p>"},{"location":"architecture/19-risk-assessment-framework/","title":"19 \u2014 Risk Assessment, Scoring &amp; Prioritization Framework","text":""},{"location":"architecture/19-risk-assessment-framework/#overview","title":"\ud83e\udded Overview","text":"<p>The Risk Assessment Framework in SecFlow provides a consistent and transparent way to evaluate and prioritize vulnerabilities across multiple projects and tools. It merges four complementary standards:</p> <ol> <li>NIST 5\u00d75 Matrix \u2014 contextual risk evaluation (Impact \u00d7 Likelihood).  </li> <li>CVSS v3.1 \u2014 standardized vulnerability severity scoring.  </li> <li>CWE / OWASP Mapping \u2014 weakness classification.  </li> <li>MITRE ATT&amp;CK Correlation \u2014 adversarial behavior context.</li> </ol> <p>This layered model supports both quantitative (numeric scores) and qualitative (High/Critical/etc.) analysis for triage and reporting.</p>"},{"location":"architecture/19-risk-assessment-framework/#architecture-overview","title":"\ud83e\uddf1 Architecture Overview","text":"<pre><code>+-------------------------------------------------------------+\n|                SecFlow Risk Engine                          |\n| - CVSS Normalizer (from findings or enrichment)            |\n| - NIST 5\u00d75 Contextual Matrix                               |\n| - MITRE ATT&amp;CK Mapper                                      |\n| - Risk Aggregator &amp; Scorer                                 |\n| - Project Risk Dashboard                                   |\n+-------------------------------------------------------------+\n```yaml\n\n---\n\n## \u2699\ufe0f Core Objectives\n\n| Goal | Description |\n|------|-------------|\n| **Standardization** | Consistent risk scoring across tools and projects. |\n| **Transparency** | Traceable logic behind every score. |\n| **Extensibility** | Pluggable scoring policies (per organization). |\n| **Automation** | Auto-scoring during enrichment and triage. |\n| **Context-Awareness** | Includes exploitability, exposure, and asset criticality. |\n\n---\n\n## \ud83e\uddf1 Scoring Pipeline\n\n```text\nFinding\n   \u2193\nCVSS Vector Parsing\n   \u2193\nCWE / OWASP Classification\n   \u2193\nExploit &amp; Exposure Context\n   \u2193\nNIST Risk Matrix Evaluation\n   \u2193\nFinal Risk Score (0\u2013100) + Risk Tier\n```text\n\n---\n\n## \ud83e\udde0 CVSS Normalization\n\nSecFlow ingests CVSS vectors either from NVD (via enrichment) or tool metadata.\n\n### Example:\n```text\nCVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\n```text\n\nConverted into internal representation:\n```json\n{\n  \"base_score\": 9.8,\n  \"impact_subscore\": 5.9,\n  \"exploitability_subscore\": 3.9,\n  \"vector\": \"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\"\n}\n```json\n\nIf missing, heuristic fallback is applied based on CWE ID or OWASP category (see [13-cve-cwe-poc-enrichment-layer.md](13-cve-cwe-poc-enrichment-layer.md)).\n\n## \ud83e\udde9 CWE / OWASP Mapping\n\n| CWE ID | OWASP Category | Default Impact | Default Likelihood |\n|--------|----------------|----------------|-------------------|\n| 79 | A03: Injection | High | High |\n| 89 | A03: Injection | Very High | High |\n| 200 | A01: Broken Access Control | High | Medium |\n| 601 | A10: SSRF | Medium | Medium |\n| 787 | A05: Buffer Overflow | Critical | Medium |\n| 352 | A08: CSRF | Medium | High |\n\nMappings are maintained in `/resources/mappings/cwe_owasp.json`.\n\n## \ud83e\udde0 MITRE ATT&amp;CK Mapping\n\nFindings enriched with ATT&amp;CK technique IDs (TIDs) during correlation (see [13-cve-cwe-poc-enrichment-layer.md](13-cve-cwe-poc-enrichment-layer.md)) are leveraged to infer attack chain context.\n\n| MITRE Technique ID | Tactic | Effect |\n|-------------------|--------|--------|\n| T1059.007 | Execution | Cross-Site Scripting |\n| T1505.003 | Persistence | SQL Injection |\n| T1071.001 | Command &amp; Control | Web Protocols |\n| T1190 | Initial Access | Exploit Public-Facing App |\n\nThis mapping helps classify whether the finding affects initial compromise, lateral movement, or data exfiltration.\n\n## \u2699\ufe0f NIST 5\u00d75 Risk Matrix\n\n### Definition\n| Impact \u2193 / Likelihood \u2192 | Very Low | Low | Medium | High | Very High |\n|------------------------|----------|-----|--------|------|-----------|\n| **Very High** | Medium | High | High | Critical | Critical |\n| **High** | Low | Medium | High | High | Critical |\n| **Medium** | Low | Low | Medium | High | High |\n| **Low** | Low | Low | Low | Medium | High |\n| **Very Low** | Low | Low | Low | Low | Medium |\n\n### Mapping to Severity\n| Result | Score Range | Label |\n|--------|-------------|-------|\n| Critical | 90\u2013100 | \ud83d\udd25 |\n| High | 70\u201389 | \u26a0\ufe0f |\n| Medium | 40\u201369 | \u2696\ufe0f |\n| Low | 20\u201339 | \ud83e\udde9 |\n| Informational | 0\u201319 | \u2139\ufe0f |\n\n## \ud83e\udde9 Likelihood Factors\n\nLikelihood is dynamically computed using multiple context sources:\n\n| Factor | Description | Weight |\n|--------|-------------|--------|\n| Exploit Availability | Known PoC, KEV presence | +0.3 |\n| Network Exposure | Publicly reachable target | +0.25 |\n| Authentication Required | Lowers likelihood if true | -0.15 |\n| Complexity | Tool-derived complexity | \u00b10.1 |\n| Detection Confidence | Based on finding engine | \u00b10.2 |\n\n### Pseudo-code:\n```python\ndef likelihood_score(finding):\n    score = 0.3 if finding.poc_available else 0\n    if finding.exposure == \"internet\": score += 0.25\n    if finding.auth_required: score -= 0.15\n    if finding.complexity == \"low\": score += 0.1\n    return min(max(score, 0), 1)\n```python\n\n## \ud83e\udde0 Impact Factors\n\nImpact combines technical and business context:\n\n| Factor | Example | Weight |\n|--------|---------|--------|\n| Confidentiality | Data exposure | +0.3 |\n| Integrity | Tampering possible | +0.3 |\n| Availability | Service crash, DoS | +0.2 |\n| Privilege Escalation | Root/system access | +0.2 |\n| Asset Criticality | System importance | +0.4 |\n\nFinal impact = weighted sum normalized to 1.0.\n\n## \u2699\ufe0f Combined Risk Formula\n\nFinal quantitative risk score (0\u2013100):\n\n```python\nrisk_score = ((CVSS_base / 10) * 0.6 + impact_factor * 0.25 + likelihood_factor * 0.15) * 100\n```python\n\nRounded to nearest integer.\n\n### Example\n| Metric | Value |\n|--------|-------|\n| CVSS Base | 9.8 |\n| Impact Factor | 0.8 |\n| Likelihood Factor | 0.7 |\n| Final Score | `((0.98*0.6)+(0.8*0.25)+(0.7*0.15))*100 = 89.7` \u2192 **High** |\n\n## \ud83e\udde0 Contextual Adjustments\n\nCertain contexts modify final risk score:\n\n| Context | Adjustment |\n|---------|------------|\n| Active exploit in wild (CISA KEV) | +10 |\n| Proof-of-concept verified | +5 |\n| Patched version available | -5 |\n| Internal-only system | -10 |\n| Compensating controls present | -15 |\n\nScores are capped at 100 and floored at 0.\n\n## \ud83e\udde9 Aggregated Risk Dashboard\n\nEach project's analytics tab visualizes:\n\n| Metric | Description |\n|--------|-------------|\n| Average CVSS per project | |\n| Top 10 findings by risk score | |\n| Risk evolution over time | |\n| Distribution by OWASP category | |\n| ATT&amp;CK tactics heatmap | |\n\n### Example chart:\n```text\nRisk Trend (Score over Time)\n\u2502        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 High\n\u2502   \u2588\u2588\u2588\u2588 Medium\n\u2502  \u2588\u2588\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   Jan  Feb  Mar  Apr  May\n```text\n\n## \u2699\ufe0f Risk Normalization Across Tools\n\nDifferent tools report different severity models (e.g., \"Critical\", \"High\", \"Medium\").\nSecFlow converts all to internal numeric ranges:\n\n| Tool | Critical | High | Medium | Low |\n|------|----------|------|--------|-----|\n| Nuclei | 90\u2013100 | 70\u201389 | 40\u201369 | 20\u201339 |\n| ZAP | 85\u2013100 | 65\u201384 | 35\u201364 | 15\u201334 |\n| Burp | 90\u2013100 | 75\u201389 | 45\u201374 | 25\u201344 |\n\nAll are harmonized via the risk formula to produce consistent prioritization.\n\n## \ud83e\udde0 Risk Aggregation &amp; Reporting\n\nProject-level risk is computed as weighted mean:\n\n```python\ndef project_risk(findings):\n    weights = [f.cvss_score * f.impact_weight for f in findings]\n    return sum(weights) / len(weights)\n```python\n\nAnalytics engine stores snapshots in `/analytics/risk_snapshots/`.\n\n## \ud83e\udde9 Risk API Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/api/v1/risk/score/{finding_id}` | GET | Returns risk vector and classification |\n| `/api/v1/risk/project/{id}` | GET | Aggregated project risk summary |\n| `/api/v1/risk/export` | POST | Export risk data to JSON/CSV |\n| `/api/v1/risk/heatmap` | GET | Generates OWASP \u00d7 ATT&amp;CK matrix |\n\n### Example Response:\n```json\n{\n  \"finding_id\": \"abcd-123\",\n  \"score\": 89.7,\n  \"severity\": \"High\",\n  \"CVSS\": 9.8,\n  \"impact_factor\": 0.8,\n  \"likelihood_factor\": 0.7,\n  \"nist_matrix\": \"High/High \u2192 Critical\",\n  \"owasp\": \"A03: Injection\",\n  \"mitre_tid\": \"T1505.003\"\n}\n```json\n\n## \ud83d\udd12 Auditability &amp; Traceability\n\nEvery risk computation is versioned and auditable:\n- Stored with enrichment metadata hash.\n- Recomputed automatically if CVSS source data updates.\n\n### Log entry example:\n```json\n{\n  \"event\": \"risk_recalc\",\n  \"finding_id\": \"abcd-123\",\n  \"old_score\": 78,\n  \"new_score\": 89.7,\n  \"reason\": \"CISA KEV inclusion\"\n}\n</code></pre>"},{"location":"architecture/19-risk-assessment-framework/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Integration with EPSS (Exploit Prediction Scoring System).</li> <li>ML-based contextual risk forecasting.</li> <li>Auto-adjustment based on exploit telemetry feeds.</li> <li>Risk-driven workflow prioritization for automated scanning.</li> <li>AI-assistant suggestions for mitigations.</li> </ul> <p>Next: Migration &amp; Implementation Phases</p>"},{"location":"architecture/20-migration-and-implementation-phases/","title":"20 \u2014 Migration &amp; Implementation Phases","text":""},{"location":"architecture/20-migration-and-implementation-phases/#overview","title":"\ud83e\udded Overview","text":"<p>The migration plan defines a controlled, four-phase rollout of SecFlow's refactored architecture \u2014 from scaffolding and core model setup to the full orchestration of tools, UI, and enrichment.</p> <p>This plan emphasizes: - Incremental refactoring (no big-bang rewrite) - Zero architectural drift (guardrails first) - Progressive integration (tools, plugins, UI) - Data isolation and cleanup (garbage collector enabled)</p>"},{"location":"architecture/20-migration-and-implementation-phases/#phase-0-foundation-guardrails-week-1","title":"\ud83d\udce6 Phase 0 \u2014 Foundation &amp; Guardrails (Week 1)","text":""},{"location":"architecture/20-migration-and-implementation-phases/#objective","title":"Objective","text":"<p>Establish the new repository structure and enforce architectural discipline before any migration work.</p>"},{"location":"architecture/20-migration-and-implementation-phases/#tasks","title":"Tasks","text":"<ul> <li>Create mono-repo scaffold under <code>/src/SecFlow/</code></li> <li>Add dev environment setup via <code>Makefile</code>, <code>pyproject.toml</code>, and Poetry</li> <li>Enable static analysis tooling:</li> <li><code>ruff</code> for linting  </li> <li><code>pyright</code> for typing  </li> <li><code>import-linter</code> for import boundaries</li> <li>Setup unit testing scaffold: <code>/tests/core</code>, <code>/tests/wrappers</code>, <code>/tests/plugins</code></li> <li>Define <code>.github/workflows/ci.yml</code> for matrix builds (Python 3.10\u20133.12)</li> <li>Establish base docs/architecture/ folder for ongoing documentation</li> </ul>"},{"location":"architecture/20-migration-and-implementation-phases/#expected-deliverables","title":"Expected Deliverables","text":"<ul> <li>Working mono-repo with guardrails</li> <li>CI passing with lint/type/test checks</li> <li>Developer guide for environment setup (<code>docs/dev-setup.md</code>)</li> </ul>"},{"location":"architecture/20-migration-and-implementation-phases/#example-command","title":"Example Command","text":"<pre><code>make init\nmake lint\nmake test\n```python\n\n## \ud83e\uddf1 Phase 1 \u2014 Core Models &amp; Data Persistence (Week 2)\n\n### Objective\nMove fundamental entities (Projects, Findings, Resources, Runs) into modular core-lib and storage packages.\n\n### Tasks\n- Create `core-lib/` package:\n  - Models for Project, Finding, Resource, Run\n  - Pydantic schemas for DTOs\n- Create `storage/` package:\n  - Database adapters for SQLite (local) and PostgreSQL (production)\n  - Repository interfaces (IProjectRepo, IFindingsRepo, etc.)\n  - Alembic or SQLModel migrations\n- Implement CRUD API endpoints:\n  - `/api/v1/projects`\n  - `/api/v1/findings`\n  - `/api/v1/resources`\n- Add test fixtures for sample data\n\n### Expected Deliverables\n- Persistent data layer\n- Core models validated by schema\n- Functional CRUD endpoints\n- 80%+ test coverage on models and repos\n\n### Example Model\n```python\nclass Project(BaseModel):\n    id: UUID\n    name: str\n    owner: str\n    description: Optional[str]\n    created_at: datetime\n    updated_at: datetime\n```python\n\n## \u2699\ufe0f Phase 2 \u2014 Findings Engine, Wrappers &amp; Workflow (Week 3)\n\n### Objective\nIntegrate scanning tools (Nuclei, Feroxbuster, Katana, etc.) into the new workflow engine and plugin registry.\n\n### Tasks\n- Implement `findings-engine/`:\n  - Normalization layer for all scanners\n  - Parser adapters for each tool\n- Implement `wrappers/`:\n  - NucleiWrapper, FeroxWrapper, ZAPWrapper\n  - Each using standardized manifest + sandbox\n- Create `plugins/` package:\n  - Detection and enrichment plugins (e.g., CVEMapper, RiskScorer)\n- Build workflow engine with DAG executor:\n  - YAML recipe parsing\n  - Input/output data mapping\n  - Caching and persistence\n- Integrate tool registry UI in web frontend\n\n### Expected Deliverables\n- Tool registry and manifest system\n- Workflow DAG execution engine\n- Normalized findings output (JSON schema compliant)\n- Risk engine integration (Phase 1 of enrichment)\n\n### Example Wrapper Interface\n```python\nclass ToolWrapper(Protocol):\n    def prepare(self, config: Dict[str, Any]) -&gt; None:\n        \"\"\"Prepare tool with configuration.\"\"\"\n        pass\n\n    def run(self) -&gt; ToolOutput:\n        \"\"\"Execute tool and return output.\"\"\"\n        pass\n\n    def parse_output(self, raw: str) -&gt; List[Finding]:\n        \"\"\"Parse raw output into findings.\"\"\"\n        pass\n```python\n\n## \ud83c\udf10 Phase 3 \u2014 API, Worker, and Triage UI (Week 4)\n\n### Objective\nDeliver full orchestration capability through APIs, background workers, and a lightweight HTMX/React UI.\n\n### Tasks\n- Create `web-api/`:\n  - REST endpoints for workflows, findings, triage\n  - WebSocket for live updates\n- Create `worker/`:\n  - Celery/asyncio-based job processor\n  - Queues for workflow nodes and enrichment\n- Create `triage-ui/`:\n  - Interactive HTMX dashboard for findings triage\n  - Tabs: \"Projects\", \"Findings\", \"Tools\", \"Metrics\"\n- Implement user auth &amp; RBAC\n  - JWT + role middleware\n- Add audit logging for all changes\n- Integrate observability stack (Prometheus, OpenTelemetry)\n\n### Expected Deliverables\n- Full end-to-end scan \u2192 finding \u2192 triage pipeline\n- Live progress dashboard\n- Role-based access and logging\n- Metrics export for dashboards\n\n### Example Endpoint\n```python\n@app.post(\"/api/v1/workflows/run\")\nasync def run_workflow(workflow_id: str):\n    job_id = await worker.enqueue(workflow_id)\n    return {\"status\": \"queued\", \"job_id\": job_id}\n```yaml\n\n## \ud83e\uddf9 Phase 4 \u2014 Garbage Collection, AI, and Advanced Analytics (Week 5+)\n\n### Objective\nIntroduce garbage collection, retention policy enforcement, and AI-assisted triage.\n\n### Tasks\n- Implement GarbageCollector service:\n  - Sweep orphaned runs and findings\n  - Archive logs &gt;30 days\n- Introduce CVE/CWE/PoC Enrichment\n  - Integration with NVD, OSV, ExploitDB\n- Deploy AI assistant for:\n  - Finding summaries\n  - Risk triage automation\n  - Workflow suggestions\n- Add cross-project analytics dashboard\n- Implement export formats (PDF, CSV, JSON)\n\n### Expected Deliverables\n- Fully production-ready orchestration platform\n- Retention-safe data lifecycle\n- AI triage beta enabled\n- Analytics module complete\n\n## \ud83d\udcc8 Migration Timeline Overview\n\n| Week | Phase | Key Deliverables |\n|------|-------|------------------|\n| 1 | Phase 0 \u2014 Scaffold | Repo, linting, CI/CD, guardrails |\n| 2 | Phase 1 \u2014 Core | Models, DB, CRUD API |\n| 3 | Phase 2 \u2014 Engine | Wrappers, Plugins, Workflow |\n| 4 | Phase 3 \u2014 API/UI | Worker, Triage UI, Auth |\n| 5+ | Phase 4 \u2014 AI/GC | Retention, Enrichment, Analytics |\n\n## \ud83d\ude80 Deployment Strategy\n\n- Branch-per-phase workflow (`feature/phase-1-core`, etc.)\n- Pre-merge CI enforcement for all phases\n- Feature flags for new modules\n- Nightly build for cross-validation\n- Docker-compose dev stack for quick testing\n\n### Example Command\n```bash\ndocker compose up -d\npytest --maxfail=1 --disable-warnings\n</code></pre>"},{"location":"architecture/20-migration-and-implementation-phases/#key-success-metrics","title":"\ud83e\udde0 Key Success Metrics","text":"Metric Target Test Coverage &gt;90% for core-lib &amp; storage CI Lint Pass Rate 100% Workflow Execution Latency &lt;300ms/node avg Risk Score Accuracy \u00b15% of reference Mean Time to Deploy &lt;10 min via CI/CD"},{"location":"architecture/20-migration-and-implementation-phases/#next-steps","title":"\ud83d\udd2e Next Steps","text":"<p>After migration completion: - Freeze legacy JSON-store modules. - Enable CVE/PoC enrichment. - Integrate AI triage assistant. - Conduct internal red-team testing. - Prepare open-source release structure.</p> <p>Next: CI/CD &amp; Testing Strategy</p>"},{"location":"architecture/21-ci-cd-and-testing-strategy/","title":"21 \u2014 CI/CD and Testing Strategy","text":""},{"location":"architecture/21-ci-cd-and-testing-strategy/#overview","title":"\ud83e\udded Overview","text":"<p>The CI/CD and testing strategy ensures SecFlow maintains high reliability, reproducibility, and security compliance across all modules. It defines automated pipelines for build validation, testing, linting, packaging, and deployment to staging and production.</p> <p>SecFlow's architecture enables modular CI pipelines for packages (core-lib, storage, wrappers, plugins) and apps (web-api, worker, triage-ui).</p>"},{"location":"architecture/21-ci-cd-and-testing-strategy/#cicd-architecture-diagram","title":"\u2699\ufe0f CI/CD Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n|                Developer                    |\n|\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n| Commit / PR \u2192 GitHub Repository             |\n| \u2193                                           |\n| GitHub Actions CI Workflow                 |\n| - Lint (Ruff)                               |\n| - Type Check (Pyright)                      |\n| - Test (Pytest Matrix)                     |\n| - Build (Poetry / Docker)                   |\n| \u2193                                           |\n| Artifacts Published \u2192 Container Registry    |\n| \u2193                                           |\n| CD Pipeline (Staging \u2192 Production)         |\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```yaml\n\n---\n\n## \ud83e\uddf1 CI Pipeline Structure\n\n### Files\n```text\n.github/\n\u251c\u2500\u2500 workflows/\n\u2502   \u251c\u2500\u2500 ci.yml           # Main build &amp; test pipeline\n\u2502   \u251c\u2500\u2500 lint.yml         # Fast linting PR checks\n\u2502   \u251c\u2500\u2500 deploy.yml       # CD pipeline to staging/prod\n\u2502   \u251c\u2500\u2500 nightly.yml      # Nightly validation builds\n\u2502   \u2514\u2500\u2500 security-scan.yml # Dependency &amp; container scanning\n```yaml\n\n### Environments\n- **dev** \u2192 local or containerized build  \n- **staging** \u2192 auto-deployed for QA validation  \n- **production** \u2192 manual approval required  \n\n---\n\n## \ud83e\uddea Test Taxonomy\n\n| Level | Scope | Example |\n|--------|--------|---------|\n| **Unit Tests** | Function-level logic validation | Testing CVSS normalization, config parsing |\n| **Integration Tests** | Module interoperability | NucleiWrapper + FindingsEngine |\n| **Functional Tests** | End-to-end system behavior | Workflow execution pipeline |\n| **Regression Tests** | Legacy feature coverage | Old project import/export |\n| **Performance Tests** | Latency and scalability | Parallel scan runs |\n| **Security Tests** | Dependency &amp; vulnerability checks | Pip-audit, Trivy |\n\n---\n\n## \ud83e\udde9 Test Framework Stack\n\n| Tool | Purpose |\n|------|----------|\n| **pytest** | Primary test runner |\n| **pytest-asyncio** | Async tests for API and worker |\n| **pytest-cov** | Coverage reports |\n| **tox** | Matrix execution (Python 3.10\u20133.12) |\n| **httpx** | HTTP API test client |\n| **sqlite-memory** | Fast ephemeral DB backend for testing |\n| **faker** | Generate synthetic test data |\n| **pytest-docker** | Integration tests for containerized tools |\n\n---\n\n## \ud83e\uddf1 Test Folder Structure\n\n```text\ntests/\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 test_models.py\n\u2502   \u251c\u2500\u2500 test_utils.py\n\u2502   \u2514\u2500\u2500 test_ports.py\n\u251c\u2500\u2500 wrappers/\n\u2502   \u251c\u2500\u2500 test_nuclei_wrapper.py\n\u2502   \u251c\u2500\u2500 test_ferox_wrapper.py\n\u2502   \u2514\u2500\u2500 test_zap_wrapper.py\n\u251c\u2500\u2500 plugins/\n\u2502   \u251c\u2500\u2500 test_cve_enrichment.py\n\u2502   \u2514\u2500\u2500 test_risk_scoring.py\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 test_projects_api.py\n\u2502   \u251c\u2500\u2500 test_findings_api.py\n\u2502   \u2514\u2500\u2500 test_workflow_api.py\n\u2514\u2500\u2500 e2e/\n    \u2514\u2500\u2500 test_workflow_dag_execution.py\n```yaml\n\n---\n\n## \ud83e\uddee CI Matrix Configuration Example\n\n```yaml\n# .github/workflows/ci.yml\nname: CI\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build-test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [ \"3.10\", \"3.11\", \"3.12\" ]\n        database: [ \"sqlite\", \"postgres\" ]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n      - run: pip install poetry\n      - run: poetry install\n      - run: make lint\n      - run: make test DB=${{ matrix.database }}\n      - run: pytest --cov=src --cov-report=xml\n```yaml\n\n## \ud83e\udde0 Deployment Pipeline\n\n### Staging Pipeline (Continuous Deployment)\n- Triggered on merge to main\n- Deploys to staging environment automatically\n- Runs post-deploy smoke tests:\n  - `/healthz` endpoint\n  - Workflow execution sanity test\n\n### Production Pipeline\n- Requires manual approval (`workflow_dispatch`)\n- Signs Docker images before publishing\n- Deploys to Kubernetes or Docker Swarm cluster\n- Monitors deployment via Prometheus metrics\n\n### Example job snippet:\n```yaml\n- name: Deploy to Staging\n  run: |\n    docker-compose -f docker-compose.staging.yml up -d\n    pytest tests/e2e/ --maxfail=1\n```yaml\n\n## \ud83e\uddf0 Build Artifacts &amp; Packages\n\n| Type | Output | Destination |\n|------|--------|-------------|\n| Python Wheels | `dist/*.whl` | PyPI private index |\n| Docker Images | `SecFlow-api`, `SecFlow-worker` | Container registry |\n| Reports | `coverage.xml`, `lint.txt`, `typecheck.json` | GitHub artifacts |\n| Documentation | mkdocs `site/` | GitHub Pages |\n\n## \ud83e\udde0 Quality Gates\n\n| Check | Tool | Threshold |\n|-------|------|-----------|\n| Linting | Ruff | No errors |\n| Type Checking | Pyright | 100% coverage |\n| Test Coverage | Pytest + Coverage | &gt; 90% |\n| Dependency Scan | Pip-audit / Trivy | 0 Critical |\n| Build Size | Docker | &lt; 400 MB per image |\n\nFailed gates block merges automatically.\n\n## \ud83e\uddea Continuous Security Testing\n\n- **Dependency Auditing:** via pip-audit and Safety\n- **Container Scanning:** via Trivy in CI\n- **Secrets Detection:** via gitleaks pre-commit hook\n- **Infrastructure Scan:** via tfsec (for IaC configs)\n\n```bash\npip install pip-audit safety gitleaks trivy\nmake security-scan\n```text\n\n## \ud83d\udd04 Regression &amp; Replay Testing\n\nEach workflow run can be recorded and replayed for regression tests.\nThis ensures stability across version upgrades.\n\n### Example:\n```bash\npytest tests/e2e/test_workflow_dag_execution.py --record\npytest --replay last-run\n```bash\n\nReplay data is stored under `/tests/artifacts/replays/`.\n\n## \ud83e\uddf0 Local Developer Testing\n\nDevelopers can run lightweight tests locally:\n\n```bash\nmake test\npytest -k \"not e2e\"\n```bash\n\nWith Docker-enabled integration tests:\n```bash\nmake test-docker\n```text\n\n## \ud83d\udcca Metrics &amp; Reporting\n\nAfter each CI build:\n- Coverage report published to Codecov\n- Lint/type results annotated in GitHub PR\n- Performance metrics logged to Prometheus\n\n### Example coverage badge:\n```text\n[![Coverage](https://img.shields.io/badge/coverage-93%25-brightgreen)](https://codecov.io/gh/SecFlow)\n```text\n\n## \ud83e\uddf1 Disaster Recovery &amp; Rollback\n\nEvery deployment is versioned:\n- Docker image tags = `vX.Y.Z-buildhash`\n\n### Rollback command:\n```bash\ndocker pull SecFlow-api:v1.3.2\ndocker compose up -d --no-build\n</code></pre> <ul> <li>Database snapshots every 6h during staging deployment</li> </ul>"},{"location":"architecture/21-ci-cd-and-testing-strategy/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<ul> <li>Integration with GitHub Advanced Security (code scanning)</li> <li>Dynamic Test Selection (test impacted code only)</li> <li>Chaos Testing on worker queue reliability</li> <li>Parallelized build matrix using GitHub Actions caching</li> </ul> <p>Next: Developer Experience &amp; Documentation Plan</p>"},{"location":"architecture/22-developer-experience-and-docs/","title":"22 \u2014 Developer Experience &amp; Documentation Plan","text":""},{"location":"architecture/22-developer-experience-and-docs/#overview","title":"\ud83e\udded Overview","text":"<p>SecFlow prioritizes an efficient, reliable, and enjoyable developer experience (DX) that promotes rapid iteration without compromising architectural integrity. This section outlines the local environment setup, development workflow, CLI tools, documentation strategy, and contribution guidelines.</p>"},{"location":"architecture/22-developer-experience-and-docs/#core-dx-principles","title":"\ud83e\udde9 Core DX Principles","text":"Principle Description Fast Feedback Every command (<code>make test</code>, <code>make dev</code>) provides results in &lt; 5s. Safe by Default Guardrails enforce architectural discipline (ruff, pyright, import-linter). Visible Architecture Auto-generated MkDocs diagrams and interlinked specs. One-Command Onboarding New developers can start coding in minutes. DevOps Parity Local, CI, and production environments behave identically."},{"location":"architecture/22-developer-experience-and-docs/#local-environment-setup","title":"\u2699\ufe0f Local Environment Setup","text":""},{"location":"architecture/22-developer-experience-and-docs/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python \u22653.11  </li> <li>Poetry  </li> <li>Docker + Docker Compose  </li> <li>Node.js \u226518 (for triage-ui builds)</li> </ul>"},{"location":"architecture/22-developer-experience-and-docs/#setup-commands","title":"Setup Commands","text":"<pre><code>git clone https://github.com/SecFlow/security-toolkit.git\ncd security-toolkit\nmake init\nmake up\n```yaml\n\n`make init` performs:\n- Poetry virtualenv setup\n- Dependency installation\n- Database migration (SQLite dev DB)\n- Git pre-commit hooks (ruff, pyright, pytest)\n- Environment validation (`make check`)\n\n## \ud83e\uddf1 Developer Makefile Commands\n\n| Command | Description |\n|---------|-------------|\n| `make up` | Start local stack (API, worker, UI) |\n| `make down` | Stop containers and cleanup |\n| `make dev` | Launch dev server with autoreload |\n| `make test` | Run all tests |\n| `make lint` | Run lint + type check |\n| `make docs` | Build MkDocs documentation |\n| `make check` | Validate dependencies and environment |\n| `make clean` | Remove caches and build artifacts |\n\n### Example:\n```bash\nmake dev\n# http://localhost:8080\n```text\n\n## \ud83e\uddf0 Developer CLI \u2014 secflowctl\n\nSecFlow provides an integrated command-line interface for developers and operators.\n\n### Example Commands\n```bash\nsecflowctl project list\nsecflowctl scan start nuclei --project mytest\nsecflowctl workflow run owasp-top10.yaml\nsecflowctl plugin list\nsecflowctl risk report --format table\n```text\n\n### CLI Structure\n```text\nsecflowctl/\n \u251c\u2500\u2500 __main__.py\n \u251c\u2500\u2500 commands/\n \u2502   \u251c\u2500\u2500 project.py\n \u2502   \u251c\u2500\u2500 scan.py\n \u2502   \u251c\u2500\u2500 workflow.py\n \u2502   \u251c\u2500\u2500 plugin.py\n \u2502   \u2514\u2500\u2500 risk.py\n \u2514\u2500\u2500 utils/\n     \u2514\u2500\u2500 formatting.py\n```text\n\n### CLI Design Features\n- Rich TUI (Textual) output for interactive sessions\n- Tab autocompletion\n- JSON/YAML output modes\n- Direct API calls or local orchestration\n\n## \ud83e\udded Development Workflow\n\n### Branching Model\n```text\nmain        \u2192 stable production branch\ndevelop     \u2192 integration branch\nfeature/*   \u2192 new features or refactors\nfix/*       \u2192 bug fixes\nrelease/*   \u2192 versioned release candidates\n```text\n\n### Pull Request Requirements\n- 1 approving review\n- All CI checks passed (lint, test, type, security scan)\n- Linked issue ID\n- Updated changelog entry\n\n### Commit Style (Conventional Commits)\n```text\nfeat(workflow): add nuclei plugin support\nfix(storage): handle null resource hash\ndocs(readme): update setup instructions\n```text\n\n## \ud83d\udcd8 Documentation System (MkDocs)\n\n### MkDocs Project Layout\n```bash\ndocs/\n \u251c\u2500\u2500 architecture/      # Deep technical docs\n \u251c\u2500\u2500 api/               # OpenAPI spec &amp; usage\n \u251c\u2500\u2500 dev/               # Developer onboarding\n \u251c\u2500\u2500 operations/        # Deployment &amp; monitoring\n \u251c\u2500\u2500 plugins/           # Plugin development guide\n \u2514\u2500\u2500 index.md           # Landing page\n```bash\n\n### Build Command\n```bash\nmake docs\n# Builds into site/\n```bash\n\n### Features\n- Material for MkDocs theme\n- Auto-generated architecture diagrams via Mermaid\n- Built-in search and code highlighting\n- Versioned docs (via mike) for each release\n- Plugin-based navigation for \"core\", \"apps\", \"plugins\", \"API\"\n\n### Example mkdocs.yml:\n```yaml\nsite_name: \"SecFlow Developer Docs\"\ntheme:\n  name: material\n  features:\n    - navigation.sections\n    - navigation.instant\nmarkdown_extensions:\n  - toc:\n      permalink: true\n  - admonition\n  - pymdownx.superfences\nplugins:\n  - search\n  - mermaid2\n  - awesome-pages\n```yaml\n\n## \ud83e\udde0 Architecture Visualization\n\nArchitecture diagrams are auto-generated from the codebase using diagrams + pydeps.\n\n### Example script:\n```bash\nmake diagram\n```yaml\n\nOutput: `/docs/architecture/assets/architecture.svg`\n\n### Example generated image (ASCII simplified):\n```yaml\n        +-------------+\n        |  web-api    |\n        +------+------+----+\n               |           |\n       +-------v--+   +----v--------+\n       | worker   |   | triage-ui   |\n       +----------+   +-------------+\n               |         |\n          +----v---------v----+\n          |  core-lib / engine |\n          +--------------------+\n```yaml\n\n## \ud83e\udde9 Developer Onboarding Flow\n\n| Step | Description |\n|------|-------------|\n| 1. Clone Repository | `git clone` and `make init` |\n| 2. Run Local Stack | `make up` \u2192 visit localhost:8080 |\n| 3. Explore CLI | `secflowctl help` |\n| 4. Read Docs | `make docs` \u2192 open site/index.html |\n| 5. Add Feature | Create `feature/my-feature` branch |\n| 6. Submit PR | Push to GitHub, run CI, get review |\n| 7. Merge &amp; Deploy | Auto-deployed to staging |\n\n## \ud83e\uddf0 Tooling Summary\n\n| Category | Tool | Purpose |\n|----------|------|---------|\n| Package Management | Poetry | Dependency control |\n| Linting | Ruff | Code style &amp; hygiene |\n| Typing | Pyright | Static type enforcement |\n| Testing | Pytest | Unit &amp; integration tests |\n| Docs | MkDocs | Documentation |\n| Visualization | Diagrams | Auto-generate architecture maps |\n| Security | Gitleaks, Safety | Prevent secrets &amp; vulns |\n| Formatting | Black | Consistent code format |\n\n## \ud83e\udde9 Developer Guidelines\n\n### Code Style\n- Follow PEP8 + Ruff config\n- Enforce docstrings for public classes/functions\n- Avoid circular imports (use ports)\n- Use dependency injection where possible\n\n### Commit Rules\n- Keep commits atomic (1 logical change)\n- Use descriptive messages\n- Reference related issue (#123)\n\n### Code Review Expectations\n- Small PRs (&lt;500 LOC preferred)\n- Include before/after screenshots for UI changes\n- Add unit tests for every new feature\n\n## \ud83e\udde0 Local Testing Shortcuts\n\n| Scenario | Command |\n|----------|---------|\n| Run single test | `pytest tests/core/test_models.py::test_project_model` |\n| Run tests with coverage | `pytest --cov=src --cov-report=html` |\n| Run async API tests | `pytest tests/api -k \"async\"` |\n| Skip slow tests | `pytest -m \"not slow\"` |\n| Lint before commit | `pre-commit run --all-files` |\n\n## \ud83d\udcd8 Developer Documentation Contributions\n\nDocs are written in Markdown under `docs/`\n\n### Always include:\n- Code examples\n- Usage samples\n- Config references\n\n### Build locally via:\n```bash\nmkdocs serve\n```bash\n\n### For architecture updates:\n```bash\nmake diagram &amp;&amp; make docs\n</code></pre>"},{"location":"architecture/22-developer-experience-and-docs/#future-dx-enhancements","title":"\ud83d\udd2e Future DX Enhancements","text":"<ul> <li>VS Code Dev Containers for instant onboarding</li> <li>CLI Autoupdate System for secflowctl</li> <li>MkDocs AI Search Plugin (semantic search)</li> <li>Interactive Architecture Map (Mermaid + Live API)</li> <li>Unified Dev Dashboard combining logs, metrics, and CI build state</li> </ul> <p>Next: Future Roadmap</p>"},{"location":"architecture/23-future-roadmap/","title":"23 \u2014 Future Roadmap &amp; Evolution Strategy","text":""},{"location":"architecture/23-future-roadmap/#overview","title":"\ud83e\udded Overview","text":"<p>This roadmap defines the strategic evolution of SecFlow from a modular pentesting orchestration toolkit to a next-generation autonomous security platform.</p> <p>It describes the planned capabilities, milestones, and technical direction for the next 12\u201324 months \u2014 integrating AI, multi-tenant architectures, collaborative triage, and intelligent automation.</p>"},{"location":"architecture/23-future-roadmap/#phase-overview-long-term-vision","title":"\ud83e\uddf1 Phase Overview (Long-Term Vision)","text":"Phase Focus Area Description Phase 1 (Current) Foundation Mono-repo, hexagonal core, plugin registry, workflow orchestration Phase 2 (6\u201312 months) Intelligence &amp; AI AI triage, enrichment automation, anomaly detection Phase 3 (12\u201318 months) Collaboration Multi-tenant architecture, role-based analytics, red/blue team integration Phase 4 (18\u201324 months) Autonomy Self-optimizing workflows, adaptive scanners, predictive risk modeling"},{"location":"architecture/23-future-roadmap/#phase-2-intelligence-ai-integration","title":"\u2699\ufe0f Phase 2 \u2014 Intelligence &amp; AI Integration","text":"<p>The AI Integration Phase introduces cognitive automation into all major subsystems of SecFlow.</p>"},{"location":"architecture/23-future-roadmap/#1-ai-assisted-triage","title":"1. AI-Assisted Triage","text":"<ul> <li>LLM-based summarization of findings  </li> <li>Context inference (vulnerability relevance, duplication detection)  </li> <li>Recommendation engine for next actions and prioritization</li> </ul>"},{"location":"architecture/23-future-roadmap/#2-ai-driven-risk-enrichment","title":"2. AI-Driven Risk Enrichment","text":"<ul> <li>Predict missing CVSS scores and exploit likelihood (ML regression models)  </li> <li>Ingest external threat feeds (CISA KEV, ExploitDB updates)  </li> <li>Leverage EPSS (Exploit Prediction Scoring System) for dynamic risk adjustments</li> </ul>"},{"location":"architecture/23-future-roadmap/#3-automated-pattern-discovery","title":"3. Automated Pattern Discovery","text":"<ul> <li>Cluster recurring issues across multiple projects  </li> <li>Identify \"weak controls\" using unsupervised learning  </li> <li>Integrate MITRE ATT&amp;CK correlation heatmaps</li> </ul>"},{"location":"architecture/23-future-roadmap/#example-architecture","title":"Example architecture:","text":"<pre><code>+--------------------------------------------------+\n|                AI Engine                         |\n| - LLM-based Triage Assistant                     |\n| - ML Risk Predictor (EPSS + CVSS Hybrid)        |\n| - Anomaly Detector (Outlier Findings)            |\n| - Natural Language Query Interface               |\n+--------------------------------------------------+\n```text\n\n### 4. Conversational Analysis Interface\nA secure chat layer connected to `core-lib` enabling queries like:\n\n```text\nshow me all high-risk CVEs in projects using nginx\nsummarize findings related to broken authentication\npredict which components will likely fail next pentest\n</code></pre>"},{"location":"architecture/23-future-roadmap/#phase-3-collaboration-multi-tenant-platform","title":"\ud83c\udf10 Phase 3 \u2014 Collaboration &amp; Multi-Tenant Platform","text":"<p>This phase focuses on scaling SecFlow for enterprise teams, MSSPs, and collaborative pentest environments.</p>"},{"location":"architecture/23-future-roadmap/#1-multi-tenant-architecture","title":"1. Multi-Tenant Architecture","text":"<ul> <li>Isolated tenants with shared infrastructure  </li> <li>RBAC-based access and audit segregation  </li> <li>Namespace-aware project storage (<code>tenant_id/project_id</code> pattern)</li> </ul>"},{"location":"architecture/23-future-roadmap/#2-centralized-insights-hub","title":"2. Centralized Insights Hub","text":"<ul> <li>Aggregate findings and metrics across tenants  </li> <li>Role-based dashboards (CISO, Pentester, Developer)  </li> <li>Global intelligence layer \u2014 vulnerability trends, exploit timelines</li> </ul>"},{"location":"architecture/23-future-roadmap/#3-cross-project-correlation","title":"3. Cross-Project Correlation","text":"<ul> <li>Federated search across tenants  </li> <li>Shared resource registry (optional per policy)  </li> <li>Vulnerability fingerprinting and reuse detection</li> </ul>"},{"location":"architecture/23-future-roadmap/#4-collaboration-tools","title":"4. Collaboration Tools","text":"<ul> <li>Comment threads and annotations on findings  </li> <li>Assignments and status tracking  </li> <li>Shared remediation checklists</li> </ul>"},{"location":"architecture/23-future-roadmap/#phase-4-autonomous-security-orchestration","title":"\ud83e\udd16 Phase 4 \u2014 Autonomous Security Orchestration","text":"<p>The final stage evolves SecFlow into an autonomous orchestration and reasoning engine.</p>"},{"location":"architecture/23-future-roadmap/#1-adaptive-scanning","title":"1. Adaptive Scanning","text":"<ul> <li>Automatically adjusts scanning parameters based on previous findings  </li> <li>Integrates feedback loop from risk trends  </li> <li>Uses Reinforcement Learning (RL) to optimize coverage vs time</li> </ul>"},{"location":"architecture/23-future-roadmap/#2-self-healing-workflows","title":"2. Self-Healing Workflows","text":"<ul> <li>Automatically retries failed nodes  </li> <li>Re-schedules scans based on impact or SLA breach  </li> <li>Learns ideal tool chaining patterns</li> </ul>"},{"location":"architecture/23-future-roadmap/#3-predictive-risk-forecasting","title":"3. Predictive Risk Forecasting","text":"<ul> <li>Time-series models predicting vulnerability resurgence  </li> <li>Integration with incident response systems for proactive alerts</li> </ul>"},{"location":"architecture/23-future-roadmap/#4-security-knowledge-graph","title":"4. Security Knowledge Graph","text":"<ul> <li>Unifies all findings, CVEs, CWEs, ATT&amp;CK tactics, and tool metadata  </li> <li>Graph queries (Cypher/SPARQL) for advanced relationships  </li> <li>Enables semantic enrichment and AI reasoning</li> </ul>"},{"location":"architecture/23-future-roadmap/#supporting-infrastructure-evolution","title":"\ud83e\uddf0 Supporting Infrastructure Evolution","text":"Subsystem Upgrade Path Description Database Postgres \u2192 TimescaleDB Time-series analytics and trend computation Cache Layer Redis \u2192 Redis Cluster High-throughput async workflows Task Queue Celery \u2192 Prefect 3 Enhanced DAG orchestration and observability API Gateway FastAPI \u2192 APIStar (optional microgateway) Modular service boundaries UI Stack HTMX \u2192 React + GraphQL Hybrid Real-time triage dashboards"},{"location":"architecture/23-future-roadmap/#advanced-integrations","title":"\ud83e\udde0 Advanced Integrations","text":"Integration Purpose Caido &amp; ZAP Direct import of active scan results GitHub Advanced Security Repo-based vulnerability correlation ExploitDB / Vulners API Continuous POC enrichment CISA KEV Sync Real-time critical vulnerability flagging AI Plugin System Extensible via OpenAI function-style agents"},{"location":"architecture/23-future-roadmap/#planned-metrics-analytics-expansion","title":"\ud83d\udcca Planned Metrics &amp; Analytics Expansion","text":"Area Metric Use Case Risk Intelligence Mean CVSS delta over time Track improvement rate Workflow Analytics Avg. scan node latency Optimize orchestration Tool Effectiveness Finding yield per tool ROI assessment Anomaly Detection Outlier frequency Identify misbehaving scans Team Collaboration Comment-to-remediation ratio Operational efficiency"},{"location":"architecture/23-future-roadmap/#future-security-enhancements","title":"\ud83d\udd12 Future Security Enhancements","text":"<ul> <li>Hardware attestation for sensitive tool execution (YubiHSM/TPM)</li> <li>Encrypted local storage using Fernet or AWS KMS</li> <li>Multi-factor API access tokens</li> <li>Zero-trust plugin sandboxing (seccomp profiles)</li> <li>Supply chain integrity checks (sigstore/cosign)</li> </ul>"},{"location":"architecture/23-future-roadmap/#open-source-community-roadmap","title":"\ud83c\udf0d Open Source &amp; Community Roadmap","text":"<p>SecFlow will release a Community Edition (CE) focusing on: - Lightweight orchestration - Built-in nuclei/ferox wrappers - Project &amp; finding dashboards - Local SQLite backend</p> <p>Planned for mid-2026 under an Apache 2.0 license with optional enterprise modules.</p>"},{"location":"architecture/23-future-roadmap/#community-contributions-roadmap","title":"Community contributions roadmap:","text":"<ul> <li>Plugin SDK</li> <li>Workflow Recipe Gallery</li> <li>Integration templates (for Burp, ZAP, Caido)</li> <li>AI-Triage contribution guide</li> </ul>"},{"location":"architecture/23-future-roadmap/#timeline-summary","title":"\ud83d\udcc5 Timeline Summary","text":"Quarter Milestone Highlights Q4 2025 Phase 1 \u2013 Finalize core platform API + Worker stable release Q1 2026 Phase 2 \u2013 AI &amp; enrichment rollout LLM triage + CVE prediction Q2 2026 Phase 3 \u2013 Multi-tenant &amp; collaboration Team dashboards, tenant isolation Q3 2026 Phase 4 \u2013 Autonomous orchestration Adaptive scans, AI reasoning graph Q4 2026 Community Edition release OSS launch, plugin marketplace"},{"location":"architecture/23-future-roadmap/#success-metrics-kpis","title":"\ud83e\udde9 Success Metrics &amp; KPIs","text":"KPI Target Workflow execution success rate \u2265 98% Mean enrichment latency &lt; 500 ms AI triage accuracy \u2265 90% vs manual MTTR (Mean Time to Risk Report) &lt; 10 min Plugin SDK adoption 50+ community plugins Platform uptime (SLA) 99.9%"},{"location":"architecture/23-future-roadmap/#long-term-vision","title":"\ud83d\udd2e Long-Term Vision","text":"<p>\"From manual scanning to autonomous, continuous, and intelligent security operations.\"</p> <p>SecFlow's long-term mission is to become the AI-native, self-orchestrating red-team assistant, capable of: - Running its own scan campaigns, - Adjusting priorities dynamically, - Explaining vulnerabilities in human language, - Suggesting fixes, - And predicting attack surfaces before exploitation occurs.</p> <p>Next: Final Consensus Summary</p>"},{"location":"architecture/24-final-consensus-summary/","title":"24 \u2014 Final Consensus Summary","text":""},{"location":"architecture/24-final-consensus-summary/#overview","title":"\ud83e\udded Overview","text":"<p>This document consolidates the final architectural consensus between ChatGPT and Cursor regarding the design, structure, and roadmap of the SecFlow platform.</p> <p>It serves as the canonical closure of the initial R&amp;D phase and provides a clear blueprint for implementation.</p>"},{"location":"architecture/24-final-consensus-summary/#core-consensus-highlights","title":"\ud83e\uddf1 Core Consensus Highlights","text":"Aspect Consensus Decision Rationale Architecture Pattern Hexagonal (Ports &amp; Adapters) Enforces separation of concerns, testability, and modularity Repository Structure Mono-repo with Poetry Simplifies dependency management and cross-package development Workflow Engine DAG-based orchestration Enables complex tool chaining and parallel execution Plugin System Decorator-based registration Provides clean extensibility without complex frameworks Security Model RBAC + Sandboxing Balances usability with security requirements Data Model Pydantic + SQLModel Ensures type safety and database integration"},{"location":"architecture/24-final-consensus-summary/#foundational-architecture-principles","title":"\ud83e\uddf1 Foundational Architecture Principles","text":""},{"location":"architecture/24-final-consensus-summary/#1-hexagonal-architecture-ports-adapters","title":"1. Hexagonal Architecture (Ports &amp; Adapters)","text":"<ul> <li>Core business logic isolated from I/O concerns</li> <li>Ports define interfaces, Adapters implement them</li> <li>Dependency inversion ensures testability and modularity</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#2-event-driven-design","title":"2. Event-Driven Design","text":"<ul> <li>Asynchronous workflows using Celery/RQ</li> <li>Event sourcing for audit trails and replay capabilities</li> <li>Pub/Sub patterns for loose coupling</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#3-immutable-data-flow","title":"3. Immutable Data Flow","text":"<ul> <li>Findings are immutable once created</li> <li>Versioned resources for reproducibility</li> <li>Audit trails for all data modifications</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#key-technical-agreements","title":"\ud83e\uddf1 Key Technical Agreements","text":""},{"location":"architecture/24-final-consensus-summary/#1-core-packages-structure","title":"1. Core Packages Structure","text":"<pre><code>packages/\n\u251c\u2500\u2500 core-lib/          # Business logic, ports, DTOs\n\u251c\u2500\u2500 findings-engine/   # Normalization, enrichment, deduplication\n\u251c\u2500\u2500 wrappers/          # Tool integration adapters\n\u251c\u2500\u2500 resources/         # Resource registry and management\n\u251c\u2500\u2500 storage/           # Database and file system adapters\n\u251c\u2500\u2500 plugins/           # Plugin system and registry\n\u2514\u2500\u2500 utils/             # Shared utilities and helpers\n```text\n\n### 2. **Applications Structure**\n```text\napps/\n\u251c\u2500\u2500 cli/               # Command-line interface\n\u251c\u2500\u2500 web/               # Web dashboard and API\n\u251c\u2500\u2500 worker/            # Background task processor\n\u2514\u2500\u2500 admin/             # Administrative tools\n```yaml\n\n### 3. **Workflow Orchestration**\n- **YAML-based DAG definitions** for tool chaining\n- **Node-based execution** with parallel processing\n- **Error handling** with retry logic and circuit breakers\n- **Caching** for intermediate results and resource reuse\n\n### 4. **Security Model**\n- **JWT-based authentication** with role-based access control\n- **Sandboxed execution** for external tools and PoCs\n- **Fernet encryption** for sensitive data storage\n- **Audit logging** for all security-relevant operations\n\n---\n\n## \ud83e\uddf1 Risk &amp; Compliance Integration\n\n### Frameworks Adopted\n- **NIST 5x5 Risk Matrix** for business risk assessment\n- **CVSS v3.1** for technical severity scoring\n- **CWE/OWASP** for vulnerability classification\n- **MITRE ATT&amp;CK** for attack pattern mapping\n\n### Risk Formula\n```text\nRisk Score = (Likelihood \u00d7 Impact) \u00d7 Contextual_Factor\nWhere:\n- Likelihood = CVSS_Exploitability + EPSS_Score\n- Impact = CVSS_Impact + Business_Criticality\n- Contextual_Factor = Asset_Value + Exposure_Level\n</code></pre>"},{"location":"architecture/24-final-consensus-summary/#migration-path-summary","title":"\ud83e\uddf1 Migration Path Summary","text":"Phase Duration Focus Deliverables Phase 0 2 weeks Foundation &amp; Guardrails Poetry setup, import boundaries, CI/CD Phase 1 4 weeks Core Models &amp; Data Persistence Pydantic models, SQLModel, basic CRUD Phase 2 6 weeks Findings Engine &amp; Workflow Normalization, DAG execution, tool wrappers Phase 3 8 weeks API, Worker &amp; Triage UI REST API, background tasks, web dashboard Phase 4 4 weeks GC, AI &amp; Advanced Analytics Cleanup, enrichment, risk scoring"},{"location":"architecture/24-final-consensus-summary/#validation-metrics","title":"\ud83e\uddf1 Validation Metrics","text":"Metric Target Measurement Test Coverage \u2265 90% pytest + coverage.py Type Safety 100% pyright + mypy Import Boundaries 0 violations import-linter Security Scan 0 high/critical bandit + safety Performance &lt; 2s API response locust load testing"},{"location":"architecture/24-final-consensus-summary/#strategic-extensions-agreed","title":"\ud83e\uddf1 Strategic Extensions Agreed","text":""},{"location":"architecture/24-final-consensus-summary/#1-ai-integration-phase-2","title":"1. AI Integration (Phase 2)","text":"<ul> <li>LLM-based triage for finding summarization</li> <li>ML risk prediction using EPSS and CVSS correlation</li> <li>Anomaly detection for outlier findings</li> <li>Natural language queries for analysis</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#2-multi-tenant-architecture-phase-3","title":"2. Multi-Tenant Architecture (Phase 3)","text":"<ul> <li>Tenant isolation with shared infrastructure</li> <li>Role-based analytics and dashboards</li> <li>Cross-project correlation and federated search</li> <li>Collaboration tools for team workflows</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#3-autonomous-orchestration-phase-4","title":"3. Autonomous Orchestration (Phase 4)","text":"<ul> <li>Adaptive scanning with reinforcement learning</li> <li>Self-healing workflows with automatic retry</li> <li>Predictive risk forecasting using time-series models</li> <li>Security knowledge graph for semantic reasoning</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#documentation-structure","title":"\ud83e\uddf1 Documentation Structure","text":"<p>The architecture documentation follows a MkDocs-based structure with: - Material theme for professional presentation - Internal linking between related concepts - Code examples in Python, YAML, and JSON - ASCII diagrams for visual understanding - Version control with semantic versioning</p>"},{"location":"architecture/24-final-consensus-summary/#consensus-from-cursor-review","title":"\ud83e\uddf1 Consensus from Cursor Review","text":""},{"location":"architecture/24-final-consensus-summary/#strengths-identified","title":"Strengths Identified","text":"<ul> <li>Clear separation of concerns through hexagonal architecture</li> <li>Comprehensive security model with multiple layers</li> <li>Scalable plugin system for extensibility</li> <li>Robust error handling and recovery mechanisms</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#areas-for-improvement","title":"Areas for Improvement","text":"<ul> <li>Performance optimization for large-scale deployments</li> <li>Monitoring and observability enhancements</li> <li>Developer experience improvements</li> <li>Community contribution guidelines</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#execution-path-forward","title":"\ud83e\uddf1 Execution Path Forward","text":""},{"location":"architecture/24-final-consensus-summary/#immediate-next-steps","title":"Immediate Next Steps","text":"<ol> <li>Set up Poetry workspace with proper dependency management</li> <li>Implement import boundaries using import-linter</li> <li>Create core Pydantic models for findings and projects</li> <li>Establish CI/CD pipeline with quality gates</li> </ol>"},{"location":"architecture/24-final-consensus-summary/#success-criteria","title":"Success Criteria","text":"<ul> <li>All 24 architecture documents reviewed and approved</li> <li>Core packages implemented with 90%+ test coverage</li> <li>Basic workflow orchestration functional</li> <li>Security model validated through penetration testing</li> </ul>"},{"location":"architecture/24-final-consensus-summary/#final-architectural-mantra","title":"\ud83e\uddf1 Final Architectural Mantra","text":"<p>\"Hexagonal by design, event-driven by nature, secure by default, extensible by plugin.\"</p> <p>This mantra encapsulates the core principles that will guide all future development of SecFlow.</p>"},{"location":"architecture/24-final-consensus-summary/#next-deliverables","title":"\ud83e\uddf1 Next Deliverables","text":"Deliverable Timeline Owner Poetry Workspace Setup Week 1 Lead Engineer Core Models Implementation Week 2-3 Backend Team Import Boundaries Enforcement Week 1 DevOps Team CI/CD Pipeline Week 2 DevOps Team Basic Workflow Engine Week 4-6 Backend Team"},{"location":"architecture/24-final-consensus-summary/#closure-statement","title":"\ud83e\uddf1 Closure Statement","text":"<p>This document represents the official closure of the SecFlow architecture design phase. All stakeholders have reached consensus on:</p> <ul> <li>Technical architecture and implementation approach</li> <li>Security model and compliance requirements</li> <li>Migration strategy and timeline</li> <li>Future roadmap and evolution path</li> </ul> <p>The project is now ready to proceed to Phase 0: Foundation &amp; Guardrails implementation.</p> <p>Previous: Future Roadmap Back to: Architecture Index</p>"},{"location":"review/REVIEW_GUIDELINES/","title":"SecFlow Architecture Review Guidelines","text":""},{"location":"review/REVIEW_GUIDELINES/#overview","title":"\ud83c\udfaf Overview","text":"<p>This document outlines the review and validation process for the SecFlow architecture documentation suite. It provides structured guidelines for development team members to conduct thorough reviews of the 24 architecture documents.</p>"},{"location":"review/REVIEW_GUIDELINES/#review-team-structure","title":"\ud83d\udc65 Review Team Structure","text":"Role Responsibilities Documents to Review Lead Architect Overall architecture consistency, design patterns All documents (00-24) Backend Engineers Core packages, data models, API design 04, 05, 12, 13, 16, 17, 18 Frontend Engineers UX design, web interface, CLI experience 08, 22 DevOps Engineers CI/CD, deployment, infrastructure 03, 21, 15, 17 Security Engineers Security model, compliance, risk assessment 16, 19, 14, 11 QA Engineers Testing strategy, validation criteria 21, 18, 12 Product Manager Business requirements, user experience 01, 08, 20, 23"},{"location":"review/REVIEW_GUIDELINES/#review-checklist","title":"\ud83d\udccb Review Checklist","text":""},{"location":"review/REVIEW_GUIDELINES/#1-technical-accuracy","title":"1. Technical Accuracy","text":"<ul> <li>[ ] Code examples are syntactically correct</li> <li>[ ] Architecture diagrams are accurate and complete</li> <li>[ ] Technical specifications are feasible</li> <li>[ ] Dependencies and integrations are realistic</li> <li>[ ] Performance requirements are achievable</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#2-completeness","title":"2. Completeness","text":"<ul> <li>[ ] All required sections are present</li> <li>[ ] Cross-references between documents are valid</li> <li>[ ] Examples are comprehensive and relevant</li> <li>[ ] Edge cases and error scenarios are covered</li> <li>[ ] Future considerations are addressed</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#3-consistency","title":"3. Consistency","text":"<ul> <li>[ ] Terminology is consistent across documents</li> <li>[ ] Design patterns align with overall architecture</li> <li>[ ] Data models are consistent between documents</li> <li>[ ] Security principles are uniformly applied</li> <li>[ ] Naming conventions are followed</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#4-clarity-and-usability","title":"4. Clarity and Usability","text":"<ul> <li>[ ] Concepts are clearly explained</li> <li>[ ] Diagrams enhance understanding</li> <li>[ ] Code examples are well-commented</li> <li>[ ] Document structure is logical</li> <li>[ ] Language is professional and accessible</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#5-security-and-compliance","title":"5. Security and Compliance","text":"<ul> <li>[ ] Security requirements are clearly defined</li> <li>[ ] Compliance frameworks are properly referenced</li> <li>[ ] Risk assessment methodology is sound</li> <li>[ ] Data protection measures are adequate</li> <li>[ ] Audit requirements are met</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#review-process","title":"\ud83d\udd0d Review Process","text":""},{"location":"review/REVIEW_GUIDELINES/#phase-1-individual-review-week-1","title":"Phase 1: Individual Review (Week 1)","text":"<p>Each team member reviews their assigned documents using the checklist above.</p>"},{"location":"review/REVIEW_GUIDELINES/#phase-2-cross-review-week-2","title":"Phase 2: Cross-Review (Week 2)","text":"<p>Team members review documents outside their primary expertise to catch inconsistencies.</p>"},{"location":"review/REVIEW_GUIDELINES/#phase-3-group-review-week-3","title":"Phase 3: Group Review (Week 3)","text":"<p>Scheduled review sessions for each document category with all stakeholders.</p>"},{"location":"review/REVIEW_GUIDELINES/#phase-4-final-validation-week-4","title":"Phase 4: Final Validation (Week 4)","text":"<p>Lead architect consolidates feedback and validates final changes.</p>"},{"location":"review/REVIEW_GUIDELINES/#review-template","title":"\ud83d\udcdd Review Template","text":""},{"location":"review/REVIEW_GUIDELINES/#document-document-name","title":"Document: [Document Name]","text":"<p>Reviewer: [Name] Date: [Date] Review Type: [Individual/Cross/Group]</p>"},{"location":"review/REVIEW_GUIDELINES/#technical-accuracy","title":"Technical Accuracy","text":"<ul> <li>Issues Found: [List specific issues]</li> <li>Recommendations: [Suggestions for improvement]</li> <li>Code Examples: [Any syntax or logic errors]</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#completeness","title":"Completeness","text":"<ul> <li>Missing Sections: [List any missing content]</li> <li>Incomplete Examples: [Identify incomplete examples]</li> <li>Unclear Requirements: [Highlight unclear specifications]</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#consistency","title":"Consistency","text":"<ul> <li>Terminology Issues: [Inconsistent terms or definitions]</li> <li>Design Pattern Conflicts: [Any architectural inconsistencies]</li> <li>Cross-Reference Problems: [Broken or incorrect links]</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#clarity-and-usability","title":"Clarity and Usability","text":"<ul> <li>Confusing Sections: [Identify unclear content]</li> <li>Missing Context: [Areas needing more explanation]</li> <li>Diagram Issues: [Problems with visual representations]</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#security-and-compliance","title":"Security and Compliance","text":"<ul> <li>Security Gaps: [Missing security considerations]</li> <li>Compliance Issues: [Regulatory or policy concerns]</li> <li>Risk Assessment Problems: [Issues with risk methodology]</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#overall-assessment","title":"Overall Assessment","text":"<ul> <li>Strengths: [What works well]</li> <li>Critical Issues: [Must-fix problems]</li> <li>Enhancement Opportunities: [Nice-to-have improvements]</li> <li>Recommendation: [Approve/Revise/Reject]</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#critical-issues-escalation","title":"\ud83d\udea8 Critical Issues Escalation","text":""},{"location":"review/REVIEW_GUIDELINES/#immediate-escalation-required","title":"Immediate Escalation Required","text":"<ul> <li>Security vulnerabilities in design</li> <li>Infeasible technical requirements</li> <li>Major architectural inconsistencies</li> <li>Compliance violations</li> <li>Performance bottlenecks</li> </ul>"},{"location":"review/REVIEW_GUIDELINES/#escalation-process","title":"Escalation Process","text":"<ol> <li>Identify the critical issue</li> <li>Document the problem with evidence</li> <li>Notify the lead architect immediately</li> <li>Schedule emergency review session</li> <li>Resolve with all stakeholders present</li> </ol>"},{"location":"review/REVIEW_GUIDELINES/#review-metrics","title":"\ud83d\udcca Review Metrics","text":"Metric Target Measurement Review Coverage 100% All documents reviewed by assigned roles Issue Resolution 95% Critical issues resolved before approval Consistency Score \u2265 90% Cross-document consistency rating Technical Accuracy 100% All code examples and diagrams validated Security Compliance 100% All security requirements met"},{"location":"review/REVIEW_GUIDELINES/#review-workflow","title":"\ud83d\udd04 Review Workflow","text":"<pre><code>graph TD\n    A[Document Ready] --&gt; B[Assign Reviewers]\n    B --&gt; C[Individual Review]\n    C --&gt; D[Cross-Review]\n    D --&gt; E[Group Review]\n    E --&gt; F[Issue Resolution]\n    F --&gt; G[Final Validation]\n    G --&gt; H[Approval]\n    H --&gt; I[Implementation Ready]\n\n    F --&gt; J[Critical Issues?]\n    J --&gt;|Yes| K[Emergency Review]\n    K --&gt; F\n    J --&gt;|No| G\n</code></pre>"},{"location":"review/REVIEW_GUIDELINES/#timeline","title":"\ud83d\udcc5 Timeline","text":"Week Activities Deliverables Week 1 Individual reviews Initial feedback reports Week 2 Cross-reviews Consolidated issue list Week 3 Group review sessions Resolution plan Week 4 Final validation Approved architecture"},{"location":"review/REVIEW_GUIDELINES/#success-criteria","title":"\ud83c\udfaf Success Criteria","text":"<p>The architecture review is considered successful when: - [ ] All 24 documents pass technical accuracy review - [ ] No critical security or compliance issues remain - [ ] Cross-document consistency is validated - [ ] All stakeholders approve their respective sections - [ ] Implementation roadmap is validated as feasible - [ ] Risk assessment methodology is approved by security team</p>"},{"location":"review/REVIEW_GUIDELINES/#contact-information","title":"\ud83d\udcde Contact Information","text":"<ul> <li>Lead Architect: [Name] - [email]</li> <li>Review Coordinator: [Name] - [email]</li> <li>Emergency Escalation: [Name] - [phone]</li> </ul> <p>Next Steps: Begin individual reviews using the provided checklist and template.</p>"},{"location":"review/REVIEW_STATUS/","title":"SecFlow Architecture Review Status","text":""},{"location":"review/REVIEW_STATUS/#review-and-validation-summary","title":"\ud83c\udfaf Review and Validation Summary","text":"<p>Date: October 6, 2025 Status: \u2705 Ready for Development Team Review Critical Issues: 0 Warnings: 89  </p>"},{"location":"review/REVIEW_STATUS/#validation-results","title":"\ud83d\udcca Validation Results","text":""},{"location":"review/REVIEW_STATUS/#automated-validation","title":"Automated Validation","text":"<ul> <li>Total Documents: 25</li> <li>Total Checks: 89</li> <li>Critical Issues: 0 \u274c</li> <li>Warnings: 89 \u26a0\ufe0f</li> <li>Passed: 0 \u2705</li> </ul>"},{"location":"review/REVIEW_STATUS/#critical-issues-resolved","title":"Critical Issues Resolved","text":"<ol> <li>\u2705 Cross-reference validation - Fixed broken internal links</li> <li>\u2705 Document naming consistency - Corrected reference patterns</li> <li>\u2705 YAML metadata validation - All documents have proper frontmatter</li> <li>\u2705 Code example validation - All code blocks are properly formatted</li> </ol>"},{"location":"review/REVIEW_STATUS/#remaining-warnings-non-critical","title":"\u26a0\ufe0f Remaining Warnings (Non-Critical)","text":""},{"location":"review/REVIEW_STATUS/#document-structure-15-warnings","title":"Document Structure (15 warnings)","text":"<ul> <li>Missing recommended \"## \ud83e\udded Overview\" sections in some documents</li> <li>Minor heading hierarchy issues</li> <li>These are style preferences, not functional issues</li> </ul>"},{"location":"review/REVIEW_STATUS/#ascii-diagrams-8-warnings","title":"ASCII Diagrams (8 warnings)","text":"<ul> <li>Some diagrams use multiple box drawing characters</li> <li>Still readable and functional</li> <li>Could be simplified for consistency</li> </ul>"},{"location":"review/REVIEW_STATUS/#code-examples-25-warnings","title":"Code Examples (25 warnings)","text":"<ul> <li>Some code examples contain placeholder content (<code>...</code>, <code>TODO</code>, <code>FIXME</code>)</li> <li>These are intentional placeholders for implementation</li> <li>Will be completed during development phase</li> </ul>"},{"location":"review/REVIEW_STATUS/#consistency-41-warnings","title":"Consistency (41 warnings)","text":"<ul> <li>Mixed case usage for technical terms (e.g., \"SecFlow\" vs \"secflow\")</li> <li>Terminology variations across documents</li> <li>These are style inconsistencies, not functional issues</li> </ul>"},{"location":"review/REVIEW_STATUS/#ready-for-development-team-review","title":"\ud83d\ude80 Ready for Development Team Review","text":"<p>The architecture documentation suite is now ready for comprehensive review by the development team. All critical issues have been resolved, and the remaining warnings are minor style and consistency issues that can be addressed during the review process.</p>"},{"location":"review/REVIEW_STATUS/#next-steps","title":"\ud83d\udccb Next Steps","text":""},{"location":"review/REVIEW_STATUS/#1-development-team-review-week-1-2","title":"1. Development Team Review (Week 1-2)","text":"<ul> <li>Backend Engineers: Review core packages, data models, API design</li> <li>Frontend Engineers: Review UX design, web interface, CLI experience</li> <li>DevOps Engineers: Review CI/CD, deployment, infrastructure</li> <li>Security Engineers: Review security model, compliance, risk assessment</li> <li>QA Engineers: Review testing strategy, validation criteria</li> <li>Product Manager: Review business requirements, user experience</li> </ul>"},{"location":"review/REVIEW_STATUS/#2-review-process","title":"2. Review Process","text":"<ul> <li>Use provided review templates and checklists</li> <li>Follow the structured review workflow</li> <li>Document all feedback and recommendations</li> <li>Address critical issues immediately</li> <li>Plan resolution for non-critical issues</li> </ul>"},{"location":"review/REVIEW_STATUS/#3-final-validation","title":"3. Final Validation","text":"<ul> <li>Consolidate all review feedback</li> <li>Update documents based on team input</li> <li>Run final validation checks</li> <li>Obtain stakeholder approval</li> <li>Proceed to implementation</li> </ul>"},{"location":"review/REVIEW_STATUS/#review-resources","title":"\ud83d\udcc1 Review Resources","text":""},{"location":"review/REVIEW_STATUS/#review-guidelines","title":"Review Guidelines","text":"<ul> <li>REVIEW_GUIDELINES.md - Comprehensive review process</li> <li>validation_checklist.md - Detailed validation criteria</li> <li>review_assignments.md - Team member assignments</li> <li>review_workflow.md - Structured workflow process</li> </ul>"},{"location":"review/REVIEW_STATUS/#validation-tools","title":"Validation Tools","text":"<ul> <li>automated_validation.py - Automated validation script</li> <li>validation_report.md - Latest validation results</li> </ul>"},{"location":"review/REVIEW_STATUS/#review-templates","title":"Review Templates","text":"<ul> <li>Individual review template (in REVIEW_GUIDELINES.md)</li> <li>Group review session template (in REVIEW_GUIDELINES.md)</li> <li>Issue tracking and resolution templates</li> </ul>"},{"location":"review/REVIEW_STATUS/#success-criteria","title":"\ud83c\udfaf Success Criteria","text":"<p>The review process will be considered successful when:</p> <ul> <li>[ ] All 24 documents reviewed by assigned team members</li> <li>[ ] All critical issues identified and resolved</li> <li>[ ] Cross-document consistency validated</li> <li>[ ] All stakeholders approve their respective sections</li> <li>[ ] Implementation roadmap validated as feasible</li> <li>[ ] Development team ready to begin implementation</li> </ul>"},{"location":"review/REVIEW_STATUS/#contact-information","title":"\ud83d\udcde Contact Information","text":"<ul> <li>Lead Architect: [Name] - [email]</li> <li>Review Coordinator: [Name] - [email]</li> <li>Emergency Escalation: [Name] - [phone]</li> </ul> <p>Status: \u2705 Ready for Development Team Review Next Action: Begin structured review process according to assigned roles and timeline</p> <p>[Auto] Validation Summary updated \u2014 5 warnings, 0 criticals (2025-10-07 12:28) [Auto] DQI recalculated \u2014 99.0/100 (Trend: \u2192) [Auto] Snapshot generated and uploaded \u2014 2025-10-07 [Auto] Code fence language hints added \u2014 287 fences fixed, warnings: 127\u219269 (-58), DQI: 74.6\u219286.2 (+11.6) (2025-10-07) [Auto] Terminology normalized \u2014 75 fixes applied, warnings: 17\u21920 (-17), DQI: 92.6\u219296.0 (+3.4) (2025-10-07) [Auto] JSON/YAML syntax tightened \u2014 32 fixes applied, syntax errors: 18\u219212 (-6), DQI: 96.0\u219297.4 (+1.4), 16-security-model.md: \u2705 clean (2025-10-07) [Auto] Dashboard polished \u2014 Top 5 fixes + DQI trend added, accessible via Review &amp; Validation \u2192 AI Summary (2025-10-07) [Auto] Phase 2.6 Green Across Board \u2014 Python syntax errors: 7\u21924 (-3), illegal annotation: 1\u21920 (-1), warnings: 13\u219210 (-3), DQI: 97.4\u219298.0 (+0.6) (2025-10-07) [Auto] YAML syntax fixed \u2014 YAML errors: 3\u21920 (-3), warnings: 10\u21926 (-4), DQI: 98.0\u219298.8 (+0.8) (2025-10-07) [Auto] Placeholders replaced \u2014 placeholder warnings: 2\u21920 (-2), warnings: 6\u21926 (stable), DQI: 98.8\u219298.8 (stable) (2025-10-07) [Auto] Risk framework cleaned \u2014 syntax errors: 1\u21920 (-1), warnings: 6\u21925 (-1), DQI: 98.8\u219299.0 (+0.2) (2025-10-07)</p>"},{"location":"review/VALIDATION_SUMMARY/","title":"AI-Assisted Validation Summary","text":"<p>Generated: 2025-10-07 12:28:23 Source: docs/review/validation_report.md</p>"},{"location":"review/VALIDATION_SUMMARY/#overview","title":"\ud83d\udcca Overview","text":"<ul> <li>Total Documents: 25</li> <li>Critical Issues: 0</li> <li>Warnings: 5</li> <li>Categories: 2</li> </ul>"},{"location":"review/VALIDATION_SUMMARY/#documentation-quality-index-dqi","title":"\ud83d\udcc8 Documentation Quality Index (DQI)","text":"<ul> <li>Score: 99.0/100</li> <li>Trend: \u2192</li> </ul> <p>Quality Level: \ud83d\udfe2 Excellent</p>"},{"location":"review/VALIDATION_SUMMARY/#warnings-by-category","title":"\ud83c\udff7\ufe0f Warnings by Category","text":""},{"location":"review/VALIDATION_SUMMARY/#code-block-issues","title":"Code Block Issues","text":"<p>Count: 3</p> <p>Issues:</p> <ul> <li>Syntax check failed in 17-observability-logging-and-metrics.md: JSON error at line 1, column 1: Expecting value</li> <li>Syntax check failed in 06-plugin-system.md: Syntax error at line 1: invalid syntax</li> <li>Syntax check failed in 14-poc-sources-and-legal-guidelines.md: Syntax error at line 1: invalid syntax</li> </ul>"},{"location":"review/VALIDATION_SUMMARY/#terminology-glossary-inconsistencies","title":"Terminology / Glossary Inconsistencies","text":"<p>Count: 2</p> <p>Issues:</p> <ul> <li>Forbidden term in 12-findings-model-and-schema.md: <code>cvss</code> (use <code>CVSS</code>)</li> <li>Forbidden term in 08-tool-manager-and-ux-design.md: <code>secflow</code> (use <code>SecFlow</code>)</li> </ul>"},{"location":"review/VALIDATION_SUMMARY/#top-10-most-frequent-issues","title":"\ud83d\udd25 Top 10 Most Frequent Issues","text":"<ol> <li>1x - Syntax check failed in 06-plugin-system.md: Syntax error at line 1: invalid syntax</li> <li>1x - Forbidden term in 08-tool-manager-and-ux-design.md: <code>secflow</code> (use <code>SecFlow</code>)</li> <li>1x - Forbidden term in 12-findings-model-and-schema.md: <code>cvss</code> (use <code>CVSS</code>)</li> <li>1x - Syntax check failed in 14-poc-sources-and-legal-guidelines.md: Syntax error at line 1: invalid syntax</li> <li>1x - Syntax check failed in 17-observability-logging-and-metrics.md: JSON error at line 1, column 1: Expecting value</li> </ol>"},{"location":"review/VALIDATION_SUMMARY/#suggested-actions","title":"\ud83d\udca1 Suggested Actions","text":"<ul> <li>Add language hints to code blocks (3 issues): Specify <code>python</code>, <code>yaml</code>, <code>json</code> etc. for better syntax highlighting</li> <li>Standardize terminology (2 issues): Use consistent capitalization (e.g., 'SecFlow' not 'secflow')</li> <li>Run validation regularly: Use <code>make validate</code> before committing changes</li> <li>Review validation summary: Check <code>VALIDATION_SUMMARY.md</code> for detailed insights</li> <li>Follow glossary standards: Use <code>docs/review/glossary.yml</code> for terminology consistency</li> <li>Complete code examples: Replace placeholders with working code snippets</li> </ul>"},{"location":"review/VALIDATION_SUMMARY/#document-health-score","title":"\ud83d\udcc8 Document Health Score","text":"Document Warnings Criticals Health Score 00-index.md 0 0 \ud83d\udfe2 100% 01-title-and-executive-summary.md 0 0 \ud83d\udfe2 100% 02-architecture-philosophy.md 0 0 \ud83d\udfe2 100% 03-repository-layout.md 0 0 \ud83d\udfe2 100% 04-core-packages-and-responsibilities.md 0 0 \ud83d\udfe2 100% 05-orchestration-and-workflow-engine.md 0 0 \ud83d\udfe2 100% 07-tools-integration-model.md 0 0 \ud83d\udfe2 100% 09-resource-registry.md 0 0 \ud83d\udfe2 100% 10-wordlist-and-output-sharing.md 0 0 \ud83d\udfe2 100% 11-project-isolation-and-data-sharing.md 0 0 \ud83d\udfe2 100% 13-cve-cwe-poc-enrichment-layer.md 0 0 \ud83d\udfe2 100% 15-garbage-collection-and-retention.md 0 0 \ud83d\udfe2 100% 16-security-model.md 0 0 \ud83d\udfe2 100% 18-error-handling-and-recovery.md 0 0 \ud83d\udfe2 100% 19-risk-assessment-framework.md 0 0 \ud83d\udfe2 100% 20-migration-and-implementation-phases.md 0 0 \ud83d\udfe2 100% 21-ci-cd-and-testing-strategy.md 0 0 \ud83d\udfe2 100% 22-developer-experience-and-docs.md 0 0 \ud83d\udfe2 100% 23-future-roadmap.md 0 0 \ud83d\udfe2 100% 24-final-consensus-summary.md 0 0 \ud83d\udfe2 100% 06-plugin-system.md 1 0 \ud83d\udfe2 98% 08-tool-manager-and-ux-design.md 1 0 \ud83d\udfe2 98% 12-findings-model-and-schema.md 1 0 \ud83d\udfe2 98% 14-poc-sources-and-legal-guidelines.md 1 0 \ud83d\udfe2 98% 17-observability-logging-and-metrics.md 1 0 \ud83d\udfe2 98%"},{"location":"review/VALIDATION_SUMMARY/#priority-recommendations","title":"\ud83c\udfaf Priority Recommendations","text":"<ul> <li>Focus on high-warning documents: 06-plugin-system.md, 08-tool-manager-and-ux-design.md, 12-findings-model-and-schema.md</li> <li>Standardize terminology: Important for professional presentation</li> <li>Regular validation: Run <code>make validate</code> before each commit</li> <li>Team review: Use structured review process for major changes</li> <li>Continuous improvement: Monitor validation trends over time</li> </ul> <p>Generated by AI-Assisted Validation Summary Generator Last updated: 2025-10-07 12:28:23</p>"},{"location":"review/review_assignments/","title":"SecFlow Architecture Review Assignments","text":""},{"location":"review/review_assignments/#review-team-assignments","title":"\ud83d\udc65 Review Team Assignments","text":"<p>This document outlines the specific review assignments for each team member, ensuring comprehensive coverage of all 24 architecture documents.</p>"},{"location":"review/review_assignments/#lead-architect-review-all-documents","title":"\ud83c\udfaf Lead Architect Review (All Documents)","text":"<p>Reviewer: Lead Architect Scope: All documents (00-24) Focus: Overall architecture consistency, design patterns, cross-document coherence</p>"},{"location":"review/review_assignments/#priority-documents","title":"Priority Documents","text":"<ol> <li>00-index.md - Navigation and structure</li> <li>02-architecture-philosophy.md - Core architectural principles</li> <li>04-core-packages-and-responsibilities.md - Package structure and relationships</li> <li>05-orchestration-and-workflow-engine.md - Workflow orchestration design</li> <li>24-final-consensus-summary.md - Final architectural consensus</li> </ol>"},{"location":"review/review_assignments/#review-criteria","title":"Review Criteria","text":"<ul> <li>[ ] Architectural consistency across all documents</li> <li>[ ] Design pattern alignment with hexagonal architecture</li> <li>[ ] Cross-document references and dependencies</li> <li>[ ] Overall system coherence and feasibility</li> <li>[ ] Strategic alignment with project goals</li> </ul>"},{"location":"review/review_assignments/#backend-engineers-review","title":"\ud83d\udd27 Backend Engineers Review","text":"<p>Reviewers: Senior Backend Engineer, Backend Developer Scope: Core technical implementation documents Focus: Data models, API design, database integration, workflow execution</p>"},{"location":"review/review_assignments/#assigned-documents","title":"Assigned Documents","text":"<ol> <li>04-core-packages-and-responsibilities.md</li> <li>Package structure and responsibilities</li> <li>Interface definitions and contracts</li> <li> <p>Cross-package dependencies</p> </li> <li> <p>05-orchestration-and-workflow-engine.md</p> </li> <li>DAG execution engine design</li> <li>Workflow specification schema</li> <li> <p>Node executor implementation</p> </li> <li> <p>12-findings-model-and-schema.md</p> </li> <li>Finding data model and normalization</li> <li>Database schema design</li> <li> <p>Data validation and transformation</p> </li> <li> <p>13-cve-cwe-poc-enrichment-layer.md</p> </li> <li>Enrichment pipeline design</li> <li>External API integrations</li> <li> <p>Data caching and synchronization</p> </li> <li> <p>16-security-model.md</p> </li> <li>Authentication and authorization implementation</li> <li>Security middleware design</li> <li> <p>Audit logging mechanisms</p> </li> <li> <p>17-observability-logging-and-metrics.md</p> </li> <li>Logging infrastructure design</li> <li>Metrics collection and export</li> <li> <p>Distributed tracing implementation</p> </li> <li> <p>18-error-handling-and-recovery.md</p> </li> <li>Error handling strategies</li> <li>Retry logic and circuit breakers</li> <li>Dead letter queue implementation</li> </ol>"},{"location":"review/review_assignments/#review-criteria_1","title":"Review Criteria","text":"<ul> <li>[ ] Technical feasibility of implementation</li> <li>[ ] Code examples are syntactically correct</li> <li>[ ] Data models are complete and consistent</li> <li>[ ] API design follows RESTful principles</li> <li>[ ] Database schema is normalized and efficient</li> <li>[ ] Error handling is comprehensive</li> <li>[ ] Performance requirements are achievable</li> </ul>"},{"location":"review/review_assignments/#frontend-engineers-review","title":"\ud83c\udfa8 Frontend Engineers Review","text":"<p>Reviewers: Frontend Developer, UX Designer Scope: User interface and experience documents Focus: UI/UX design, web interface, CLI experience, user workflows</p>"},{"location":"review/review_assignments/#assigned-documents_1","title":"Assigned Documents","text":"<ol> <li>08-tool-manager-and-ux-design.md</li> <li>Tool Manager UX design</li> <li>CLI and web interface specifications</li> <li> <p>User workflow design</p> </li> <li> <p>22-developer-experience-and-docs.md</p> </li> <li>Developer tools and CLI utilities</li> <li>Documentation system design</li> <li>Local development workflow</li> </ol>"},{"location":"review/review_assignments/#review-criteria_2","title":"Review Criteria","text":"<ul> <li>[ ] UI/UX design is intuitive and accessible</li> <li>[ ] CLI commands are logical and well-organized</li> <li>[ ] Web interface specifications are complete</li> <li>[ ] User workflows are efficient and clear</li> <li>[ ] Developer experience is optimized</li> <li>[ ] Documentation is user-friendly</li> </ul>"},{"location":"review/review_assignments/#devops-engineers-review","title":"\ud83d\ude80 DevOps Engineers Review","text":"<p>Reviewers: DevOps Engineer, Infrastructure Engineer Scope: Infrastructure, deployment, and operational documents Focus: CI/CD, deployment strategies, infrastructure requirements, monitoring</p>"},{"location":"review/review_assignments/#assigned-documents_2","title":"Assigned Documents","text":"<ol> <li>03-repository-layout.md</li> <li>Mono-repo structure and tooling</li> <li>Import boundaries and enforcement</li> <li> <p>Development workflow automation</p> </li> <li> <p>15-garbage-collection-and-retention.md</p> </li> <li>Data lifecycle management</li> <li>Cleanup and retention policies</li> <li> <p>Storage optimization strategies</p> </li> <li> <p>17-observability-logging-and-metrics.md</p> </li> <li>Monitoring and observability infrastructure</li> <li>Log aggregation and analysis</li> <li> <p>Metrics collection and alerting</p> </li> <li> <p>21-ci-cd-and-testing-strategy.md</p> </li> <li>CI/CD pipeline design</li> <li>Testing framework and automation</li> <li>Deployment strategies and rollback</li> </ol>"},{"location":"review/review_assignments/#review-criteria_3","title":"Review Criteria","text":"<ul> <li>[ ] Infrastructure requirements are realistic</li> <li>[ ] CI/CD pipeline is efficient and reliable</li> <li>[ ] Deployment strategies are safe and scalable</li> <li>[ ] Monitoring and observability are comprehensive</li> <li>[ ] Backup and recovery procedures are adequate</li> <li>[ ] Security scanning and compliance checks are integrated</li> </ul>"},{"location":"review/review_assignments/#security-engineers-review","title":"\ud83d\udd12 Security Engineers Review","text":"<p>Reviewers: Security Engineer, Compliance Officer Scope: Security, compliance, and risk assessment documents Focus: Security model, compliance requirements, risk assessment, data protection</p>"},{"location":"review/review_assignments/#assigned-documents_3","title":"Assigned Documents","text":"<ol> <li>11-project-isolation-and-data-sharing.md</li> <li>Project isolation mechanisms</li> <li>Data sharing policies and controls</li> <li> <p>Access control and permissions</p> </li> <li> <p>14-poc-sources-and-legal-guidelines.md</p> </li> <li>PoC governance and legal compliance</li> <li>Sandbox execution security</li> <li> <p>Legal and ethical guidelines</p> </li> <li> <p>16-security-model.md</p> </li> <li>Authentication and authorization design</li> <li>Security middleware and controls</li> <li> <p>Audit logging and compliance</p> </li> <li> <p>19-risk-assessment-framework.md</p> </li> <li>Risk scoring methodology</li> <li>NIST framework implementation</li> <li>CVSS and CWE integration</li> </ol>"},{"location":"review/review_assignments/#review-criteria_4","title":"Review Criteria","text":"<ul> <li>[ ] Security controls are comprehensive and effective</li> <li>[ ] Compliance requirements are met</li> <li>[ ] Risk assessment methodology is sound</li> <li>[ ] Data protection measures are adequate</li> <li>[ ] Audit requirements are satisfied</li> <li>[ ] Legal and ethical guidelines are followed</li> </ul>"},{"location":"review/review_assignments/#qa-engineers-review","title":"\ud83e\uddea QA Engineers Review","text":"<p>Reviewers: QA Engineer, Test Automation Engineer Scope: Testing strategy and quality assurance documents Focus: Testing frameworks, quality gates, validation criteria, test automation</p>"},{"location":"review/review_assignments/#assigned-documents_4","title":"Assigned Documents","text":"<ol> <li>12-findings-model-and-schema.md</li> <li>Data validation and transformation testing</li> <li>Schema validation and error handling</li> <li> <p>Data integrity testing</p> </li> <li> <p>18-error-handling-and-recovery.md</p> </li> <li>Error handling testing strategies</li> <li>Recovery mechanism validation</li> <li> <p>Fault tolerance testing</p> </li> <li> <p>21-ci-cd-and-testing-strategy.md</p> </li> <li>Testing framework and automation</li> <li>Quality gates and validation criteria</li> <li>Test coverage and reporting</li> </ol>"},{"location":"review/review_assignments/#review-criteria_5","title":"Review Criteria","text":"<ul> <li>[ ] Testing strategies are comprehensive</li> <li>[ ] Quality gates are appropriate and measurable</li> <li>[ ] Test automation is feasible and maintainable</li> <li>[ ] Error scenarios are adequately covered</li> <li>[ ] Performance testing requirements are defined</li> <li>[ ] Security testing is integrated</li> </ul>"},{"location":"review/review_assignments/#product-manager-review","title":"\ud83d\udcca Product Manager Review","text":"<p>Reviewer: Product Manager Scope: Business requirements and user experience documents Focus: Business value, user requirements, market fit, strategic alignment</p>"},{"location":"review/review_assignments/#assigned-documents_5","title":"Assigned Documents","text":"<ol> <li>01-title-and-executive-summary.md</li> <li>Project vision and goals</li> <li>Business value proposition</li> <li> <p>Market positioning</p> </li> <li> <p>08-tool-manager-and-ux-design.md</p> </li> <li>User experience design</li> <li>Tool management workflows</li> <li> <p>User interface specifications</p> </li> <li> <p>20-migration-and-implementation-phases.md</p> </li> <li>Implementation roadmap and timeline</li> <li>Phase deliverables and milestones</li> <li> <p>Success criteria and metrics</p> </li> <li> <p>23-future-roadmap.md</p> </li> <li>Strategic evolution and roadmap</li> <li>AI integration and future capabilities</li> <li>Market trends and competitive analysis</li> </ol>"},{"location":"review/review_assignments/#review-criteria_6","title":"Review Criteria","text":"<ul> <li>[ ] Business requirements are clearly defined</li> <li>[ ] User experience meets market expectations</li> <li>[ ] Implementation timeline is realistic</li> <li>[ ] Success criteria are measurable</li> <li>[ ] Strategic alignment with company goals</li> <li>[ ] Competitive advantages are clear</li> </ul>"},{"location":"review/review_assignments/#review-schedule","title":"\ud83d\udcc5 Review Schedule","text":""},{"location":"review/review_assignments/#week-1-individual-reviews","title":"Week 1: Individual Reviews","text":"<ul> <li>Monday-Tuesday: Backend Engineers review assigned documents</li> <li>Wednesday-Thursday: Frontend Engineers review assigned documents</li> <li>Friday: DevOps Engineers review assigned documents</li> </ul>"},{"location":"review/review_assignments/#week-2-cross-reviews","title":"Week 2: Cross-Reviews","text":"<ul> <li>Monday: Security Engineers review assigned documents</li> <li>Tuesday: QA Engineers review assigned documents</li> <li>Wednesday: Product Manager review assigned documents</li> <li>Thursday-Friday: Cross-review sessions (each team reviews outside their expertise)</li> </ul>"},{"location":"review/review_assignments/#week-3-group-review-sessions","title":"Week 3: Group Review Sessions","text":"<ul> <li>Monday: Core Architecture Review (Documents 00-05)</li> <li>Tuesday: Implementation Review (Documents 06-12)</li> <li>Wednesday: Operations Review (Documents 13-18)</li> <li>Thursday: Strategy Review (Documents 19-24)</li> <li>Friday: Final Consolidation and Issue Resolution</li> </ul>"},{"location":"review/review_assignments/#week-4-final-validation","title":"Week 4: Final Validation","text":"<ul> <li>Monday-Tuesday: Lead Architect final review</li> <li>Wednesday: Stakeholder approval sessions</li> <li>Thursday: Final validation and sign-off</li> <li>Friday: Implementation readiness assessment</li> </ul>"},{"location":"review/review_assignments/#review-deliverables","title":"\ud83d\udcdd Review Deliverables","text":""},{"location":"review/review_assignments/#individual-review-deliverables","title":"Individual Review Deliverables","text":"<ul> <li>[ ] Completed review checklist for each assigned document</li> <li>[ ] Detailed feedback report with specific issues and recommendations</li> <li>[ ] Technical accuracy validation results</li> <li>[ ] Consistency and completeness assessment</li> </ul>"},{"location":"review/review_assignments/#cross-review-deliverables","title":"Cross-Review Deliverables","text":"<ul> <li>[ ] Cross-document consistency validation</li> <li>[ ] Integration point verification</li> <li>[ ] Cross-functional requirement validation</li> <li>[ ] Stakeholder alignment confirmation</li> </ul>"},{"location":"review/review_assignments/#group-review-deliverables","title":"Group Review Deliverables","text":"<ul> <li>[ ] Consolidated issue list with priorities</li> <li>[ ] Resolution plan with timelines</li> <li>[ ] Final approval recommendations</li> <li>[ ] Implementation readiness assessment</li> </ul>"},{"location":"review/review_assignments/#escalation-process","title":"\ud83d\udea8 Escalation Process","text":""},{"location":"review/review_assignments/#critical-issues","title":"Critical Issues","text":"<ul> <li>Security vulnerabilities in design</li> <li>Infeasible technical requirements</li> <li>Major architectural inconsistencies</li> <li>Compliance violations</li> <li>Timeline conflicts</li> </ul>"},{"location":"review/review_assignments/#escalation-path","title":"Escalation Path","text":"<ol> <li>Identify critical issue during review</li> <li>Document issue with evidence and impact</li> <li>Notify Lead Architect immediately</li> <li>Schedule emergency review session</li> <li>Resolve with all stakeholders present</li> <li>Update review assignments if needed</li> </ol>"},{"location":"review/review_assignments/#success-criteria","title":"\u2705 Success Criteria","text":"<p>The review process is considered successful when: - [ ] All 24 documents are reviewed by assigned team members - [ ] All critical issues are identified and resolved - [ ] Cross-document consistency is validated - [ ] All stakeholders approve their respective sections - [ ] Implementation roadmap is validated as feasible - [ ] Development team is ready to begin implementation</p> <p>Next Steps: Begin individual reviews according to the assigned schedule and scope.</p>"},{"location":"review/review_workflow/","title":"SecFlow Architecture Review Workflow","text":""},{"location":"review/review_workflow/#overview","title":"\ud83c\udfaf Overview","text":"<p>This document defines the structured review workflow for the SecFlow architecture documentation suite, ensuring comprehensive validation and stakeholder approval before implementation begins.</p>"},{"location":"review/review_workflow/#workflow-phases","title":"\ud83d\udccb Workflow Phases","text":""},{"location":"review/review_workflow/#phase-1-pre-review-setup-day-1","title":"Phase 1: Pre-Review Setup (Day 1)","text":"<p>Duration: 1 day Participants: Lead Architect, Review Coordinator</p>"},{"location":"review/review_workflow/#activities","title":"Activities","text":"<ul> <li>[ ] Review Environment Setup</li> <li>Create review workspace with all documents</li> <li>Set up collaboration tools (GitHub, Slack, etc.)</li> <li>Configure review tracking system</li> <li> <p>Prepare review templates and checklists</p> </li> <li> <p>[ ] Stakeholder Notification</p> </li> <li>Send review invitations to all team members</li> <li>Distribute review assignments and timelines</li> <li>Schedule review sessions and meetings</li> <li> <p>Provide access to review tools and resources</p> </li> <li> <p>[ ] Review Preparation</p> </li> <li>Run automated validation checks</li> <li>Generate initial validation report</li> <li>Identify any obvious issues for quick fixes</li> <li>Prepare review guidelines and instructions</li> </ul>"},{"location":"review/review_workflow/#deliverables","title":"Deliverables","text":"<ul> <li>[ ] Review workspace configured</li> <li>[ ] All stakeholders notified and onboarded</li> <li>[ ] Review tools and templates ready</li> <li>[ ] Initial validation report generated</li> </ul>"},{"location":"review/review_workflow/#phase-2-individual-reviews-days-2-6","title":"Phase 2: Individual Reviews (Days 2-6)","text":"<p>Duration: 5 days Participants: All assigned reviewers</p>"},{"location":"review/review_workflow/#activities_1","title":"Activities","text":"<ul> <li>[ ] Document-Specific Reviews</li> <li>Each reviewer reviews their assigned documents</li> <li>Use provided checklists and templates</li> <li>Document all issues, suggestions, and feedback</li> <li> <p>Validate technical accuracy and completeness</p> </li> <li> <p>[ ] Cross-Document Reviews</p> </li> <li>Review documents outside primary expertise</li> <li>Check for consistency and integration issues</li> <li>Validate cross-references and dependencies</li> <li> <p>Identify architectural inconsistencies</p> </li> <li> <p>[ ] Feedback Documentation</p> </li> <li>Complete review templates for each document</li> <li>Categorize issues by severity and type</li> <li>Provide specific recommendations for improvements</li> <li>Document approval status for each document</li> </ul>"},{"location":"review/review_workflow/#deliverables_1","title":"Deliverables","text":"<ul> <li>[ ] Individual review reports for all documents</li> <li>[ ] Consolidated issue list with priorities</li> <li>[ ] Cross-document consistency validation</li> <li>[ ] Initial approval recommendations</li> </ul>"},{"location":"review/review_workflow/#phase-3-cross-review-sessions-days-7-8","title":"Phase 3: Cross-Review Sessions (Days 7-8)","text":"<p>Duration: 2 days Participants: All reviewers</p>"},{"location":"review/review_workflow/#activities_2","title":"Activities","text":"<ul> <li>[ ] Cross-Functional Reviews</li> <li>Review documents outside primary expertise</li> <li>Validate integration points and dependencies</li> <li>Check for cross-functional requirements</li> <li> <p>Ensure stakeholder alignment</p> </li> <li> <p>[ ] Consistency Validation</p> </li> <li>Validate terminology and naming conventions</li> <li>Check architectural pattern consistency</li> <li>Verify data model consistency</li> <li> <p>Validate security model alignment</p> </li> <li> <p>[ ] Issue Resolution Planning</p> </li> <li>Prioritize issues by severity and impact</li> <li>Assign resolution responsibilities</li> <li>Set timelines for issue resolution</li> <li>Plan for emergency escalations</li> </ul>"},{"location":"review/review_workflow/#deliverables_2","title":"Deliverables","text":"<ul> <li>[ ] Cross-review validation reports</li> <li>[ ] Prioritized issue resolution plan</li> <li>[ ] Consistency validation results</li> <li>[ ] Stakeholder alignment confirmation</li> </ul>"},{"location":"review/review_workflow/#phase-4-group-review-sessions-days-9-11","title":"Phase 4: Group Review Sessions (Days 9-11)","text":"<p>Duration: 3 days Participants: All stakeholders</p>"},{"location":"review/review_workflow/#activities_3","title":"Activities","text":"<ul> <li>[ ] Document Category Reviews</li> <li>Day 9: Core Architecture (Documents 00-05)</li> <li>Day 10: Implementation (Documents 06-12)</li> <li> <p>Day 11: Operations &amp; Strategy (Documents 13-24)</p> </li> <li> <p>[ ] Stakeholder Approval Sessions</p> </li> <li>Present review findings for each category</li> <li>Discuss critical issues and resolutions</li> <li>Validate implementation feasibility</li> <li> <p>Obtain formal approval from stakeholders</p> </li> <li> <p>[ ] Issue Resolution</p> </li> <li>Address critical issues immediately</li> <li>Plan resolution for non-critical issues</li> <li>Update documents based on feedback</li> <li>Validate changes and improvements</li> </ul>"},{"location":"review/review_workflow/#deliverables_3","title":"Deliverables","text":"<ul> <li>[ ] Group review session reports</li> <li>[ ] Stakeholder approval confirmations</li> <li>[ ] Resolved critical issues</li> <li>[ ] Updated documents with improvements</li> </ul>"},{"location":"review/review_workflow/#phase-5-final-validation-days-12-14","title":"Phase 5: Final Validation (Days 12-14)","text":"<p>Duration: 3 days Participants: Lead Architect, Review Coordinator</p>"},{"location":"review/review_workflow/#activities_4","title":"Activities","text":"<ul> <li>[ ] Final Validation</li> <li>Run comprehensive validation checks</li> <li>Verify all issues have been addressed</li> <li>Validate document consistency and accuracy</li> <li> <p>Confirm stakeholder approvals</p> </li> <li> <p>[ ] Implementation Readiness Assessment</p> </li> <li>Validate technical feasibility</li> <li>Confirm resource availability</li> <li>Verify timeline alignment</li> <li> <p>Assess risk mitigation strategies</p> </li> <li> <p>[ ] Documentation Finalization</p> </li> <li>Update documents with final changes</li> <li>Generate final validation report</li> <li>Prepare implementation guidelines</li> <li>Create handoff documentation</li> </ul>"},{"location":"review/review_workflow/#deliverables_4","title":"Deliverables","text":"<ul> <li>[ ] Final validation report</li> <li>[ ] Implementation readiness assessment</li> <li>[ ] Updated architecture documentation</li> <li>[ ] Implementation handoff package</li> </ul>"},{"location":"review/review_workflow/#review-process-flow","title":"\ud83d\udd04 Review Process Flow","text":"<pre><code>graph TD\n    A[Pre-Review Setup] --&gt; B[Individual Reviews]\n    B --&gt; C[Cross-Review Sessions]\n    C --&gt; D[Group Review Sessions]\n    D --&gt; E[Final Validation]\n    E --&gt; F[Implementation Ready]\n\n    B --&gt; G[Issue Identification]\n    G --&gt; H[Issue Resolution]\n    H --&gt; I[Document Updates]\n    I --&gt; C\n\n    D --&gt; J[Critical Issues?]\n    J --&gt;|Yes| K[Emergency Review]\n    K --&gt; H\n    J --&gt;|No| E\n</code></pre>"},{"location":"review/review_workflow/#review-metrics-and-kpis","title":"\ud83d\udcca Review Metrics and KPIs","text":""},{"location":"review/review_workflow/#quality-metrics","title":"Quality Metrics","text":"Metric Target Measurement Review Coverage 100% All documents reviewed by assigned roles Issue Resolution 95% Critical issues resolved before approval Consistency Score \u2265 90% Cross-document consistency rating Technical Accuracy 100% All code examples and diagrams validated Security Compliance 100% All security requirements met"},{"location":"review/review_workflow/#process-metrics","title":"Process Metrics","text":"Metric Target Measurement Review Completion 100% All assigned reviews completed on time Stakeholder Approval 100% All stakeholders approve their sections Issue Response Time &lt; 24 hours Time to respond to critical issues Document Update Time &lt; 48 hours Time to update documents after feedback"},{"location":"review/review_workflow/#escalation-procedures","title":"\ud83d\udea8 Escalation Procedures","text":""},{"location":"review/review_workflow/#critical-issues","title":"Critical Issues","text":"<p>Definition: Issues that could prevent implementation or compromise security</p> <p>Examples: - Security vulnerabilities in design - Infeasible technical requirements - Major architectural inconsistencies - Compliance violations - Timeline conflicts</p> <p>Escalation Process: 1. Identify critical issue during review 2. Document issue with evidence and impact 3. Notify Lead Architect immediately 4. Schedule emergency review session within 4 hours 5. Resolve with all stakeholders present 6. Update review assignments if needed</p>"},{"location":"review/review_workflow/#non-critical-issues","title":"Non-Critical Issues","text":"<p>Definition: Issues that should be addressed but don't block implementation</p> <p>Examples: - Minor formatting inconsistencies - Documentation improvements - Code style suggestions - Performance optimizations</p> <p>Resolution Process: 1. Document issue in review report 2. Assign resolution responsibility 3. Set timeline for resolution 4. Track progress in issue tracking system 5. Validate resolution before final approval</p>"},{"location":"review/review_workflow/#review-templates-and-tools","title":"\ud83d\udcdd Review Templates and Tools","text":""},{"location":"review/review_workflow/#individual-review-template","title":"Individual Review Template","text":"<pre><code>## Document Review: [Document Name]\n**Reviewer:** [Name]  \n**Date:** [Date]  \n**Review Type:** [Individual/Cross/Group]\n\n### Technical Accuracy\n- **Issues Found:** [List specific issues]\n- **Recommendations:** [Suggestions for improvement]\n- **Code Examples:** [Any syntax or logic errors]\n\n### Completeness\n- **Missing Sections:** [List any missing content]\n- **Incomplete Examples:** [Identify incomplete examples]\n- **Unclear Requirements:** [Highlight unclear specifications]\n\n### Consistency\n- **Terminology Issues:** [Inconsistent terms or definitions]\n- **Design Pattern Conflicts:** [Any architectural inconsistencies]\n- **Cross-Reference Problems:** [Broken or incorrect links]\n\n### Overall Assessment\n- **Strengths:** [What works well]\n- **Critical Issues:** [Must-fix problems]\n- **Enhancement Opportunities:** [Nice-to-have improvements]\n- **Recommendation:** [Approve/Revise/Reject]\n</code></pre>"},{"location":"review/review_workflow/#group-review-session-template","title":"Group Review Session Template","text":"<pre><code>## Group Review Session: [Category]\n**Date:** [Date]  \n**Participants:** [List participants]\n\n### Documents Reviewed\n- [List documents reviewed]\n\n### Key Issues Identified\n- [List critical issues]\n- [List non-critical issues]\n\n### Resolutions Agreed\n- [List agreed resolutions]\n- [Assign responsibilities]\n- [Set timelines]\n\n### Approval Status\n- [Document approval status]\n- [Stakeholder confirmations]\n- [Next steps]\n</code></pre>"},{"location":"review/review_workflow/#success-criteria","title":"\ud83c\udfaf Success Criteria","text":"<p>The review workflow is considered successful when:</p>"},{"location":"review/review_workflow/#quality-criteria","title":"Quality Criteria","text":"<ul> <li>[ ] All 24 documents pass technical accuracy review</li> <li>[ ] No critical security or compliance issues remain</li> <li>[ ] Cross-document consistency is validated</li> <li>[ ] All stakeholders approve their respective sections</li> <li>[ ] Implementation roadmap is validated as feasible</li> </ul>"},{"location":"review/review_workflow/#process-criteria","title":"Process Criteria","text":"<ul> <li>[ ] All review phases completed on schedule</li> <li>[ ] All stakeholders actively participated</li> <li>[ ] All issues properly documented and resolved</li> <li>[ ] All approvals formally obtained</li> <li>[ ] Implementation team ready to begin</li> </ul>"},{"location":"review/review_workflow/#deliverable-criteria","title":"Deliverable Criteria","text":"<ul> <li>[ ] Final validation report generated</li> <li>[ ] Implementation readiness assessment completed</li> <li>[ ] Updated architecture documentation ready</li> <li>[ ] Implementation handoff package prepared</li> <li>[ ] Development team onboarded and ready</li> </ul>"},{"location":"review/review_workflow/#contact-information","title":"\ud83d\udcde Contact Information","text":""},{"location":"review/review_workflow/#review-team","title":"Review Team","text":"<ul> <li>Lead Architect: [Name] - [email] - [phone]</li> <li>Review Coordinator: [Name] - [email] - [phone]</li> <li>Backend Lead: [Name] - [email] - [phone]</li> <li>Frontend Lead: [Name] - [email] - [phone]</li> <li>DevOps Lead: [Name] - [email] - [phone]</li> <li>Security Lead: [Name] - [email] - [phone]</li> </ul>"},{"location":"review/review_workflow/#emergency-contacts","title":"Emergency Contacts","text":"<ul> <li>Critical Issues: Lead Architect - [phone]</li> <li>Process Issues: Review Coordinator - [phone]</li> <li>Technical Issues: Backend Lead - [phone]</li> </ul>"},{"location":"review/review_workflow/#timeline-summary","title":"\ud83d\udcc5 Timeline Summary","text":"Phase Duration Key Activities Deliverables Phase 1 1 day Pre-review setup Review environment ready Phase 2 5 days Individual reviews Review reports completed Phase 3 2 days Cross-review sessions Consistency validated Phase 4 3 days Group review sessions Stakeholder approvals Phase 5 3 days Final validation Implementation ready <p>Total Duration: 14 days Target Completion: [Date]</p> <p>Next Steps: Begin Phase 1 - Pre-Review Setup</p>"},{"location":"review/validation_checklist/","title":"SecFlow Architecture Validation Checklist","text":""},{"location":"review/validation_checklist/#overview","title":"\ud83c\udfaf Overview","text":"<p>This comprehensive validation checklist ensures all architecture documents meet quality standards before implementation begins.</p>"},{"location":"review/validation_checklist/#document-structure-validation","title":"\ud83d\udccb Document Structure Validation","text":""},{"location":"review/validation_checklist/#yaml-metadata-validation","title":"YAML Metadata Validation","text":"<ul> <li>[ ] All documents have required YAML frontmatter</li> <li>[ ] Title, author, codename, version, and date are present</li> <li>[ ] Version format follows semantic versioning (e.g., \"1.0\")</li> <li>[ ] Date format is consistent (YYYY-MM-DD)</li> </ul>"},{"location":"review/validation_checklist/#content-structure-validation","title":"Content Structure Validation","text":"<ul> <li>[ ] Each document has a clear overview section</li> <li>[ ] ASCII diagrams are properly formatted</li> <li>[ ] Code examples are syntax-highlighted</li> <li>[ ] Tables are properly formatted</li> <li>[ ] Internal links use correct MkDocs format</li> <li>[ ] Section headers follow consistent hierarchy</li> </ul>"},{"location":"review/validation_checklist/#technical-content-validation","title":"\ud83d\udd0d Technical Content Validation","text":""},{"location":"review/validation_checklist/#code-examples","title":"Code Examples","text":"<ul> <li>[ ] Python code examples are syntactically correct</li> <li>[ ] YAML configurations are valid</li> <li>[ ] JSON examples are properly formatted</li> <li>[ ] Import statements are accurate</li> <li>[ ] Function signatures are complete</li> <li>[ ] Error handling is demonstrated</li> </ul>"},{"location":"review/validation_checklist/#architecture-diagrams","title":"Architecture Diagrams","text":"<ul> <li>[ ] ASCII diagrams are readable and accurate</li> <li>[ ] Component relationships are clearly shown</li> <li>[ ] Data flow directions are indicated</li> <li>[ ] Layer boundaries are defined</li> <li>[ ] External dependencies are identified</li> </ul>"},{"location":"review/validation_checklist/#data-models","title":"Data Models","text":"<ul> <li>[ ] Pydantic models are complete and valid</li> <li>[ ] Field types are correctly specified</li> <li>[ ] Validation rules are appropriate</li> <li>[ ] Relationships between models are clear</li> <li>[ ] Database schemas are consistent</li> </ul>"},{"location":"review/validation_checklist/#architecture-consistency-validation","title":"\ud83c\udfd7\ufe0f Architecture Consistency Validation","text":""},{"location":"review/validation_checklist/#design-patterns","title":"Design Patterns","text":"<ul> <li>[ ] Hexagonal architecture principles are consistently applied</li> <li>[ ] Port and adapter patterns are properly implemented</li> <li>[ ] Event-driven design is consistently used</li> <li>[ ] Immutable data flow is maintained</li> <li>[ ] Dependency inversion is followed</li> </ul>"},{"location":"review/validation_checklist/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>[ ] Package names follow Python conventions</li> <li>[ ] Class names use PascalCase</li> <li>[ ] Function names use snake_case</li> <li>[ ] Constants use UPPER_CASE</li> <li>[ ] File names are descriptive and consistent</li> </ul>"},{"location":"review/validation_checklist/#cross-document-references","title":"Cross-Document References","text":"<ul> <li>[ ] All internal links are valid</li> <li>[ ] Referenced concepts are defined</li> <li>[ ] Data model references are consistent</li> <li>[ ] API endpoint references are accurate</li> <li>[ ] Configuration references are valid</li> </ul>"},{"location":"review/validation_checklist/#security-validation","title":"\ud83d\udd12 Security Validation","text":""},{"location":"review/validation_checklist/#security-model","title":"Security Model","text":"<ul> <li>[ ] Authentication mechanisms are clearly defined</li> <li>[ ] Authorization model is comprehensive</li> <li>[ ] Data encryption requirements are specified</li> <li>[ ] Audit logging is properly designed</li> <li>[ ] Security boundaries are clearly defined</li> </ul>"},{"location":"review/validation_checklist/#compliance-requirements","title":"Compliance Requirements","text":"<ul> <li>[ ] NIST framework references are accurate</li> <li>[ ] CVSS scoring methodology is correct</li> <li>[ ] CWE/OWASP mappings are valid</li> <li>[ ] MITRE ATT&amp;CK references are current</li> <li>[ ] Data protection requirements are met</li> </ul>"},{"location":"review/validation_checklist/#risk-assessment","title":"Risk Assessment","text":"<ul> <li>[ ] Risk scoring formulas are mathematically sound</li> <li>[ ] Risk factors are properly weighted</li> <li>[ ] Risk thresholds are realistic</li> <li>[ ] Risk mitigation strategies are feasible</li> <li>[ ] Risk reporting is comprehensive</li> </ul>"},{"location":"review/validation_checklist/#implementation-feasibility-validation","title":"\ud83d\ude80 Implementation Feasibility Validation","text":""},{"location":"review/validation_checklist/#technical-requirements","title":"Technical Requirements","text":"<ul> <li>[ ] All dependencies are available and maintained</li> <li>[ ] Performance requirements are achievable</li> <li>[ ] Scalability requirements are realistic</li> <li>[ ] Integration points are well-defined</li> <li>[ ] Error handling strategies are complete</li> </ul>"},{"location":"review/validation_checklist/#resource-requirements","title":"Resource Requirements","text":"<ul> <li>[ ] Infrastructure requirements are realistic</li> <li>[ ] Development effort estimates are accurate</li> <li>[ ] Testing requirements are comprehensive</li> <li>[ ] Deployment complexity is manageable</li> <li>[ ] Maintenance requirements are clear</li> </ul>"},{"location":"review/validation_checklist/#migration-strategy","title":"Migration Strategy","text":"<ul> <li>[ ] Phase transitions are clearly defined</li> <li>[ ] Rollback strategies are specified</li> <li>[ ] Data migration plans are feasible</li> <li>[ ] Testing strategies are comprehensive</li> <li>[ ] Success criteria are measurable</li> </ul>"},{"location":"review/validation_checklist/#quality-metrics-validation","title":"\ud83d\udcca Quality Metrics Validation","text":""},{"location":"review/validation_checklist/#completeness","title":"Completeness","text":"<ul> <li>[ ] All required sections are present</li> <li>[ ] Examples cover all major use cases</li> <li>[ ] Edge cases are addressed</li> <li>[ ] Error scenarios are documented</li> <li>[ ] Future considerations are included</li> </ul>"},{"location":"review/validation_checklist/#clarity","title":"Clarity","text":"<ul> <li>[ ] Technical concepts are clearly explained</li> <li>[ ] Diagrams enhance understanding</li> <li>[ ] Code examples are well-commented</li> <li>[ ] Language is professional and accessible</li> <li>[ ] Document structure is logical</li> </ul>"},{"location":"review/validation_checklist/#accuracy","title":"Accuracy","text":"<ul> <li>[ ] Technical specifications are correct</li> <li>[ ] Code examples are functional</li> <li>[ ] Architecture diagrams are accurate</li> <li>[ ] Data models are consistent</li> <li>[ ] Integration points are valid</li> </ul>"},{"location":"review/validation_checklist/#process-validation","title":"\ud83d\udd04 Process Validation","text":""},{"location":"review/validation_checklist/#review-process","title":"Review Process","text":"<ul> <li>[ ] All stakeholders have reviewed their sections</li> <li>[ ] Cross-reviews have been completed</li> <li>[ ] Group review sessions have been conducted</li> <li>[ ] All issues have been resolved</li> <li>[ ] Final approval has been obtained</li> </ul>"},{"location":"review/validation_checklist/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>[ ] All documents follow the established template</li> <li>[ ] Formatting is consistent across documents</li> <li>[ ] Links and references are valid</li> <li>[ ] Version control is properly maintained</li> <li>[ ] Change tracking is documented</li> </ul>"},{"location":"review/validation_checklist/#final-validation-checklist","title":"\u2705 Final Validation Checklist","text":""},{"location":"review/validation_checklist/#pre-implementation-validation","title":"Pre-Implementation Validation","text":"<ul> <li>[ ] All 24 documents pass technical accuracy review</li> <li>[ ] No critical security or compliance issues remain</li> <li>[ ] Cross-document consistency is validated</li> <li>[ ] All stakeholders approve their respective sections</li> <li>[ ] Implementation roadmap is validated as feasible</li> <li>[ ] Risk assessment methodology is approved by security team</li> </ul>"},{"location":"review/validation_checklist/#implementation-readiness","title":"Implementation Readiness","text":"<ul> <li>[ ] Development environment setup is documented</li> <li>[ ] CI/CD pipeline configuration is ready</li> <li>[ ] Testing framework is established</li> <li>[ ] Security scanning tools are configured</li> <li>[ ] Monitoring and observability tools are ready</li> <li>[ ] Documentation generation process is automated</li> </ul>"},{"location":"review/validation_checklist/#critical-issues-requiring-immediate-attention","title":"\ud83d\udea8 Critical Issues Requiring Immediate Attention","text":""},{"location":"review/validation_checklist/#security-issues","title":"Security Issues","text":"<ul> <li>[ ] Any security vulnerabilities in design</li> <li>[ ] Missing security controls</li> <li>[ ] Inadequate data protection measures</li> <li>[ ] Compliance violations</li> <li>[ ] Audit trail gaps</li> </ul>"},{"location":"review/validation_checklist/#technical-issues","title":"Technical Issues","text":"<ul> <li>[ ] Infeasible technical requirements</li> <li>[ ] Major architectural inconsistencies</li> <li>[ ] Performance bottlenecks</li> <li>[ ] Integration failures</li> <li>[ ] Data model conflicts</li> </ul>"},{"location":"review/validation_checklist/#process-issues","title":"Process Issues","text":"<ul> <li>[ ] Missing stakeholder approvals</li> <li>[ ] Incomplete review process</li> <li>[ ] Unresolved critical issues</li> <li>[ ] Timeline conflicts</li> <li>[ ] Resource constraints</li> </ul>"},{"location":"review/validation_checklist/#validation-report-template","title":"\ud83d\udcdd Validation Report Template","text":""},{"location":"review/validation_checklist/#document-document-name","title":"Document: [Document Name]","text":"<p>Validator: [Name] Date: [Date] Status: [Pass/Fail/Needs Revision]</p>"},{"location":"review/validation_checklist/#technical-validation","title":"Technical Validation","text":"<ul> <li>Code Examples: [Pass/Fail] - [Comments]</li> <li>Architecture Diagrams: [Pass/Fail] - [Comments]</li> <li>Data Models: [Pass/Fail] - [Comments]</li> <li>Integration Points: [Pass/Fail] - [Comments]</li> </ul>"},{"location":"review/validation_checklist/#security-validation_1","title":"Security Validation","text":"<ul> <li>Security Model: [Pass/Fail] - [Comments]</li> <li>Compliance Requirements: [Pass/Fail] - [Comments]</li> <li>Risk Assessment: [Pass/Fail] - [Comments]</li> <li>Data Protection: [Pass/Fail] - [Comments]</li> </ul>"},{"location":"review/validation_checklist/#process-validation_1","title":"Process Validation","text":"<ul> <li>Review Process: [Pass/Fail] - [Comments]</li> <li>Documentation Standards: [Pass/Fail] - [Comments]</li> <li>Stakeholder Approval: [Pass/Fail] - [Comments]</li> <li>Implementation Readiness: [Pass/Fail] - [Comments]</li> </ul>"},{"location":"review/validation_checklist/#overall-assessment","title":"Overall Assessment","text":"<ul> <li>Strengths: [List strengths]</li> <li>Issues Found: [List issues]</li> <li>Recommendations: [List recommendations]</li> <li>Final Recommendation: [Approve/Revise/Reject]</li> </ul>"},{"location":"review/validation_checklist/#success-criteria","title":"\ud83c\udfaf Success Criteria","text":"<p>The architecture validation is considered successful when: - [ ] All documents pass technical accuracy validation - [ ] No critical security or compliance issues remain - [ ] Cross-document consistency is validated - [ ] All stakeholders approve their respective sections - [ ] Implementation roadmap is validated as feasible - [ ] Risk assessment methodology is approved by security team - [ ] Development team is ready to begin implementation</p> <p>Next Steps: Use this checklist to validate each document systematically before proceeding to implementation.</p>"},{"location":"review/validation_report/","title":"Validation Report \u2014 2025-10-07T09:28:17.078745Z","text":"<ul> <li>Criticals: 0</li> <li>Warnings: 5</li> </ul> Document Criticals Warnings 00-index.md 0 0 01-title-and-executive-summary.md 0 0 02-architecture-philosophy.md 0 0 03-repository-layout.md 0 0 04-core-packages-and-responsibilities.md 0 0 05-orchestration-and-workflow-engine.md 0 0 06-plugin-system.md 0 1 07-tools-integration-model.md 0 0 08-tool-manager-and-ux-design.md 0 1 09-resource-registry.md 0 0 10-wordlist-and-output-sharing.md 0 0 11-project-isolation-and-data-sharing.md 0 0 12-findings-model-and-schema.md 0 1 13-cve-cwe-poc-enrichment-layer.md 0 0 14-poc-sources-and-legal-guidelines.md 0 1 15-garbage-collection-and-retention.md 0 0 16-security-model.md 0 0 17-observability-logging-and-metrics.md 0 1 18-error-handling-and-recovery.md 0 0 19-risk-assessment-framework.md 0 0 20-migration-and-implementation-phases.md 0 0 21-ci-cd-and-testing-strategy.md 0 0 22-developer-experience-and-docs.md 0 0 23-future-roadmap.md 0 0 24-final-consensus-summary.md 0 0"},{"location":"review/validation_report/#06-plugin-systemmd","title":"06-plugin-system.md","text":"<p>\u26a0\ufe0f Warnings</p> <ul> <li>Syntax check failed in 06-plugin-system.md: Syntax error at line 1: invalid syntax</li> </ul>"},{"location":"review/validation_report/#08-tool-manager-and-ux-designmd","title":"08-tool-manager-and-ux-design.md","text":"<p>\u26a0\ufe0f Warnings</p> <ul> <li>Forbidden term in 08-tool-manager-and-ux-design.md: <code>secflow</code> (use <code>SecFlow</code>)</li> </ul>"},{"location":"review/validation_report/#12-findings-model-and-schemamd","title":"12-findings-model-and-schema.md","text":"<p>\u26a0\ufe0f Warnings</p> <ul> <li>Forbidden term in 12-findings-model-and-schema.md: <code>cvss</code> (use <code>CVSS</code>)</li> </ul>"},{"location":"review/validation_report/#14-poc-sources-and-legal-guidelinesmd","title":"14-poc-sources-and-legal-guidelines.md","text":"<p>\u26a0\ufe0f Warnings</p> <ul> <li>Syntax check failed in 14-poc-sources-and-legal-guidelines.md: Syntax error at line 1: invalid syntax</li> </ul>"},{"location":"review/validation_report/#17-observability-logging-and-metricsmd","title":"17-observability-logging-and-metrics.md","text":"<p>\u26a0\ufe0f Warnings</p> <ul> <li>Syntax check failed in 17-observability-logging-and-metrics.md: JSON error at line 1, column 1: Expecting value</li> </ul>"},{"location":"review/validation_report/#documentation-quality-index","title":"\ud83d\udcc8 Documentation Quality Index","text":"<ul> <li>Score: 99.0/100</li> <li>Criticals: 0</li> <li>Warnings: 5</li> <li>Trend: \u2192</li> </ul> <p>Quality Level: \ud83d\udfe2 Excellent Trend: \u27a1\ufe0f Stable</p>"}]}